{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lheinzel/UAVHRBuildingDetection/blob/SSD_MobNet_320x320_Augmenter/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/HR_BuildingDetector_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzx9J_TlztU2"
      },
      "source": [
        "# Setup Project Parameters and Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQUQ5KGU1dxB"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsUgUFXIz23i"
      },
      "source": [
        "Project parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wQ7GzPHz5WH"
      },
      "outputs": [],
      "source": [
        "CUSTOM_MODEL_NAME = 'HRDetection_MobNetV2'\n",
        "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
        "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
        "GITHUB_REPO_URL = 'https://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@github.com/lheinzel/UAVHRBuildingDetection.git'\n",
        "DATASET_REPO_URL = 'https://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@github.com/lheinzel/UAVHighRiseBuildingsKorea.git'\n",
        "DATASET_REPO_NAME = 'UAVHighRiseBuildingsKorea'\n",
        "DATASET_BRANCH_NAME = 'CroppingRework_320x320'\n",
        "DATA_PACKAGE_NAME = 'newData'\n",
        "INPUT_DIMS = [320, 320]\n",
        "LABEL_MAP_NAME = 'labelmap.pbtxt'\n",
        "NOF_CLASSES = 1\n",
        "GIT_BRANCH = \"SSD_MobNet_320x320_Augmenter\"\n",
        "NOF_STEPS = 20000\n",
        "BATCH_SIZE = 16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaAB_EZw04EW"
      },
      "source": [
        "Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WQG9nQK05hv"
      },
      "outputs": [],
      "source": [
        "paths = {\"github_repo\" : os.path.join(\"//content\",\"UAVHRBuildingDetection\"),\n",
        "         \"workspace\" : os.path.join(\"//content\",\"UAVHRBuildingDetection\",\"Tensorflow\",\"workspace\"),\n",
        "         \"annotations\" : os.path.join(\"//content\",\"UAVHRBuildingDetection\",\"Tensorflow\",\"workspace\",\"annotations\"),\n",
        "         \"images\": os.path.join(\"//content\",\"UAVHRBuildingDetection\",\"Tensorflow\",\"workspace\",\"images\"),\n",
        "         \"training\" : os.path.join(\"//content\",\"UAVHRBuildingDetection\",\"Tensorflow\",\"workspace\",\"training_SSD-MobnetV2_320x320_MoreAugments\"),\n",
        "         \"scripts_pre\" : os.path.join(\"//content\",\"UAVHRBuildingDetection\",\"Tensorflow\",\"scripts\",\"preprocessing\"),\n",
        "         \"pretrained_models\" : os.path.join(\"//content\",\"UAVHRBuildingDetection\",\"Tensorflow\",\"workspace\",\"pretrained_model\"),\n",
        "         \"custom_models\" : os.path.join(\"//content\",\"UAVHRBuildingDetection\",\"Tensorflow\",\"workspace\",\"training_SSD-MobnetV2_320x320_MoreAugments\", \"models\"),\n",
        "         \"obj_detection_api\" : os.path.join(\"//content\",\"UAVHRBuildingDetection\",\"Tensorflow\", \"models\", \"research\", \"object_detection\"),\n",
        "         \"custom_model_dir\" : os.path.join(\"//content\",\"UAVHRBuildingDetection\",\"Tensorflow\",\"workspace\",\"training_SSD-MobnetV2_320x320_MoreAugments\", \"models\",CUSTOM_MODEL_NAME),\n",
        "         \"custom_model_config\" : os.path.join(\"//content\",\"UAVHRBuildingDetection\",\"Tensorflow\",\"workspace\",\"training_SSD-MobnetV2_320x320_MoreAugments\", \"models\",CUSTOM_MODEL_NAME, \"pipeline.config\"),\n",
        "         \"model_export_dir\" : os.path.join(\"//content\",\"UAVHRBuildingDetection\",\"Tensorflow\",\"workspace\",\"training_SSD-MobnetV2_320x320_MoreAugments\",\"exported_models\"),\n",
        "         \"dataset_images\" : os.path.join(\"//content\", \"UAVHRBuildingDetection\", \"Datasets\", DATASET_REPO_NAME, DATA_PACKAGE_NAME, \"Images\"),\n",
        "         \"dataset_labels\" : os.path.join(\"//content\", \"UAVHRBuildingDetection\",\"Datasets\", DATASET_REPO_NAME, DATA_PACKAGE_NAME, \"Labels\")\n",
        "         }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CecPFTsQfH3"
      },
      "source": [
        "# Environment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1ZaBbmBTJvC"
      },
      "source": [
        "Clone the project repository from github"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIN-rdTzTO6e",
        "outputId": "decc33db-c416-4ca6-845e-52f6049d9aad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'UAVHRBuildingDetection'...\n",
            "remote: Enumerating objects: 6175, done.\u001b[K\n",
            "remote: Counting objects: 100% (85/85), done.\u001b[K\n",
            "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
            "remote: Total 6175 (delta 41), reused 66 (delta 33), pack-reused 6090\u001b[K\n",
            "Receiving objects: 100% (6175/6175), 3.24 GiB | 17.09 MiB/s, done.\n",
            "Resolving deltas: 100% (609/609), done.\n",
            "Checking out files: 100% (72/72), done.\n",
            "[Errno 2] No such file or directory: 'paths[github_repo]'\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(paths[\"github_repo\"]):\n",
        "    !git clone -b {GIT_BRANCH} --single-branch {GITHUB_REPO_URL}\n",
        "\n",
        "%cd paths[\"github_repo\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIkeq6uxW1Qb",
        "outputId": "ebb11834-5044-42cd-fb82-31daf29aace1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ],
      "source": [
        "!git pull origin {GIT_BRANCH}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfoOOLN9Wvc5"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_IWOJwP803d"
      },
      "source": [
        "Clone the dataset repository from github"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spMz-XGW83yX",
        "outputId": "5e7e0ed7-92f6-46cf-cdfc-b9fb2660620f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UAVHRBuildingDetection/Datasets\n",
            "Cloning into 'UAVHighRiseBuildingsKorea'...\n",
            "remote: Enumerating objects: 14312, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 14312 (delta 3), reused 11 (delta 2), pack-reused 14294\u001b[K\n",
            "Receiving objects: 100% (14312/14312), 2.42 GiB | 17.06 MiB/s, done.\n",
            "Resolving deltas: 100% (7585/7585), done.\n",
            "/content/UAVHRBuildingDetection\n"
          ]
        }
      ],
      "source": [
        "datasetPath = os.path.join(paths[\"github_repo\"], \"Datasets\")\n",
        "\n",
        "if not os.path.exists(datasetPath):\n",
        "  os.makedirs(datasetPath)\n",
        "\n",
        "%cd {datasetPath}\n",
        "\n",
        "if not os.path.exists(os.path.join(datasetPath, DATASET_REPO_NAME)):\n",
        "  !git clone -b {DATASET_BRANCH_NAME} --single-branch {DATASET_REPO_URL}\n",
        "\n",
        "%cd {paths[\"github_repo\"]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeARLJTzV4pn",
        "outputId": "ee35ef4a-99b6-411a-86cf-32a468e91dae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UAVHRBuildingDetection/Datasets/UAVHighRiseBuildingsKorea\n",
            "On branch CroppingRework_320x320\n",
            "Your branch is up to date with 'origin/CroppingRework_320x320'.\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "From https://github.com/lheinzel/UAVHighRiseBuildingsKorea\n",
            " * branch            CroppingRework_320x320 -> FETCH_HEAD\n",
            "Already up to date.\n",
            "/content/UAVHRBuildingDetection\n"
          ]
        }
      ],
      "source": [
        "%cd {os.path.join(paths[\"github_repo\"], \"Datasets\",DATASET_REPO_NAME)}\n",
        "!git status\n",
        "!git pull origin {DATASET_BRANCH_NAME}\n",
        "%cd {paths[\"github_repo\"]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YE9tdhlZTRK1"
      },
      "source": [
        "Install the object detection api and all other necessary things on the runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JD8AsOp3QoNR",
        "outputId": "e8a74b8b-67a1-4caa-9f25-58a27ab47c97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.8\n",
            "  Downloading https://us-python.pkg.dev/colab-wheels/public/tensorflow/tensorflow-2.8.0%2Bzzzcolab20220506162203-cp37-cp37m-linux_x86_64.whl (668.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 668.3 MB 17 kB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (3.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.1.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (14.0.6)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (0.5.3)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (2.8.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.14.1)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (2.8.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (3.17.3)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 37.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (4.1.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.6.3)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (0.26.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (57.4.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (2.0.7)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.48.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow==2.8) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow==2.8) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (1.8.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly, tensorflow\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220719082949\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220719082949:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220719082949\n",
            "Successfully installed tensorflow-2.8.0+zzzcolab20220506162203 tf-estimator-nightly-2.8.0.dev2021122109\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following packages will be REMOVED:\n",
            "  libcudnn8-dev\n",
            "The following held packages will be changed:\n",
            "  libcudnn8\n",
            "The following packages will be upgraded:\n",
            "  libcudnn8\n",
            "1 upgraded, 0 newly installed, 1 to remove and 30 not upgraded.\n",
            "Need to get 430 MB of archives.\n",
            "After this operation, 3,139 MB disk space will be freed.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcudnn8 8.1.0.77-1+cuda11.2 [430 MB]\n",
            "Fetched 430 MB in 12s (36.2 MB/s)\n",
            "(Reading database ... 155685 files and directories currently installed.)\n",
            "Removing libcudnn8-dev (8.0.5.39-1+cuda11.1) ...\n",
            "(Reading database ... 155663 files and directories currently installed.)\n",
            "Preparing to unpack .../libcudnn8_8.1.0.77-1+cuda11.2_amd64.deb ...\n",
            "Unpacking libcudnn8 (8.1.0.77-1+cuda11.2) over (8.0.5.39-1+cuda11.1) ...\n",
            "Setting up libcudnn8 (8.1.0.77-1+cuda11.2) ...\n",
            "2022-09-13 14:28:36.202362: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "tf.Tensor(-709.9026, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# install/upgrade tensorflow\n",
        "#!pip install --ignore-installed --upgrade tensorflow==2.5.0\n",
        "!pip install tensorflow==2.8\n",
        "!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2\n",
        "\n",
        "# verify installation\n",
        "!python -c \"import tensorflow as tf; print(tf.reduce_sum(tf.random.normal([1000, 1000])))\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eUZ2lN6xJrr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5cf0188-5d3a-4733-a8fa-ca8856f602fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/UAVHRBuildingDetection/Tensorflow’: File exists\n",
            "/content/UAVHRBuildingDetection/Tensorflow\n",
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 77038, done.\u001b[K\n",
            "remote: Counting objects: 100% (332/332), done.\u001b[K\n",
            "remote: Compressing objects: 100% (232/232), done.\u001b[K\n",
            "remote: Total 77038 (delta 138), reused 264 (delta 92), pack-reused 76706\u001b[K\n",
            "Receiving objects: 100% (77038/77038), 593.21 MiB | 17.05 MiB/s, done.\n",
            "Resolving deltas: 100% (54652/54652), done.\n"
          ]
        }
      ],
      "source": [
        "# download model zoo if not present\n",
        "if not os.path.exists(r\"/content/UAVHRBuildingDetection/Tensorflow/models\"):\n",
        "  !mkdir /content/UAVHRBuildingDetection/Tensorflow\n",
        "  %cd /content/UAVHRBuildingDetection/Tensorflow\n",
        "  !git clone https://github.com/tensorflow/models.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BjKgzSLxMW9",
        "outputId": "a32e540a-1b96-4767-80e9-555ceccaf642"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UAVHRBuildingDetection/Tensorflow/models/research\n"
          ]
        }
      ],
      "source": [
        "# protobuf compilation\n",
        "%cd /content/UAVHRBuildingDetection/Tensorflow/models/research/\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiyKej9ZxQO_",
        "outputId": "6d5f4511-2508-41c6-e363-4f2b8d39dfdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UAVHRBuildingDetection\n",
            "Cloning into 'cocoapi'...\n",
            "remote: Enumerating objects: 975, done.\u001b[K\n",
            "remote: Total 975 (delta 0), reused 0 (delta 0), pack-reused 975\u001b[K\n",
            "Receiving objects: 100% (975/975), 11.72 MiB | 15.53 MiB/s, done.\n",
            "Resolving deltas: 100% (576/576), done.\n",
            "/content/UAVHRBuildingDetection/cocoapi/PythonAPI\n",
            "python setup.py build_ext --inplace\n",
            "running build_ext\n",
            "cythoning pycocotools/_mask.pyx to pycocotools/_mask.c\n",
            "/usr/local/lib/python3.7/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/UAVHRBuildingDetection/cocoapi/PythonAPI/pycocotools/_mask.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "building 'pycocotools._mask' extension\n",
            "creating build\n",
            "creating build/common\n",
            "creating build/temp.linux-x86_64-3.7\n",
            "creating build/temp.linux-x86_64-3.7/pycocotools\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c ../common/maskApi.c -o build/temp.linux-x86_64-3.7/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleDecode\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:46:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n",
            "       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:46:49:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; \u001b[01;36m\u001b[Kv\u001b[m\u001b[K=!v; }}\n",
            "                                                 \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrPoly\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:166:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n",
            "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:166:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); \u001b[01;36m\u001b[Kx\u001b[m\u001b[K[k]=x[0];\n",
            "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:167:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n",
            "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:167:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); \u001b[01;36m\u001b[Ky\u001b[m\u001b[K[k]=y[0];\n",
            "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:212:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "       \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(more) c |= 0x20; c+=48; s[p++]=c;\n",
            "       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:212:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "       if(more) c |= 0x20; \u001b[01;36m\u001b[Kc\u001b[m\u001b[K+=48; s[p++]=c;\n",
            "                           \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:220:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kwhile\u001b[m\u001b[K( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n",
            "   \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:220:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’\n",
            "   while( s[m] ) m++; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K=malloc(sizeof(uint)*m); m=0;\n",
            "                      \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:228:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "     \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n",
            "     \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:228:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "     if(m>2) x+=(long) cnts[m-2]; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K[m++]=(uint) x;\n",
            "                                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToBbox\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:141:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kxp\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
            "       if(j%2==0) xp=x; else if\u001b[01;35m\u001b[K(\u001b[m\u001b[Kxp<x) { ys=0; ye=h-1; }\n",
            "                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c pycocotools/_mask.c -o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "creating build/lib.linux-x86_64-3.7\n",
            "creating build/lib.linux-x86_64-3.7/pycocotools\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/../common/maskApi.o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -o build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so -> pycocotools\n",
            "rm -rf build\n"
          ]
        }
      ],
      "source": [
        "%cd /content/UAVHRBuildingDetection\n",
        "\n",
        "# install cocoapi\n",
        "if not os.path.exists(r\"/content/UAVHRBuildingDetection/Tensorflow/models/research/cocoapi\"):\n",
        "  !git clone https://github.com/cocodataset/cocoapi.git\n",
        "  %cd /content/UAVHRBuildingDetection/cocoapi/PythonAPI\n",
        "  !make\n",
        "  !cp -r pycocotools /content/UAVHRBuildingDetection/Tensorflow/models/research/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LTQ82a_KxUgQ",
        "outputId": "46006de6-8229-4d01-ae99-78177d450e26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UAVHRBuildingDetection/Tensorflow/models/research\n",
            "\u001b[33mWARNING: --use-feature=2020-resolver no longer has any effect, since it is now the default dependency resolver in pip. This will become an error in pip 21.0.\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/UAVHRBuildingDetection/Tensorflow/models/research\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.41.0-cp37-cp37m-manylinux2010_x86_64.whl (10.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.9 MB 52.9 MB/s \n",
            "\u001b[?25hCollecting pillow\n",
            "  Downloading Pillow-9.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 44.5 MB/s \n",
            "\u001b[?25hCollecting lxml\n",
            "  Downloading lxml-4.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 48.7 MB/s \n",
            "\u001b[?25hCollecting matplotlib\n",
            "  Downloading matplotlib-3.5.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.2 MB 55.0 MB/s \n",
            "\u001b[?25hCollecting Cython\n",
            "  Downloading Cython-0.29.32-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 46.9 MB/s \n",
            "\u001b[?25hCollecting contextlib2\n",
            "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 77.9 MB/s \n",
            "\u001b[?25hCollecting six\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pycocotools\n",
            "  Downloading pycocotools-2.0.4.tar.gz (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 69.4 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Collecting scipy\n",
            "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.1 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting pandas\n",
            "  Downloading pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.3 MB 61.8 MB/s \n",
            "\u001b[?25hCollecting tf-models-official>=2.5.1\n",
            "  Downloading tf_models_official-2.9.2-py2.py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 63.8 MB/s \n",
            "\u001b[?25hCollecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.27.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (25.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.0 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting keras\n",
            "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 58.4 MB/s \n",
            "\u001b[?25hCollecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 7.1 MB/s \n",
            "\u001b[?25hCollecting py-cpuinfo>=3.3.0\n",
            "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
            "\u001b[K     |████████████████████████████████| 99 kB 11.7 MB/s \n",
            "\u001b[?25hCollecting kaggle>=1.3.9\n",
            "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 7.2 MB/s \n",
            "\u001b[?25hCollecting sacrebleu\n",
            "  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
            "\u001b[K     |████████████████████████████████| 116 kB 69.9 MB/s \n",
            "\u001b[?25hCollecting tensorflow-text~=2.9.0\n",
            "  Downloading tensorflow_text-2.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 47.6 MB/s \n",
            "\u001b[?25hCollecting tensorflow-hub>=0.6.0\n",
            "  Downloading tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
            "\u001b[K     |████████████████████████████████| 108 kB 75.2 MB/s \n",
            "\u001b[?25hCollecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.3-py2.py3-none-any.whl (238 kB)\n",
            "\u001b[K     |████████████████████████████████| 238 kB 76.8 MB/s \n",
            "\u001b[?25hCollecting google-api-python-client>=1.6.7\n",
            "  Downloading google_api_python_client-2.60.0-py2.py3-none-any.whl (9.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.0 MB 45.0 MB/s \n",
            "\u001b[?25hCollecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.17.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 69.2 MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 60.4 MB/s \n",
            "\u001b[?25hCollecting gin-config\n",
            "  Downloading gin_config-0.5.0-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 8.3 MB/s \n",
            "\u001b[?25hCollecting psutil>=5.4.3\n",
            "  Downloading psutil-5.9.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
            "\u001b[K     |████████████████████████████████| 281 kB 72.3 MB/s \n",
            "\u001b[?25hCollecting oauth2client\n",
            "  Downloading oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[K     |████████████████████████████████| 98 kB 9.1 MB/s \n",
            "\u001b[?25hCollecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.0 MB/s \n",
            "\u001b[?25hCollecting numpy>=1.20\n",
            "  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 45.9 MB/s \n",
            "\u001b[?25hCollecting tensorflow~=2.9.0\n",
            "  Downloading tensorflow-2.9.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 511.8 MB 9.3 kB/s \n",
            "\u001b[?25hCollecting pyyaml<6.0,>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 63.5 MB/s \n",
            "\u001b[?25hCollecting tensorflow-datasets\n",
            "  Downloading tensorflow_datasets-4.6.0-py3-none-any.whl (4.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 55.0 MB/s \n",
            "\u001b[?25hCollecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (48.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 48.3 MB 3.6 MB/s \n",
            "\u001b[?25hCollecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5\n",
            "  Downloading google_api_core-2.10.0-py3-none-any.whl (115 kB)\n",
            "\u001b[K     |████████████████████████████████| 115 kB 73.6 MB/s \n",
            "\u001b[?25hCollecting google-auth-httplib2>=0.1.0\n",
            "  Downloading google_auth_httplib2-0.1.0-py2.py3-none-any.whl (9.3 kB)\n",
            "Collecting httplib2<1dev,>=0.15.0\n",
            "  Downloading httplib2-0.20.4-py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 6.7 MB/s \n",
            "\u001b[?25hCollecting uritemplate<5,>=3.0.1\n",
            "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
            "Collecting google-auth<3.0.0dev,>=1.19.0\n",
            "  Downloading google_auth-2.11.0-py2.py3-none-any.whl (167 kB)\n",
            "\u001b[K     |████████████████████████████████| 167 kB 72.3 MB/s \n",
            "\u001b[?25hCollecting requests<3.0.0dev,>=2.18.0\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.8 MB/s \n",
            "\u001b[?25hCollecting protobuf<5.0.0dev,>=3.20.1\n",
            "  Downloading protobuf-4.21.5-cp37-abi3-manylinux2014_x86_64.whl (408 kB)\n",
            "\u001b[K     |████████████████████████████████| 408 kB 74.4 MB/s \n",
            "\u001b[?25hCollecting googleapis-common-protos<2.0dev,>=1.56.2\n",
            "  Downloading googleapis_common_protos-1.56.4-py2.py3-none-any.whl (211 kB)\n",
            "\u001b[K     |████████████████████████████████| 211 kB 69.9 MB/s \n",
            "\u001b[?25hCollecting pyasn1-modules>=0.2.1\n",
            "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
            "\u001b[K     |████████████████████████████████| 155 kB 73.0 MB/s \n",
            "\u001b[?25hCollecting cachetools<6.0,>=2.0.0\n",
            "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
            "Collecting rsa<5,>=3.1.4\n",
            "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Collecting certifi\n",
            "  Downloading certifi-2022.6.15.1-py3-none-any.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 76.6 MB/s \n",
            "\u001b[?25hCollecting python-dateutil\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[K     |████████████████████████████████| 247 kB 74.4 MB/s \n",
            "\u001b[?25hCollecting tqdm\n",
            "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 7.6 MB/s \n",
            "\u001b[?25hCollecting python-slugify\n",
            "  Downloading python_slugify-6.1.2-py2.py3-none-any.whl (9.4 kB)\n",
            "Collecting urllib3\n",
            "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 77.9 MB/s \n",
            "\u001b[?25hCollecting pytz>=2017.3\n",
            "  Downloading pytz-2022.2.1-py2.py3-none-any.whl (500 kB)\n",
            "\u001b[K     |████████████████████████████████| 500 kB 74.2 MB/s \n",
            "\u001b[?25hCollecting pyasn1<0.5.0,>=0.4.6\n",
            "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 7.4 MB/s \n",
            "\u001b[?25hCollecting idna<4,>=2.5\n",
            "  Downloading idna-3.3-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 7.1 MB/s \n",
            "\u001b[?25hCollecting charset-normalizer<3,>=2\n",
            "  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
            "Collecting packaging\n",
            "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 2.0 MB/s \n",
            "\u001b[?25hCollecting wrapt>=1.11.0\n",
            "  Downloading wrapt-1.14.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 4.3 MB/s \n",
            "\u001b[?25hCollecting tensorboard<2.10,>=2.9\n",
            "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 49.9 MB/s \n",
            "\u001b[?25hCollecting astunparse>=1.6.0\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Collecting absl-py>=1.0.0\n",
            "  Downloading absl_py-1.2.0-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 76.4 MB/s \n",
            "\u001b[?25hCollecting gast<=0.4.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Collecting keras\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 59.2 MB/s \n",
            "\u001b[?25hCollecting libclang>=13.0.0\n",
            "  Downloading libclang-14.0.6-py2.py3-none-manylinux2010_x86_64.whl (14.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.1 MB 49.0 MB/s \n",
            "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
            "  Downloading grpcio-1.48.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 54.2 MB/s \n",
            "\u001b[?25hCollecting tensorflow~=2.9.0\n",
            "  Downloading tensorflow-2.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 511.7 MB 6.5 kB/s \n",
            "\u001b[?25h  Downloading tensorflow-2.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 511.7 MB 4.6 kB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[K     |████████████████████████████████| 438 kB 66.7 MB/s \n",
            "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
            "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 4.6 MB/s \n",
            "\u001b[?25hCollecting flatbuffers<2,>=1.12\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting typing-extensions>=3.6.6\n",
            "  Downloading typing_extensions-4.3.0-py3-none-any.whl (25 kB)\n",
            "Collecting keras-preprocessing>=1.1.1\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.3 MB/s \n",
            "\u001b[?25hCollecting setuptools\n",
            "  Using cached setuptools-65.3.0-py3-none-any.whl (1.2 MB)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.27.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4 MB 55.8 MB/s \n",
            "\u001b[?25hCollecting termcolor>=1.1.0\n",
            "  Downloading termcolor-2.0.1-py3-none-any.whl (5.4 kB)\n",
            "Collecting h5py>=2.9.0\n",
            "  Downloading h5py-3.7.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 54.3 MB/s \n",
            "\u001b[?25hCollecting google-pasta>=0.1.1\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 6.3 MB/s \n",
            "\u001b[?25hCollecting wheel<1.0,>=0.23.0\n",
            "  Using cached wheel-0.37.1-py2.py3-none-any.whl (35 kB)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 59.0 MB/s \n",
            "\u001b[?25hCollecting tensorboard<2.10,>=2.9\n",
            "  Downloading tensorboard-2.9.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 51.7 MB/s \n",
            "\u001b[?25hCollecting werkzeug>=1.0.1\n",
            "  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
            "\u001b[K     |████████████████████████████████| 232 kB 76.5 MB/s \n",
            "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[K     |████████████████████████████████| 781 kB 74.0 MB/s \n",
            "\u001b[?25hCollecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.9 MB/s \n",
            "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Collecting requests-oauthlib>=0.7.0\n",
            "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
            "Collecting importlib-metadata>=4.4\n",
            "  Downloading importlib_metadata-4.12.0-py3-none-any.whl (21 kB)\n",
            "Collecting zipp>=0.5\n",
            "  Downloading zipp-3.8.1-py3-none-any.whl (5.6 kB)\n",
            "Collecting oauthlib>=3.0.0\n",
            "  Downloading oauthlib-3.2.1-py3-none-any.whl (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 76.2 MB/s \n",
            "\u001b[?25hCollecting dm-tree~=0.1.1\n",
            "  Downloading dm_tree-0.1.7-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (143 kB)\n",
            "\u001b[K     |████████████████████████████████| 143 kB 71.5 MB/s \n",
            "\u001b[?25hCollecting MarkupSafe>=2.1.1\n",
            "  Downloading MarkupSafe-2.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting protobuf<5.0.0dev,>=3.20.1\n",
            "  Downloading protobuf-3.20.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 69.5 MB/s \n",
            "\u001b[?25hCollecting cloudpickle<3,>=2.1.0\n",
            "  Downloading cloudpickle-2.2.0-py3-none-any.whl (25 kB)\n",
            "Collecting pydot<2,>=1.2.0\n",
            "  Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
            "Collecting orjson<4.0\n",
            "  Downloading orjson-3.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (270 kB)\n",
            "\u001b[K     |████████████████████████████████| 270 kB 66.6 MB/s \n",
            "\u001b[?25hCollecting pymongo<4.0.0,>=3.8.0\n",
            "  Downloading pymongo-3.12.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (508 kB)\n",
            "\u001b[K     |████████████████████████████████| 508 kB 8.5 MB/s \n",
            "\u001b[?25hCollecting pyarrow<8.0.0,>=0.15.1\n",
            "  Downloading pyarrow-7.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.7 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 69.1 MB/s \n",
            "\u001b[?25hCollecting proto-plus<2,>=1.7.1\n",
            "  Downloading proto_plus-1.22.1-py3-none-any.whl (47 kB)\n",
            "\u001b[K     |████████████████████████████████| 47 kB 4.8 MB/s \n",
            "\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
            "Collecting crcmod<2.0,>=1.7\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[K     |████████████████████████████████| 89 kB 10.3 MB/s \n",
            "\u001b[?25hCollecting fastavro<2,>=0.23.6\n",
            "  Downloading fastavro-1.6.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4 MB 52.8 MB/s \n",
            "\u001b[?25hCollecting docopt\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "Collecting cycler>=0.10.0\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Collecting opencv-python>=4.1.0.25\n",
            "  Downloading opencv_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 60.9 MB 168 kB/s \n",
            "\u001b[?25hCollecting kiwisolver>=1.1.0\n",
            "  Downloading kiwisolver-1.4.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 60.0 MB/s \n",
            "\u001b[?25hCollecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.37.1-py3-none-any.whl (957 kB)\n",
            "\u001b[K     |████████████████████████████████| 957 kB 69.8 MB/s \n",
            "\u001b[?25hCollecting text-unidecode>=1.3\n",
            "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 8.0 MB/s \n",
            "\u001b[?25hCollecting regex\n",
            "  Downloading regex-2022.9.13-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n",
            "\u001b[K     |████████████████████████████████| 757 kB 74.5 MB/s \n",
            "\u001b[?25hCollecting portalocker\n",
            "  Downloading portalocker-2.5.1-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tabulate>=0.8.9\n",
            "  Downloading tabulate-0.8.10-py3-none-any.whl (29 kB)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
            "Collecting scikit-learn>=0.21.3\n",
            "  Downloading scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.8 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting joblib>=0.11\n",
            "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
            "\u001b[K     |████████████████████████████████| 306 kB 69.9 MB/s \n",
            "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting typeguard>=2.7\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Collecting tensorflow-metadata\n",
            "  Downloading tensorflow_metadata-1.10.0-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.7 MB/s \n",
            "\u001b[?25hCollecting etils[epath]\n",
            "  Downloading etils-0.8.0-py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 74.8 MB/s \n",
            "\u001b[?25hCollecting toml\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting importlib-resources\n",
            "  Downloading importlib_resources-5.9.0-py3-none-any.whl (33 kB)\n",
            "Collecting promise\n",
            "  Downloading promise-2.3.tar.gz (19 kB)\n",
            "Building wheels for collected packages: object-detection, kaggle, py-cpuinfo, crcmod, dill, avro-python3, docopt, pycocotools, seqeval, promise\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1695161 sha256=7914fa1d09c3a5dc0b499c0a5db1e7df8eda61f63283fe2b08461cacb768af52\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-lh3ty5ci/wheels/d1/88/4c/6e266386b82f3ada7b4a0729eeff3721d08a9ba6a71efc7a13\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73051 sha256=d61f6e22ea05005deadd03ba4cfb466ae2cdcafdb4af9897453fab939dac8bf2\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/d6/58/5853130f941e75b2177d281eb7e44b4a98ed46dd155f556dc5\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=90275c3c296cfe6a6107a505fb39cc2d82429bf778730615c81c930dfb88854e\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp37-cp37m-linux_x86_64.whl size=36343 sha256=3cc8b72207c3a9081f7d27baaa01ab35f272bd48747d324e456a98d2a8a744c8\n",
            "  Stored in directory: /root/.cache/pip/wheels/dc/9a/e9/49e627353476cec8484343c4ab656f1e0d783ee77b9dde2d1f\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=f0f31f7e574346572de9788cb38cee541f5dbdba956e11e236b11afbf91f9ed2\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44010 sha256=71d04010f928d68b48c45df5399d12f895db5b912574e450c3fca92b975529e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/e5/b1/6b151d9b535ee50aaa6ab27d145a0104b6df02e5636f0376da\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=2ed56d682b421ceefa02ae49226104c8d4a90da818cf1f1a6e0a85c579f8e186\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/b0/3f/1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\n",
            "  Building wheel for pycocotools (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0.4-cp37-cp37m-linux_x86_64.whl size=265254 sha256=364212bb8045f4dc575e0a2df788f4df2eaa0a941b303bc2218c5969db4b2298\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/5f/fa/f011e578cc76e1fc5be8dce30b3eb9fd00f337e744b3bba59b\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=8129e9dbcdaa668e963b1794f1ae9a0e2376793258a82411a5e9a623a22bcfac\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "  Building wheel for promise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21503 sha256=7bdc9b2a871fa0afad72b6075bc0d1085a73a561d77224ed4e3e7336b722599e\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/93/c6/762e359f8cb6a5b69c72235d798804cae523bbe41c2aa8333d\n",
            "Successfully built object-detection kaggle py-cpuinfo crcmod dill avro-python3 docopt pycocotools seqeval promise\n",
            "Installing collected packages: urllib3, pyasn1, idna, charset-normalizer, certifi, zipp, typing-extensions, six, rsa, requests, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, MarkupSafe, importlib-metadata, google-auth, wheel, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, setuptools, pyparsing, protobuf, numpy, markdown, grpcio, google-auth-oauthlib, etils, absl-py, wrapt, threadpoolctl, text-unidecode, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, scipy, python-dateutil, pillow, packaging, opt-einsum, libclang, kiwisolver, keras-preprocessing, keras, joblib, importlib-resources, httplib2, h5py, googleapis-common-protos, google-pasta, gast, fonttools, flatbuffers, cycler, astunparse, uritemplate, typeguard, tqdm, toml, tensorflow-metadata, tensorflow-hub, tensorflow, tabulate, scikit-learn, regex, pytz, python-slugify, promise, portalocker, matplotlib, lxml, google-auth-httplib2, google-api-core, docopt, dm-tree, dill, colorama, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-datasets, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, pymongo, pydot, pycocotools, pyarrow, py-cpuinfo, psutil, proto-plus, pandas, orjson, opencv-python-headless, opencv-python, oauth2client, kaggle, hdfs, google-api-python-client, gin-config, fastavro, Cython, crcmod, cloudpickle, tf-models-official, tensorflow-io, lvis, contextlib2, avro-python3, apache-beam, object-detection\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\n",
            "thinc 8.1.0 requires typing-extensions<4.2.0,>=3.7.4.1; python_version < \"3.8\", but you have typing-extensions 4.3.0 which is incompatible.\n",
            "spacy 3.4.1 requires typing-extensions<4.2.0,>=3.7.4; python_version < \"3.8\", but you have typing-extensions 4.3.0 which is incompatible.\n",
            "numba 0.56.2 requires setuptools<60, but you have setuptools 65.3.0 which is incompatible.\n",
            "google-cloud-translate 1.5.0 requires google-api-core[grpc]<2.0.0dev,>=1.6.0, but you have google-api-core 2.10.0 which is incompatible.\n",
            "google-cloud-language 1.2.0 requires google-api-core[grpc]<2.0.0dev,>=1.6.0, but you have google-api-core 2.10.0 which is incompatible.\n",
            "google-cloud-firestore 1.7.0 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.10.0 which is incompatible.\n",
            "google-cloud-datastore 1.8.0 requires google-api-core[grpc]<2.0.0dev,>=1.6.0, but you have google-api-core 2.10.0 which is incompatible.\n",
            "google-cloud-core 1.0.3 requires google-api-core<2.0.0dev,>=1.14.0, but you have google-api-core 2.10.0 which is incompatible.\n",
            "flask 1.1.4 requires Werkzeug<2.0,>=0.15, but you have werkzeug 2.2.2 which is incompatible.\n",
            "firebase-admin 4.4.0 requires google-api-core[grpc]<2.0.0dev,>=1.14.0; platform_python_implementation != \"PyPy\", but you have google-api-core 2.10.0 which is incompatible.\n",
            "earthengine-api 0.1.323 requires google-api-python-client<2,>=1.12.1, but you have google-api-python-client 2.60.0 which is incompatible.\u001b[0m\n",
            "Successfully installed Cython-0.29.32 MarkupSafe-2.1.1 absl-py-1.2.0 apache-beam-2.41.0 astunparse-1.6.3 avro-python3-1.10.2 cachetools-5.2.0 certifi-2022.6.15.1 charset-normalizer-2.1.1 cloudpickle-2.2.0 colorama-0.4.5 contextlib2-21.6.0 crcmod-1.7 cycler-0.11.0 dill-0.3.5.1 dm-tree-0.1.7 docopt-0.6.2 etils-0.8.0 fastavro-1.6.1 flatbuffers-2.0.7 fonttools-4.37.1 gast-0.5.3 gin-config-0.5.0 google-api-core-2.10.0 google-api-python-client-2.60.0 google-auth-2.11.0 google-auth-httplib2-0.1.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 googleapis-common-protos-1.56.4 grpcio-1.48.1 h5py-3.7.0 hdfs-2.7.0 httplib2-0.20.4 idna-3.3 importlib-metadata-4.12.0 importlib-resources-5.9.0 joblib-1.1.0 kaggle-1.5.12 keras-2.9.0 keras-preprocessing-1.1.2 kiwisolver-1.4.4 libclang-14.0.6 lvis-0.5.3 lxml-4.9.1 markdown-3.4.1 matplotlib-3.5.3 numpy-1.21.6 oauth2client-4.1.3 oauthlib-3.2.1 object-detection-0.1 opencv-python-4.6.0.66 opencv-python-headless-4.6.0.66 opt-einsum-3.3.0 orjson-3.8.0 packaging-21.3 pandas-1.3.5 pillow-9.2.0 portalocker-2.5.1 promise-2.3 proto-plus-1.22.1 protobuf-3.20.1 psutil-5.9.2 py-cpuinfo-8.0.0 pyarrow-7.0.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycocotools-2.0.4 pydot-1.4.2 pymongo-4.2.0 pyparsing-3.0.9 python-dateutil-2.8.2 python-slugify-6.1.2 pytz-2022.2.1 pyyaml-6.0 regex-2022.9.13 requests-2.28.1 requests-oauthlib-1.3.1 rsa-4.9 sacrebleu-2.2.0 scikit-learn-1.0.2 scipy-1.7.3 sentencepiece-0.1.97 seqeval-1.2.2 setuptools-65.3.0 six-1.16.0 tabulate-0.8.10 tensorboard-2.9.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.9.0 tensorflow-addons-0.17.1 tensorflow-datasets-4.6.0 tensorflow-estimator-2.9.0 tensorflow-hub-0.12.0 tensorflow-io-0.27.0 tensorflow-io-gcs-filesystem-0.27.0 tensorflow-metadata-1.10.0 tensorflow-model-optimization-0.7.3 tensorflow-text-2.9.0 termcolor-2.0.1 text-unidecode-1.3 tf-models-official-2.9.2 tf-slim-1.1.0 threadpoolctl-3.1.0 toml-0.10.2 tqdm-4.64.1 typeguard-2.13.3 typing-extensions-4.3.0 uritemplate-4.1.1 urllib3-1.26.12 werkzeug-2.2.2 wheel-0.37.1 wrapt-1.14.1 zipp-3.8.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "certifi",
                  "cycler",
                  "dateutil",
                  "google",
                  "httplib2",
                  "kiwisolver",
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy",
                  "pkg_resources",
                  "psutil",
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# install object detection api\n",
        "%cd /content/UAVHRBuildingDetection/Tensorflow/models/research/\n",
        "!cp object_detection/packages/tf2/setup.py .\n",
        "!pip install --ignore-installed --use-feature=2020-resolver ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVHMexLgxV_6",
        "outputId": "5235de49-0bd1-4997-a69e-34c7084e70d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UAVHRBuildingDetection/Tensorflow/models/research\n",
            "Running tests under Python 3.7.13: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2022-09-13 14:34:08.546143: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "W0913 14:34:08.796549 140202722101120 model_builder.py:1102] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.53s\n",
            "I0913 14:34:09.070613 140202722101120 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.53s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.58s\n",
            "I0913 14:34:09.652027 140202722101120 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.58s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.4s\n",
            "I0913 14:34:10.050989 140202722101120 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.4s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.24s\n",
            "I0913 14:34:10.292229 140202722101120 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.24s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.78s\n",
            "I0913 14:34:12.076967 140202722101120 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.78s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0913 14:34:12.077957 140202722101120 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
            "I0913 14:34:12.101964 140202722101120 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
            "I0913 14:34:12.117246 140202722101120 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "I0913 14:34:12.133573 140202722101120 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.11s\n",
            "I0913 14:34:12.240044 140202722101120 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.11s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.1s\n",
            "I0913 14:34:12.335906 140202722101120 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.1s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.11s\n",
            "I0913 14:34:12.444471 140202722101120 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.11s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.1s\n",
            "I0913 14:34:12.541269 140202722101120 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.1s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.28s\n",
            "I0913 14:34:12.817353 140202722101120 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.28s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "I0913 14:34:12.847948 140202722101120 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0913 14:34:13.025035 140202722101120 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0913 14:34:13.025232 140202722101120 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n",
            "I0913 14:34:13.025312 140202722101120 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\n",
            "I0913 14:34:13.029335 140202722101120 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0913 14:34:13.049019 140202722101120 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0913 14:34:13.049159 140202722101120 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0913 14:34:13.111934 140202722101120 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0913 14:34:13.112083 140202722101120 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0913 14:34:13.273522 140202722101120 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0913 14:34:13.273711 140202722101120 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0913 14:34:13.436868 140202722101120 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0913 14:34:13.437078 140202722101120 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0913 14:34:13.683827 140202722101120 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0913 14:34:13.684008 140202722101120 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0913 14:34:13.930596 140202722101120 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0913 14:34:13.930815 140202722101120 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0913 14:34:14.265038 140202722101120 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0913 14:34:14.265230 140202722101120 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0913 14:34:14.344439 140202722101120 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0913 14:34:14.377717 140202722101120 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0913 14:34:14.429266 140202722101120 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0913 14:34:14.429456 140202722101120 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\n",
            "I0913 14:34:14.429548 140202722101120 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 4\n",
            "I0913 14:34:14.431125 140202722101120 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0913 14:34:14.447377 140202722101120 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0913 14:34:14.447502 140202722101120 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0913 14:34:14.576062 140202722101120 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0913 14:34:14.576260 140202722101120 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0913 14:34:14.817570 140202722101120 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0913 14:34:14.817749 140202722101120 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0913 14:34:15.054551 140202722101120 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0913 14:34:15.054718 140202722101120 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0913 14:34:15.373628 140202722101120 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0913 14:34:15.373820 140202722101120 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0913 14:34:15.928279 140202722101120 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0913 14:34:15.928499 140202722101120 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0913 14:34:16.817732 140202722101120 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0913 14:34:16.817994 140202722101120 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0913 14:34:17.235302 140202722101120 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0913 14:34:17.342075 140202722101120 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0913 14:34:17.515943 140202722101120 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0913 14:34:17.516160 140202722101120 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112\n",
            "I0913 14:34:17.516264 140202722101120 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 5\n",
            "I0913 14:34:17.518721 140202722101120 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0913 14:34:17.540619 140202722101120 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0913 14:34:17.540781 140202722101120 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0913 14:34:17.746373 140202722101120 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0913 14:34:17.746573 140202722101120 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0913 14:34:18.147950 140202722101120 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0913 14:34:18.148154 140202722101120 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0913 14:34:18.518862 140202722101120 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0913 14:34:18.519081 140202722101120 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0913 14:34:19.261792 140202722101120 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0913 14:34:19.262022 140202722101120 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0913 14:34:20.033039 140202722101120 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0913 14:34:20.033301 140202722101120 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0913 14:34:20.668022 140202722101120 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0913 14:34:20.668305 140202722101120 efficientnet_model.py:143] round_filter input=320 output=352\n",
            "I0913 14:34:21.067911 140202722101120 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
            "I0913 14:34:21.112359 140202722101120 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0913 14:34:21.171786 140202722101120 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0913 14:34:21.171951 140202722101120 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n",
            "I0913 14:34:21.172028 140202722101120 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 6\n",
            "I0913 14:34:21.173620 140202722101120 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0913 14:34:21.189985 140202722101120 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0913 14:34:21.190093 140202722101120 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0913 14:34:21.414995 140202722101120 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0913 14:34:21.415219 140202722101120 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0913 14:34:21.808487 140202722101120 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0913 14:34:21.808712 140202722101120 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0913 14:34:22.220519 140202722101120 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0913 14:34:22.220740 140202722101120 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0913 14:34:22.975345 140202722101120 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0913 14:34:22.975564 140202722101120 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0913 14:34:23.669722 140202722101120 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0913 14:34:23.669909 140202722101120 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0913 14:34:24.332587 140202722101120 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0913 14:34:24.332825 140202722101120 efficientnet_model.py:143] round_filter input=320 output=384\n",
            "I0913 14:34:24.661835 140202722101120 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
            "I0913 14:34:24.709901 140202722101120 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0913 14:34:24.951534 140202722101120 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0913 14:34:24.951752 140202722101120 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\n",
            "I0913 14:34:24.951860 140202722101120 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
            "I0913 14:34:24.954464 140202722101120 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0913 14:34:24.979550 140202722101120 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0913 14:34:24.979698 140202722101120 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0913 14:34:25.246982 140202722101120 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0913 14:34:25.247218 140202722101120 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0913 14:34:25.743598 140202722101120 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0913 14:34:25.743809 140202722101120 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0913 14:34:26.063289 140202722101120 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0913 14:34:26.063460 140202722101120 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0913 14:34:26.811933 140202722101120 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0913 14:34:26.812110 140202722101120 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0913 14:34:27.395208 140202722101120 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0913 14:34:27.395448 140202722101120 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0913 14:34:28.550300 140202722101120 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0913 14:34:28.550519 140202722101120 efficientnet_model.py:143] round_filter input=320 output=448\n",
            "I0913 14:34:28.795128 140202722101120 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
            "I0913 14:34:28.826750 140202722101120 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0913 14:34:28.902440 140202722101120 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0913 14:34:28.902595 140202722101120 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288\n",
            "I0913 14:34:28.902675 140202722101120 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
            "I0913 14:34:28.904201 140202722101120 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0913 14:34:28.920453 140202722101120 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0913 14:34:28.920572 140202722101120 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0913 14:34:29.699542 140202722101120 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0913 14:34:29.699718 140202722101120 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0913 14:34:30.112547 140202722101120 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0913 14:34:30.112716 140202722101120 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0913 14:34:30.490911 140202722101120 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0913 14:34:30.491087 140202722101120 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0913 14:34:31.453730 140202722101120 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0913 14:34:31.453966 140202722101120 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0913 14:34:32.759974 140202722101120 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0913 14:34:32.760206 140202722101120 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0913 14:34:34.111457 140202722101120 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0913 14:34:34.113872 140202722101120 efficientnet_model.py:143] round_filter input=320 output=512\n",
            "I0913 14:34:34.379333 140202722101120 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
            "I0913 14:34:34.411669 140202722101120 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0913 14:34:34.530993 140202722101120 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0913 14:34:34.531197 140202722101120 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
            "I0913 14:34:34.531300 140202722101120 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
            "I0913 14:34:34.535284 140202722101120 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0913 14:34:34.562227 140202722101120 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0913 14:34:34.562374 140202722101120 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0913 14:34:34.864624 140202722101120 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0913 14:34:34.864821 140202722101120 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0913 14:34:35.718241 140202722101120 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0913 14:34:35.718462 140202722101120 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0913 14:34:36.434655 140202722101120 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0913 14:34:36.434894 140202722101120 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0913 14:34:37.293595 140202722101120 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0913 14:34:37.293774 140202722101120 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0913 14:34:37.911144 140202722101120 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0913 14:34:37.911346 140202722101120 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0913 14:34:39.239992 140202722101120 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0913 14:34:39.240168 140202722101120 efficientnet_model.py:143] round_filter input=320 output=576\n",
            "I0913 14:34:39.472657 140202722101120 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
            "I0913 14:34:39.505141 140202722101120 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0913 14:34:39.609958 140202722101120 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0913 14:34:39.610169 140202722101120 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
            "I0913 14:34:39.610270 140202722101120 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
            "I0913 14:34:39.612110 140202722101120 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0913 14:34:39.630663 140202722101120 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0913 14:34:39.630845 140202722101120 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0913 14:34:39.899953 140202722101120 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0913 14:34:39.900139 140202722101120 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0913 14:34:40.465647 140202722101120 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0913 14:34:40.465825 140202722101120 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0913 14:34:41.011687 140202722101120 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0913 14:34:41.011873 140202722101120 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0913 14:34:41.819946 140202722101120 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0913 14:34:41.820139 140202722101120 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0913 14:34:42.625323 140202722101120 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0913 14:34:42.625715 140202722101120 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0913 14:34:43.658807 140202722101120 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0913 14:34:43.658982 140202722101120 efficientnet_model.py:143] round_filter input=320 output=640\n",
            "I0913 14:34:43.982492 140202722101120 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
            "I0913 14:34:44.012664 140202722101120 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 31.28s\n",
            "I0913 14:34:44.129004 140202722101120 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 31.28s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I0913 14:34:44.134648 140202722101120 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0913 14:34:44.136217 140202722101120 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0913 14:34:44.136668 140202722101120 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0913 14:34:44.138048 140202722101120 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0913 14:34:44.139486 140202722101120 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0913 14:34:44.139928 140202722101120 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0913 14:34:44.140895 140202722101120 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 36.602s\n",
            "\n",
            "OK (skipped=1)\n",
            "/content/UAVHRBuildingDetection\n"
          ]
        }
      ],
      "source": [
        "# Verify installation\n",
        "%cd /content/UAVHRBuildingDetection/Tensorflow/models/research/\n",
        "!python object_detection/builders/model_builder_tf2_test.py\n",
        "\n",
        "# return to content directory\n",
        "%cd /content/UAVHRBuildingDetection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDNCmFR1CnSt"
      },
      "source": [
        "Create directories for pretrained models and custom models in workspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMLy0Wx3Csxj"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(paths[\"pretrained_models\"]):\n",
        "  os.makedirs(paths[\"pretrained_models\"])\n",
        "\n",
        "if not os.path.exists(paths[\"custom_models\"]):\n",
        "  os.makedirs(paths[\"custom_models\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P267uD75lE2_"
      },
      "source": [
        "Install other python packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvHMyrW6lI4r",
        "outputId": "498178f5-1e45-4763-a15c-1a196357fa42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9657 sha256=9251b7fdc2e23d59da4f63db8d5ef0cfc8e7d0afc5f5e4a17995eae9c0b7f6ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.7/dist-packages (1.2.1)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from albumentations) (0.0.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations) (6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.7.3)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (4.6.0.66)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.21.6)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (0.18.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from qudida>=0.0.4->albumentations) (4.3.0)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from qudida>=0.0.4->albumentations) (1.0.2)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (3.5.3)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (9.2.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (1.3.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2021.11.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2.6.3)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2.9.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (4.37.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.16.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install wget\n",
        "!pip install albumentations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIUttk2BkFi-"
      },
      "source": [
        "# Download pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sLzYy5BkLg_",
        "outputId": "b9d2211a-5dd0-4f90-9c81-f632d9ce0575"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UAVHRBuildingDetection/Tensorflow/workspace/pretrained_model\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n",
            "/content/UAVHRBuildingDetection\n"
          ]
        }
      ],
      "source": [
        "import wget\n",
        "# download pretrained model\n",
        "%cd {paths[\"pretrained_models\"]}\n",
        "preModZipName = PRETRAINED_MODEL_NAME + \".tar.gz\"\n",
        "\n",
        "if not os.path.exists(preModZipName):\n",
        "  wget.download(PRETRAINED_MODEL_URL)\n",
        "\n",
        "if not os.path.exists(PRETRAINED_MODEL_NAME):\n",
        "  !tar -zxvf {PRETRAINED_MODEL_NAME + \".tar.gz\"}\n",
        "\n",
        "%cd {paths[\"github_repo\"]}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cleanup previous training files"
      ],
      "metadata": {
        "id": "5PjjoyyzONMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from shutil import rmtree\n",
        "if os.path.exists(paths[\"custom_model_dir\"]):\n",
        "  rmtree(paths[\"custom_model_dir\"])\n",
        "\n",
        "if os.path.exists(paths[\"images\"]):\n",
        "  rmtree(paths[\"images\"])"
      ],
      "metadata": {
        "id": "w8yTQtotORhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAlZZ0yXyoQ6"
      },
      "source": [
        "# Setup Training Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tHwGkWc66aC",
        "outputId": "ad30ab37-58ca-46d8-c258-e4fa4970ea15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UAVHRBuildingDetection\n"
          ]
        }
      ],
      "source": [
        "%cd {paths[\"github_repo\"]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pr3yoKq-LKr"
      },
      "source": [
        "Copy labelmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHbakWIG-ZGr"
      },
      "outputs": [],
      "source": [
        "from shutil import copyfile\n",
        "\n",
        "if not os.path.exists(os.path.join(paths[\"annotations\"], LABEL_MAP_NAME)):\n",
        "  copyfile(os.path.join(\"Dataset\",DATASET_REPO_NAME,LABEL_MAP_NAME), os.path.join(paths[\"annotations\"], LABEL_MAP_NAME))  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AbHg5y065SJ"
      },
      "source": [
        "Partition dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoXHbrWK7Ahf",
        "outputId": "12d43639-2a8a-494c-9bd5-b82effde1db1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UAVHRBuildingDetection\n",
            "Partitioning the images...\n",
            "Copying matching labels...\n",
            "Verifying Test partition...\n",
            "Test partition o.k. !\n",
            "Verifying Train partition...\n",
            "Train partition o.k. !\n"
          ]
        }
      ],
      "source": [
        "from Tensorflow.scripts.preprocessing.datasetPartitioning import partition \n",
        "\n",
        "imgTestPath = os.path.join(paths[\"images\"],\"test\")\n",
        "imgTrainPath = os.path.join(paths[\"images\"], \"train\")\n",
        "ratioTest = 0.25\n",
        "ratioValid = 0\n",
        "\n",
        "!pwd\n",
        "\n",
        "# Create partitioning if train and test directories do not exist\n",
        "if not os.path.exists(imgTestPath) or not os.path.exists(imgTrainPath):\n",
        "  partition(paths[\"dataset_images\"], paths[\"dataset_labels\"], paths[\"images\"], ratioTest, ratioValid, \"png\")\n",
        "\n",
        "# Or if the directories are empty\n",
        "elif not os.listdir(imgTestPath) or not os.listdir(imgTrainPath):\n",
        "  partition(paths[\"dataset_images\"], paths[\"dataset_labels\"], paths[\"images\"], ratioTest, ratioValid, \"png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbm5WYfKXiAN"
      },
      "source": [
        "perform data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eX6s2w8pXkjr"
      },
      "outputs": [],
      "source": [
        "from Tensorflow.scripts.preprocessing.dataAugmentation import augmentData\n",
        "import albumentations as alb\n",
        "\n",
        "nAugmentations = 30\n",
        "testPath = os.path.join(paths[\"images\"],\"test\")\n",
        "trainPath = os.path.join(paths[\"images\"], \"train\")\n",
        "validPath = os.path.join(paths[\"images\"], \"valid\")\n",
        "\n",
        "bboxParams = alb.BboxParams(format='pascal_voc', min_visibility=0.75)\n",
        "oAugmenter = alb.Compose([alb.RandomCrop(INPUT_DIMS[0],INPUT_DIMS[1]),\n",
        "                        alb.Affine(shear=[-2.5,2.5], rotate=[-2.5 ,2.5], fit_output=True, p=0.5), \n",
        "                        alb.Resize(INPUT_DIMS[0]+50,INPUT_DIMS[1]+50),\n",
        "                        alb.CenterCrop(INPUT_DIMS[0],INPUT_DIMS[1]),\n",
        "                        alb.ColorJitter(hue=0.1, brightness=0.5, saturation=0.5, p=0.5),\n",
        "                        alb.HorizontalFlip(p=0.25),\n",
        "                        alb.VerticalFlip(p=0.25)], bboxParams)\n",
        "\n",
        "# Augment Test data\n",
        "augmentData(oAugmenter, testPath, testPath, testPath, nAugmentations, \"png\")\n",
        "\n",
        "# Augment Train data\n",
        "augmentData(oAugmenter, trainPath, trainPath, trainPath, nAugmentations, \"png\")\n",
        "\n",
        "# Augment Validation data\n",
        "if os.path.exists(validPath):\n",
        "  augmentData(oAugmenter, validPath, validPath, validPath, nAugmentations, \"png\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wv7HxrtMyyMi"
      },
      "source": [
        "Create tfrecord files for training and test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktavbHFHy3Z1",
        "outputId": "08da2bd3-be5f-4af9-c7ba-c11ef16cdf95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully created the TFRecord file: //content/UAVHRBuildingDetection/Tensorflow/workspace/annotations/train.record\n",
            "Successfully created the TFRecord file: //content/UAVHRBuildingDetection/Tensorflow/workspace/annotations/test.record\n"
          ]
        }
      ],
      "source": [
        "#if not os.path.exists(os.path.join(paths[\"annotations\"], \"train.record\")):\n",
        "!python {os.path.join(paths[\"scripts_pre\"],\"generate_tfrecord.py\")} -x {os.path.join(paths[\"images\"],\"train\")} -l {os.path.join(paths[\"annotations\"], LABEL_MAP_NAME)} -o {os.path.join(paths[\"annotations\"], \"train.record\" )} -i {os.path.join(paths[\"images\"],\"train\")}\n",
        "\n",
        "#if not os.path.exists(os.path.join(paths[\"annotations\"], \"test.record\")):\n",
        "!python {os.path.join(paths[\"scripts_pre\"],\"generate_tfrecord.py\")} -x {os.path.join(paths[\"images\"],\"test\")} -l {os.path.join(paths[\"annotations\"], LABEL_MAP_NAME)} -o {os.path.join(paths[\"annotations\"], \"test.record\" )} -i {os.path.join(paths[\"images\"],\"test\")}\n",
        "\n",
        "#if not os.path.exists(os.path.join(paths[\"annotations\"], \"test.record\")):\n",
        "#!python {os.path.join(paths[\"scripts_pre\"],\"generate_tfrecord.py\")} -x {os.path.join(paths[\"images\"],\"valid\")} -l {os.path.join(paths[\"annotations\"], LABEL_MAP_NAME)} -o {os.path.join(paths[\"annotations\"], \"valid.record\" )} -i {os.path.join(paths[\"images\"],\"valid\")}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEWJr8-M9qBB"
      },
      "source": [
        "copy and adapt pipline config if necessary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMHo2Mfp9umt"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from google.protobuf import text_format\n",
        "from shutil import rmtree\n",
        "\n",
        "if not os.path.exists(paths[\"custom_model_dir\"] ):\n",
        "  os.makedirs(paths[\"custom_model_dir\"])\n",
        "\n",
        "if not os.path.exists(paths[\"custom_model_config\"]):\n",
        "  # Copy Config if necessary\n",
        "  if os.name == \"posix\":\n",
        "    !cp {os.path.join(paths[\"pretrained_models\"], PRETRAINED_MODEL_NAME,\"pipeline.config\")} {paths[\"custom_model_config\"]}\n",
        "  elif os.name == \"nt\":\n",
        "    !copy {os.path.join(paths[\"pretrained_models\"], PRETRAINED_MODEL_NAME,\"pipeline.config\")} {paths[\"custom_model_config\"]}\n",
        "  \n",
        "\n",
        "  # adapt config\n",
        "  config = config_util.get_configs_from_pipeline_file(paths[\"custom_model_config\"])\n",
        "\n",
        "  pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "  with tf.io.gfile.GFile(paths['custom_model_config'], \"r\") as f:                                                                                                                                                                                                                     \n",
        "      proto_str = f.read()                                                                                                                                                                                                                                          \n",
        "      text_format.Merge(proto_str, pipeline_config)  \n",
        "\n",
        "  pipeline_config.model.ssd.image_resizer.fixed_shape_resizer.height = INPUT_DIMS[0]\n",
        "  pipeline_config.model.ssd.image_resizer.fixed_shape_resizer.width = INPUT_DIMS[1]\n",
        "  pipeline_config.model.ssd.num_classes = NOF_CLASSES\n",
        "  pipeline_config.train_config.batch_size = BATCH_SIZE\n",
        "  pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths[\"pretrained_models\"], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
        "  pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
        "  pipeline_config.train_input_reader.label_map_path= os.path.join(paths[\"annotations\"],LABEL_MAP_NAME)\n",
        "  pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths[\"annotations\"], 'train.record')]\n",
        "  pipeline_config.eval_input_reader[0].label_map_path = os.path.join(paths[\"annotations\"],LABEL_MAP_NAME)\n",
        "  pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths[\"annotations\"], 'test.record')]\n",
        "\n",
        "  pipeline_config.eval_config.num_visualizations=100\n",
        "  pipeline_config.eval_config.max_num_boxes_to_visualize = 100\n",
        "  pipeline_config.eval_config.num_examples = len(os.listdir(os.path.join(paths[\"images\"],\"test\")))\n",
        "  pipeline_config.eval_config.eval_interval_secs = 30\n",
        "\n",
        "\n",
        "\n",
        "  config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
        "  with tf.io.gfile.GFile(paths[\"custom_model_config\"], \"wb\") as f:                                                                                                                                                                                                                     \n",
        "      f.write(config_text)   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpTdLaJ5O59u"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCP97JHVO-56",
        "outputId": "50d47e13-456a-47cd-9c04-32cb8127a3d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0913 19:17:04.239578 139874090080128 model_lib_v2.py:1090] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n",
            "I0913 19:17:04.239844 139874090080128 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0913 19:17:04.240215 139874090080128 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0913 19:17:04.240345 139874090080128 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0913 19:17:04.240477 139874090080128 model_lib_v2.py:1110] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "2022-09-13 19:17:05.723126: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2022-09-13 19:17:05.732773: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I0913 19:17:05.734594 140213675833216 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 20000\n",
            "I0913 19:17:05.739784 140213675833216 config_util.py:552] Maybe overwriting train_steps: 20000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0913 19:17:05.739962 140213675833216 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Reading unweighted datasets: ['//content/UAVHRBuildingDetection/Tensorflow/workspace/annotations/test.record']\n",
            "I0913 19:17:05.780692 139874090080128 dataset_builder.py:162] Reading unweighted datasets: ['//content/UAVHRBuildingDetection/Tensorflow/workspace/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['//content/UAVHRBuildingDetection/Tensorflow/workspace/annotations/test.record']\n",
            "I0913 19:17:05.780973 139874090080128 dataset_builder.py:79] Reading record datasets for input file: ['//content/UAVHRBuildingDetection/Tensorflow/workspace/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0913 19:17:05.781090 139874090080128 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0913 19:17:05.781166 139874090080128 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0913 19:17:05.783495 139874090080128 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0913 19:17:05.784502 140213675833216 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['//content/UAVHRBuildingDetection/Tensorflow/workspace/annotations/train.record']\n",
            "I0913 19:17:05.789664 140213675833216 dataset_builder.py:162] Reading unweighted datasets: ['//content/UAVHRBuildingDetection/Tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['//content/UAVHRBuildingDetection/Tensorflow/workspace/annotations/train.record']\n",
            "I0913 19:17:05.789879 140213675833216 dataset_builder.py:79] Reading record datasets for input file: ['//content/UAVHRBuildingDetection/Tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0913 19:17:05.790003 140213675833216 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0913 19:17:05.790094 140213675833216 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0913 19:17:05.793401 140213675833216 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0913 19:17:05.820253 139874090080128 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0913 19:17:05.821852 140213675833216 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0913 19:17:12.359880 139874090080128 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0913 19:17:14.274221 139874090080128 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0913 19:17:17.562643 140213675833216 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "INFO:tensorflow:Waiting for new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2\n",
            "I0913 19:17:18.353396 139874090080128 checkpoint_utils.py:136] Waiting for new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0913 19:17:20.724015 140213675833216 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0913 19:17:22.179417 140213675833216 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0913 19:17:53.577061 140213675833216 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0913 19:17:53.578502 140213675833216 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0913 19:17:53.581427 140213675833216 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0913 19:17:53.582334 140213675833216 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0913 19:17:53.584341 140213675833216 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0913 19:17:53.585237 140213675833216 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0913 19:17:53.587226 140213675833216 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0913 19:17:53.588141 140213675833216 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0913 19:17:53.590184 140213675833216 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0913 19:17:53.591048 140213675833216 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W0913 19:17:54.184971 140208707393280 deprecation.py:560] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "INFO:tensorflow:Found new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-1\n",
            "I0913 19:17:54.395099 139874090080128 checkpoint_utils.py:145] Found new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-1\n",
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0913 19:18:31.817806 139874090080128 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Finished eval step 0\n",
            "I0913 19:18:31.833688 139874090080128 model_lib_v2.py:966] Finished eval step 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W0913 19:18:32.036530 139874090080128 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "INFO:tensorflow:Finished eval step 100\n",
            "I0913 19:18:52.534007 139874090080128 model_lib_v2.py:966] Finished eval step 100\n",
            "INFO:tensorflow:Finished eval step 200\n",
            "I0913 19:19:00.235745 139874090080128 model_lib_v2.py:966] Finished eval step 200\n",
            "INFO:tensorflow:Finished eval step 300\n",
            "I0913 19:19:11.866288 139874090080128 model_lib_v2.py:966] Finished eval step 300\n",
            "INFO:tensorflow:Finished eval step 400\n",
            "I0913 19:19:24.149557 139874090080128 model_lib_v2.py:966] Finished eval step 400\n",
            "INFO:tensorflow:Step 100 per-step time 1.011s\n",
            "I0913 19:19:34.976647 140213675833216 model_lib_v2.py:707] Step 100 per-step time 1.011s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.36708796,\n",
            " 'Loss/localization_loss': 0.49506265,\n",
            " 'Loss/regularization_loss': 0.15354985,\n",
            " 'Loss/total_loss': 1.0157005,\n",
            " 'learning_rate': 0.0319994}\n",
            "I0913 19:19:34.977046 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.36708796,\n",
            " 'Loss/localization_loss': 0.49506265,\n",
            " 'Loss/regularization_loss': 0.15354985,\n",
            " 'Loss/total_loss': 1.0157005,\n",
            " 'learning_rate': 0.0319994}\n",
            "INFO:tensorflow:Finished eval step 500\n",
            "I0913 19:19:36.807570 139874090080128 model_lib_v2.py:966] Finished eval step 500\n",
            "INFO:tensorflow:Finished eval step 600\n",
            "I0913 19:19:49.270340 139874090080128 model_lib_v2.py:966] Finished eval step 600\n",
            "INFO:tensorflow:Finished eval step 700\n",
            "I0913 19:20:01.596425 139874090080128 model_lib_v2.py:966] Finished eval step 700\n",
            "INFO:tensorflow:Step 200 per-step time 0.347s\n",
            "I0913 19:20:09.631460 140213675833216 model_lib_v2.py:707] Step 200 per-step time 0.347s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.24004419,\n",
            " 'Loss/localization_loss': 0.25124276,\n",
            " 'Loss/regularization_loss': 0.15334658,\n",
            " 'Loss/total_loss': 0.64463353,\n",
            " 'learning_rate': 0.0373328}\n",
            "I0913 19:20:09.631828 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.24004419,\n",
            " 'Loss/localization_loss': 0.25124276,\n",
            " 'Loss/regularization_loss': 0.15334658,\n",
            " 'Loss/total_loss': 0.64463353,\n",
            " 'learning_rate': 0.0373328}\n",
            "INFO:tensorflow:Finished eval step 800\n",
            "I0913 19:20:16.661218 139874090080128 model_lib_v2.py:966] Finished eval step 800\n",
            "INFO:tensorflow:Finished eval step 900\n",
            "I0913 19:20:29.935552 139874090080128 model_lib_v2.py:966] Finished eval step 900\n",
            "INFO:tensorflow:Finished eval step 1000\n",
            "I0913 19:20:41.962000 139874090080128 model_lib_v2.py:966] Finished eval step 1000\n",
            "INFO:tensorflow:Step 300 per-step time 0.358s\n",
            "I0913 19:20:45.467802 140213675833216 model_lib_v2.py:707] Step 300 per-step time 0.358s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2626005,\n",
            " 'Loss/localization_loss': 0.22839417,\n",
            " 'Loss/regularization_loss': 0.15308982,\n",
            " 'Loss/total_loss': 0.6440845,\n",
            " 'learning_rate': 0.0426662}\n",
            "I0913 19:20:45.468254 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.2626005,\n",
            " 'Loss/localization_loss': 0.22839417,\n",
            " 'Loss/regularization_loss': 0.15308982,\n",
            " 'Loss/total_loss': 0.6440845,\n",
            " 'learning_rate': 0.0426662}\n",
            "INFO:tensorflow:Finished eval step 1100\n",
            "I0913 19:20:53.909381 139874090080128 model_lib_v2.py:966] Finished eval step 1100\n",
            "INFO:tensorflow:Finished eval step 1200\n",
            "I0913 19:21:05.962806 139874090080128 model_lib_v2.py:966] Finished eval step 1200\n",
            "INFO:tensorflow:Finished eval step 1300\n",
            "I0913 19:21:18.111973 139874090080128 model_lib_v2.py:966] Finished eval step 1300\n",
            "INFO:tensorflow:Step 400 per-step time 0.349s\n",
            "I0913 19:21:20.323669 140213675833216 model_lib_v2.py:707] Step 400 per-step time 0.349s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1984617,\n",
            " 'Loss/localization_loss': 0.20490474,\n",
            " 'Loss/regularization_loss': 0.15286815,\n",
            " 'Loss/total_loss': 0.5562346,\n",
            " 'learning_rate': 0.047999598}\n",
            "I0913 19:21:20.324079 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.1984617,\n",
            " 'Loss/localization_loss': 0.20490474,\n",
            " 'Loss/regularization_loss': 0.15286815,\n",
            " 'Loss/total_loss': 0.5562346,\n",
            " 'learning_rate': 0.047999598}\n",
            "INFO:tensorflow:Finished eval step 1400\n",
            "I0913 19:21:30.078991 139874090080128 model_lib_v2.py:966] Finished eval step 1400\n",
            "INFO:tensorflow:Finished eval step 1500\n",
            "I0913 19:21:42.530092 139874090080128 model_lib_v2.py:966] Finished eval step 1500\n",
            "INFO:tensorflow:Step 500 per-step time 0.345s\n",
            "I0913 19:21:54.843425 140213675833216 model_lib_v2.py:707] Step 500 per-step time 0.345s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.21167417,\n",
            " 'Loss/localization_loss': 0.19813736,\n",
            " 'Loss/regularization_loss': 0.15265262,\n",
            " 'Loss/total_loss': 0.5624641,\n",
            " 'learning_rate': 0.053333}\n",
            "I0913 19:21:54.843719 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.21167417,\n",
            " 'Loss/localization_loss': 0.19813736,\n",
            " 'Loss/regularization_loss': 0.15265262,\n",
            " 'Loss/total_loss': 0.5624641,\n",
            " 'learning_rate': 0.053333}\n",
            "INFO:tensorflow:Performing evaluation on 1572 images.\n",
            "I0913 19:22:16.731082 139874090080128 coco_evaluation.py:293] Performing evaluation on 1572 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0913 19:22:16.752949 139874090080128 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.18s)\n",
            "I0913 19:22:16.934219 139874090080128 coco_tools.py:138] DONE (t=0.18s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "INFO:tensorflow:Step 600 per-step time 0.304s\n",
            "I0913 19:22:25.265557 140213675833216 model_lib_v2.py:707] Step 600 per-step time 0.304s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.17210138,\n",
            " 'Loss/localization_loss': 0.14822416,\n",
            " 'Loss/regularization_loss': 0.15233879,\n",
            " 'Loss/total_loss': 0.47266436,\n",
            " 'learning_rate': 0.0586664}\n",
            "I0913 19:22:25.265953 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.17210138,\n",
            " 'Loss/localization_loss': 0.14822416,\n",
            " 'Loss/regularization_loss': 0.15233879,\n",
            " 'Loss/total_loss': 0.47266436,\n",
            " 'learning_rate': 0.0586664}\n",
            "INFO:tensorflow:Step 700 per-step time 0.301s\n",
            "I0913 19:22:55.401152 140213675833216 model_lib_v2.py:707] Step 700 per-step time 0.301s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.21502131,\n",
            " 'Loss/localization_loss': 0.17685102,\n",
            " 'Loss/regularization_loss': 0.15207672,\n",
            " 'Loss/total_loss': 0.54394907,\n",
            " 'learning_rate': 0.0639998}\n",
            "I0913 19:22:55.401564 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.21502131,\n",
            " 'Loss/localization_loss': 0.17685102,\n",
            " 'Loss/regularization_loss': 0.15207672,\n",
            " 'Loss/total_loss': 0.54394907,\n",
            " 'learning_rate': 0.0639998}\n",
            "INFO:tensorflow:Step 800 per-step time 0.305s\n",
            "I0913 19:23:25.942567 140213675833216 model_lib_v2.py:707] Step 800 per-step time 0.305s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.14955236,\n",
            " 'Loss/localization_loss': 0.114758134,\n",
            " 'Loss/regularization_loss': 0.15188219,\n",
            " 'Loss/total_loss': 0.41619265,\n",
            " 'learning_rate': 0.069333196}\n",
            "I0913 19:23:25.942925 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.14955236,\n",
            " 'Loss/localization_loss': 0.114758134,\n",
            " 'Loss/regularization_loss': 0.15188219,\n",
            " 'Loss/total_loss': 0.41619265,\n",
            " 'learning_rate': 0.069333196}\n",
            "DONE (t=86.37s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=3.53s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.001\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.010\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.018\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.005\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            "INFO:tensorflow:Eval metrics at step 0\n",
            "I0913 19:23:47.118794 139874090080128 model_lib_v2.py:1015] Eval metrics at step 0\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.000035\n",
            "I0913 19:23:47.127343 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.000035\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.000091\n",
            "I0913 19:23:47.132790 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.000091\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.000028\n",
            "I0913 19:23:47.137454 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.000028\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.000056\n",
            "I0913 19:23:47.142065 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): 0.000056\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.000034\n",
            "I0913 19:23:47.146787 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): 0.000034\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.000000\n",
            "I0913 19:23:47.151209 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): 0.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.000211\n",
            "I0913 19:23:47.155856 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.000211\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.001010\n",
            "I0913 19:23:47.160287 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.001010\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.009855\n",
            "I0913 19:23:47.164610 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.009855\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.018453\n",
            "I0913 19:23:47.168245 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): 0.018453\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.004583\n",
            "I0913 19:23:47.180812 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.004583\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.000000\n",
            "I0913 19:23:47.186044 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): 0.000000\n",
            "INFO:tensorflow:\t+ Loss/localization_loss: 0.711596\n",
            "I0913 19:23:47.192884 139874090080128 model_lib_v2.py:1018] \t+ Loss/localization_loss: 0.711596\n",
            "INFO:tensorflow:\t+ Loss/classification_loss: 1.130120\n",
            "I0913 19:23:47.200332 139874090080128 model_lib_v2.py:1018] \t+ Loss/classification_loss: 1.130120\n",
            "INFO:tensorflow:\t+ Loss/regularization_loss: 0.153446\n",
            "I0913 19:23:47.208541 139874090080128 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.153446\n",
            "INFO:tensorflow:\t+ Loss/total_loss: 1.995162\n",
            "I0913 19:23:47.225621 139874090080128 model_lib_v2.py:1018] \t+ Loss/total_loss: 1.995162\n",
            "INFO:tensorflow:Waiting for new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2\n",
            "I0913 19:23:47.631473 139874090080128 checkpoint_utils.py:136] Waiting for new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2\n",
            "INFO:tensorflow:Step 900 per-step time 0.312s\n",
            "I0913 19:23:57.158082 140213675833216 model_lib_v2.py:707] Step 900 per-step time 0.312s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.17280526,\n",
            " 'Loss/localization_loss': 0.15227069,\n",
            " 'Loss/regularization_loss': 0.15151878,\n",
            " 'Loss/total_loss': 0.47659475,\n",
            " 'learning_rate': 0.074666604}\n",
            "I0913 19:23:57.158380 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.17280526,\n",
            " 'Loss/localization_loss': 0.15227069,\n",
            " 'Loss/regularization_loss': 0.15151878,\n",
            " 'Loss/total_loss': 0.47659475,\n",
            " 'learning_rate': 0.074666604}\n",
            "INFO:tensorflow:Step 1000 per-step time 0.305s\n",
            "I0913 19:24:27.609427 140213675833216 model_lib_v2.py:707] Step 1000 per-step time 0.305s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15130863,\n",
            " 'Loss/localization_loss': 0.09115044,\n",
            " 'Loss/regularization_loss': 0.15118006,\n",
            " 'Loss/total_loss': 0.39363912,\n",
            " 'learning_rate': 0.08}\n",
            "I0913 19:24:27.609770 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.15130863,\n",
            " 'Loss/localization_loss': 0.09115044,\n",
            " 'Loss/regularization_loss': 0.15118006,\n",
            " 'Loss/total_loss': 0.39363912,\n",
            " 'learning_rate': 0.08}\n",
            "INFO:tensorflow:Found new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-2\n",
            "I0913 19:24:28.687081 139874090080128 checkpoint_utils.py:145] Found new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-2\n",
            "INFO:tensorflow:Finished eval step 0\n",
            "I0913 19:24:39.857880 139874090080128 model_lib_v2.py:966] Finished eval step 0\n",
            "INFO:tensorflow:Step 1100 per-step time 0.324s\n",
            "I0913 19:25:00.030480 140213675833216 model_lib_v2.py:707] Step 1100 per-step time 0.324s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15439288,\n",
            " 'Loss/localization_loss': 0.1360361,\n",
            " 'Loss/regularization_loss': 0.15097879,\n",
            " 'Loss/total_loss': 0.4414078,\n",
            " 'learning_rate': 0.07999918}\n",
            "I0913 19:25:00.030879 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.15439288,\n",
            " 'Loss/localization_loss': 0.1360361,\n",
            " 'Loss/regularization_loss': 0.15097879,\n",
            " 'Loss/total_loss': 0.4414078,\n",
            " 'learning_rate': 0.07999918}\n",
            "INFO:tensorflow:Finished eval step 100\n",
            "I0913 19:25:15.451751 139874090080128 model_lib_v2.py:966] Finished eval step 100\n",
            "INFO:tensorflow:Finished eval step 200\n",
            "I0913 19:25:27.795105 139874090080128 model_lib_v2.py:966] Finished eval step 200\n",
            "INFO:tensorflow:Step 1200 per-step time 0.340s\n",
            "I0913 19:25:34.025953 140213675833216 model_lib_v2.py:707] Step 1200 per-step time 0.340s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18158866,\n",
            " 'Loss/localization_loss': 0.11412937,\n",
            " 'Loss/regularization_loss': 0.15058269,\n",
            " 'Loss/total_loss': 0.44630075,\n",
            " 'learning_rate': 0.079996705}\n",
            "I0913 19:25:34.026353 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.18158866,\n",
            " 'Loss/localization_loss': 0.11412937,\n",
            " 'Loss/regularization_loss': 0.15058269,\n",
            " 'Loss/total_loss': 0.44630075,\n",
            " 'learning_rate': 0.079996705}\n",
            "INFO:tensorflow:Finished eval step 300\n",
            "I0913 19:25:40.064928 139874090080128 model_lib_v2.py:966] Finished eval step 300\n",
            "INFO:tensorflow:Finished eval step 400\n",
            "I0913 19:25:52.224819 139874090080128 model_lib_v2.py:966] Finished eval step 400\n",
            "INFO:tensorflow:Finished eval step 500\n",
            "I0913 19:26:04.799466 139874090080128 model_lib_v2.py:966] Finished eval step 500\n",
            "INFO:tensorflow:Step 1300 per-step time 0.350s\n",
            "I0913 19:26:08.997563 140213675833216 model_lib_v2.py:707] Step 1300 per-step time 0.350s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13020965,\n",
            " 'Loss/localization_loss': 0.07644486,\n",
            " 'Loss/regularization_loss': 0.15016468,\n",
            " 'Loss/total_loss': 0.3568192,\n",
            " 'learning_rate': 0.0799926}\n",
            "I0913 19:26:08.997923 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.13020965,\n",
            " 'Loss/localization_loss': 0.07644486,\n",
            " 'Loss/regularization_loss': 0.15016468,\n",
            " 'Loss/total_loss': 0.3568192,\n",
            " 'learning_rate': 0.0799926}\n",
            "INFO:tensorflow:Finished eval step 600\n",
            "I0913 19:26:17.159848 139874090080128 model_lib_v2.py:966] Finished eval step 600\n",
            "INFO:tensorflow:Finished eval step 700\n",
            "I0913 19:26:29.548129 139874090080128 model_lib_v2.py:966] Finished eval step 700\n",
            "INFO:tensorflow:Finished eval step 800\n",
            "I0913 19:26:42.941555 139874090080128 model_lib_v2.py:966] Finished eval step 800\n",
            "INFO:tensorflow:Step 1400 per-step time 0.356s\n",
            "I0913 19:26:44.601154 140213675833216 model_lib_v2.py:707] Step 1400 per-step time 0.356s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.14473474,\n",
            " 'Loss/localization_loss': 0.11015588,\n",
            " 'Loss/regularization_loss': 0.1498039,\n",
            " 'Loss/total_loss': 0.40469453,\n",
            " 'learning_rate': 0.07998685}\n",
            "I0913 19:26:44.601596 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.14473474,\n",
            " 'Loss/localization_loss': 0.11015588,\n",
            " 'Loss/regularization_loss': 0.1498039,\n",
            " 'Loss/total_loss': 0.40469453,\n",
            " 'learning_rate': 0.07998685}\n",
            "INFO:tensorflow:Finished eval step 900\n",
            "I0913 19:26:57.144241 139874090080128 model_lib_v2.py:966] Finished eval step 900\n",
            "INFO:tensorflow:Finished eval step 1000\n",
            "I0913 19:27:09.239380 139874090080128 model_lib_v2.py:966] Finished eval step 1000\n",
            "INFO:tensorflow:Step 1500 per-step time 0.359s\n",
            "I0913 19:27:20.472186 140213675833216 model_lib_v2.py:707] Step 1500 per-step time 0.359s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13510472,\n",
            " 'Loss/localization_loss': 0.10124128,\n",
            " 'Loss/regularization_loss': 0.14932182,\n",
            " 'Loss/total_loss': 0.38566783,\n",
            " 'learning_rate': 0.07997945}\n",
            "I0913 19:27:20.473073 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.13510472,\n",
            " 'Loss/localization_loss': 0.10124128,\n",
            " 'Loss/regularization_loss': 0.14932182,\n",
            " 'Loss/total_loss': 0.38566783,\n",
            " 'learning_rate': 0.07997945}\n",
            "INFO:tensorflow:Finished eval step 1100\n",
            "I0913 19:27:21.375242 139874090080128 model_lib_v2.py:966] Finished eval step 1100\n",
            "INFO:tensorflow:Finished eval step 1200\n",
            "I0913 19:27:34.121893 139874090080128 model_lib_v2.py:966] Finished eval step 1200\n",
            "INFO:tensorflow:Finished eval step 1300\n",
            "I0913 19:27:46.537140 139874090080128 model_lib_v2.py:966] Finished eval step 1300\n",
            "INFO:tensorflow:Step 1600 per-step time 0.353s\n",
            "I0913 19:27:55.807252 140213675833216 model_lib_v2.py:707] Step 1600 per-step time 0.353s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1573862,\n",
            " 'Loss/localization_loss': 0.11618082,\n",
            " 'Loss/regularization_loss': 0.1488798,\n",
            " 'Loss/total_loss': 0.42244682,\n",
            " 'learning_rate': 0.079970405}\n",
            "I0913 19:27:55.807621 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.1573862,\n",
            " 'Loss/localization_loss': 0.11618082,\n",
            " 'Loss/regularization_loss': 0.1488798,\n",
            " 'Loss/total_loss': 0.42244682,\n",
            " 'learning_rate': 0.079970405}\n",
            "INFO:tensorflow:Finished eval step 1400\n",
            "I0913 19:27:58.668751 139874090080128 model_lib_v2.py:966] Finished eval step 1400\n",
            "INFO:tensorflow:Finished eval step 1500\n",
            "I0913 19:28:11.207262 139874090080128 model_lib_v2.py:966] Finished eval step 1500\n",
            "INFO:tensorflow:Step 1700 per-step time 0.336s\n",
            "I0913 19:28:29.380412 140213675833216 model_lib_v2.py:707] Step 1700 per-step time 0.336s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13503967,\n",
            " 'Loss/localization_loss': 0.09897149,\n",
            " 'Loss/regularization_loss': 0.14847094,\n",
            " 'Loss/total_loss': 0.3824821,\n",
            " 'learning_rate': 0.07995972}\n",
            "I0913 19:28:29.380745 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.13503967,\n",
            " 'Loss/localization_loss': 0.09897149,\n",
            " 'Loss/regularization_loss': 0.14847094,\n",
            " 'Loss/total_loss': 0.3824821,\n",
            " 'learning_rate': 0.07995972}\n",
            "INFO:tensorflow:Performing evaluation on 1572 images.\n",
            "I0913 19:28:53.235220 139874090080128 coco_evaluation.py:293] Performing evaluation on 1572 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0913 19:28:53.252979 139874090080128 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.15s)\n",
            "I0913 19:28:53.408163 139874090080128 coco_tools.py:138] DONE (t=0.15s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "INFO:tensorflow:Step 1800 per-step time 0.303s\n",
            "I0913 19:28:59.639478 140213675833216 model_lib_v2.py:707] Step 1800 per-step time 0.303s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12262593,\n",
            " 'Loss/localization_loss': 0.077843085,\n",
            " 'Loss/regularization_loss': 0.14802822,\n",
            " 'Loss/total_loss': 0.34849724,\n",
            " 'learning_rate': 0.0799474}\n",
            "I0913 19:28:59.639846 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.12262593,\n",
            " 'Loss/localization_loss': 0.077843085,\n",
            " 'Loss/regularization_loss': 0.14802822,\n",
            " 'Loss/total_loss': 0.34849724,\n",
            " 'learning_rate': 0.0799474}\n",
            "INFO:tensorflow:Step 1900 per-step time 0.303s\n",
            "I0913 19:29:29.936265 140213675833216 model_lib_v2.py:707] Step 1900 per-step time 0.303s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13247068,\n",
            " 'Loss/localization_loss': 0.10154036,\n",
            " 'Loss/regularization_loss': 0.1474926,\n",
            " 'Loss/total_loss': 0.38150364,\n",
            " 'learning_rate': 0.07993342}\n",
            "I0913 19:29:29.937460 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.13247068,\n",
            " 'Loss/localization_loss': 0.10154036,\n",
            " 'Loss/regularization_loss': 0.1474926,\n",
            " 'Loss/total_loss': 0.38150364,\n",
            " 'learning_rate': 0.07993342}\n",
            "INFO:tensorflow:Step 2000 per-step time 0.308s\n",
            "I0913 19:30:00.707974 140213675833216 model_lib_v2.py:707] Step 2000 per-step time 0.308s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11235971,\n",
            " 'Loss/localization_loss': 0.061118454,\n",
            " 'Loss/regularization_loss': 0.146978,\n",
            " 'Loss/total_loss': 0.32045615,\n",
            " 'learning_rate': 0.07991781}\n",
            "I0913 19:30:00.708344 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.11235971,\n",
            " 'Loss/localization_loss': 0.061118454,\n",
            " 'Loss/regularization_loss': 0.146978,\n",
            " 'Loss/total_loss': 0.32045615,\n",
            " 'learning_rate': 0.07991781}\n",
            "DONE (t=81.04s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=3.10s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.156\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.395\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.077\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.147\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.212\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.445\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.037\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.189\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.374\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.260\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.442\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.583\n",
            "INFO:tensorflow:Eval metrics at step 1000\n",
            "I0913 19:30:17.884090 139874090080128 model_lib_v2.py:1015] Eval metrics at step 1000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.156369\n",
            "I0913 19:30:17.890297 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.156369\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.394684\n",
            "I0913 19:30:17.896094 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.394684\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.076868\n",
            "I0913 19:30:17.900727 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.076868\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.146897\n",
            "I0913 19:30:17.905549 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): 0.146897\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.211831\n",
            "I0913 19:30:17.910050 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): 0.211831\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.444618\n",
            "I0913 19:30:17.914672 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): 0.444618\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.036855\n",
            "I0913 19:30:17.919229 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.036855\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.189493\n",
            "I0913 19:30:17.923888 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.189493\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.374496\n",
            "I0913 19:30:17.928655 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.374496\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.260245\n",
            "I0913 19:30:17.934149 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): 0.260245\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.442028\n",
            "I0913 19:30:17.940013 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.442028\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.582609\n",
            "I0913 19:30:17.944631 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): 0.582609\n",
            "INFO:tensorflow:\t+ Loss/localization_loss: 0.408939\n",
            "I0913 19:30:17.946879 139874090080128 model_lib_v2.py:1018] \t+ Loss/localization_loss: 0.408939\n",
            "INFO:tensorflow:\t+ Loss/classification_loss: 0.665145\n",
            "I0913 19:30:17.949256 139874090080128 model_lib_v2.py:1018] \t+ Loss/classification_loss: 0.665145\n",
            "INFO:tensorflow:\t+ Loss/regularization_loss: 0.151177\n",
            "I0913 19:30:17.951586 139874090080128 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.151177\n",
            "INFO:tensorflow:\t+ Loss/total_loss: 1.225260\n",
            "I0913 19:30:17.953910 139874090080128 model_lib_v2.py:1018] \t+ Loss/total_loss: 1.225260\n",
            "INFO:tensorflow:Waiting for new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2\n",
            "I0913 19:30:18.246160 139874090080128 checkpoint_utils.py:136] Waiting for new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2\n",
            "INFO:tensorflow:Found new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-3\n",
            "I0913 19:30:18.247231 139874090080128 checkpoint_utils.py:145] Found new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-3\n",
            "INFO:tensorflow:Finished eval step 0\n",
            "I0913 19:30:28.835925 139874090080128 model_lib_v2.py:966] Finished eval step 0\n",
            "INFO:tensorflow:Step 2100 per-step time 0.330s\n",
            "I0913 19:30:33.701213 140213675833216 model_lib_v2.py:707] Step 2100 per-step time 0.330s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12019164,\n",
            " 'Loss/localization_loss': 0.07854411,\n",
            " 'Loss/regularization_loss': 0.14651597,\n",
            " 'Loss/total_loss': 0.3452517,\n",
            " 'learning_rate': 0.07990056}\n",
            "I0913 19:30:33.701611 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.12019164,\n",
            " 'Loss/localization_loss': 0.07854411,\n",
            " 'Loss/regularization_loss': 0.14651597,\n",
            " 'Loss/total_loss': 0.3452517,\n",
            " 'learning_rate': 0.07990056}\n",
            "INFO:tensorflow:Finished eval step 100\n",
            "I0913 19:31:04.026305 139874090080128 model_lib_v2.py:966] Finished eval step 100\n",
            "INFO:tensorflow:Step 2200 per-step time 0.324s\n",
            "I0913 19:31:06.049996 140213675833216 model_lib_v2.py:707] Step 2200 per-step time 0.324s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.14131723,\n",
            " 'Loss/localization_loss': 0.089522906,\n",
            " 'Loss/regularization_loss': 0.14596291,\n",
            " 'Loss/total_loss': 0.37680304,\n",
            " 'learning_rate': 0.07988167}\n",
            "I0913 19:31:06.050345 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.14131723,\n",
            " 'Loss/localization_loss': 0.089522906,\n",
            " 'Loss/regularization_loss': 0.14596291,\n",
            " 'Loss/total_loss': 0.37680304,\n",
            " 'learning_rate': 0.07988167}\n",
            "INFO:tensorflow:Finished eval step 200\n",
            "I0913 19:31:16.859305 139874090080128 model_lib_v2.py:966] Finished eval step 200\n",
            "INFO:tensorflow:Finished eval step 300\n",
            "I0913 19:31:29.320859 139874090080128 model_lib_v2.py:966] Finished eval step 300\n",
            "INFO:tensorflow:Step 2300 per-step time 0.349s\n",
            "I0913 19:31:40.944652 140213675833216 model_lib_v2.py:707] Step 2300 per-step time 0.349s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10952191,\n",
            " 'Loss/localization_loss': 0.061183196,\n",
            " 'Loss/regularization_loss': 0.14546578,\n",
            " 'Loss/total_loss': 0.31617087,\n",
            " 'learning_rate': 0.07986114}\n",
            "I0913 19:31:40.945027 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.10952191,\n",
            " 'Loss/localization_loss': 0.061183196,\n",
            " 'Loss/regularization_loss': 0.14546578,\n",
            " 'Loss/total_loss': 0.31617087,\n",
            " 'learning_rate': 0.07986114}\n",
            "INFO:tensorflow:Finished eval step 400\n",
            "I0913 19:31:41.630060 139874090080128 model_lib_v2.py:966] Finished eval step 400\n",
            "INFO:tensorflow:Finished eval step 500\n",
            "I0913 19:31:53.783143 139874090080128 model_lib_v2.py:966] Finished eval step 500\n",
            "INFO:tensorflow:Finished eval step 600\n",
            "I0913 19:32:06.158622 139874090080128 model_lib_v2.py:966] Finished eval step 600\n",
            "INFO:tensorflow:Step 2400 per-step time 0.350s\n",
            "I0913 19:32:15.979832 140213675833216 model_lib_v2.py:707] Step 2400 per-step time 0.350s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10812571,\n",
            " 'Loss/localization_loss': 0.05886257,\n",
            " 'Loss/regularization_loss': 0.14495821,\n",
            " 'Loss/total_loss': 0.3119465,\n",
            " 'learning_rate': 0.07983897}\n",
            "I0913 19:32:15.980273 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.10812571,\n",
            " 'Loss/localization_loss': 0.05886257,\n",
            " 'Loss/regularization_loss': 0.14495821,\n",
            " 'Loss/total_loss': 0.3119465,\n",
            " 'learning_rate': 0.07983897}\n",
            "INFO:tensorflow:Finished eval step 700\n",
            "I0913 19:32:18.957059 139874090080128 model_lib_v2.py:966] Finished eval step 700\n",
            "INFO:tensorflow:Finished eval step 800\n",
            "I0913 19:32:31.359353 139874090080128 model_lib_v2.py:966] Finished eval step 800\n",
            "INFO:tensorflow:Finished eval step 900\n",
            "I0913 19:32:43.836498 139874090080128 model_lib_v2.py:966] Finished eval step 900\n",
            "INFO:tensorflow:Step 2500 per-step time 0.350s\n",
            "I0913 19:32:50.987321 140213675833216 model_lib_v2.py:707] Step 2500 per-step time 0.350s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1069773,\n",
            " 'Loss/localization_loss': 0.073325925,\n",
            " 'Loss/regularization_loss': 0.14436275,\n",
            " 'Loss/total_loss': 0.32466596,\n",
            " 'learning_rate': 0.079815164}\n",
            "I0913 19:32:50.987751 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.1069773,\n",
            " 'Loss/localization_loss': 0.073325925,\n",
            " 'Loss/regularization_loss': 0.14436275,\n",
            " 'Loss/total_loss': 0.32466596,\n",
            " 'learning_rate': 0.079815164}\n",
            "INFO:tensorflow:Finished eval step 1000\n",
            "I0913 19:32:56.121758 139874090080128 model_lib_v2.py:966] Finished eval step 1000\n",
            "INFO:tensorflow:Finished eval step 1100\n",
            "I0913 19:33:08.752704 139874090080128 model_lib_v2.py:966] Finished eval step 1100\n",
            "INFO:tensorflow:Finished eval step 1200\n",
            "I0913 19:33:23.663055 139874090080128 model_lib_v2.py:966] Finished eval step 1200\n",
            "INFO:tensorflow:Step 2600 per-step time 0.359s\n",
            "I0913 19:33:26.925844 140213675833216 model_lib_v2.py:707] Step 2600 per-step time 0.359s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11472118,\n",
            " 'Loss/localization_loss': 0.08502766,\n",
            " 'Loss/regularization_loss': 0.14381775,\n",
            " 'Loss/total_loss': 0.3435666,\n",
            " 'learning_rate': 0.07978972}\n",
            "I0913 19:33:26.926273 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.11472118,\n",
            " 'Loss/localization_loss': 0.08502766,\n",
            " 'Loss/regularization_loss': 0.14381775,\n",
            " 'Loss/total_loss': 0.3435666,\n",
            " 'learning_rate': 0.07978972}\n",
            "INFO:tensorflow:Finished eval step 1300\n",
            "I0913 19:33:36.798350 139874090080128 model_lib_v2.py:966] Finished eval step 1300\n",
            "INFO:tensorflow:Finished eval step 1400\n",
            "I0913 19:33:48.989714 139874090080128 model_lib_v2.py:966] Finished eval step 1400\n",
            "INFO:tensorflow:Step 2700 per-step time 0.349s\n",
            "I0913 19:34:01.862542 140213675833216 model_lib_v2.py:707] Step 2700 per-step time 0.349s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11189109,\n",
            " 'Loss/localization_loss': 0.06821392,\n",
            " 'Loss/regularization_loss': 0.14328858,\n",
            " 'Loss/total_loss': 0.32339358,\n",
            " 'learning_rate': 0.07976264}\n",
            "I0913 19:34:01.862917 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.11189109,\n",
            " 'Loss/localization_loss': 0.06821392,\n",
            " 'Loss/regularization_loss': 0.14328858,\n",
            " 'Loss/total_loss': 0.32339358,\n",
            " 'learning_rate': 0.07976264}\n",
            "INFO:tensorflow:Finished eval step 1500\n",
            "I0913 19:34:02.009818 139874090080128 model_lib_v2.py:966] Finished eval step 1500\n",
            "INFO:tensorflow:Performing evaluation on 1572 images.\n",
            "I0913 19:34:10.707261 139874090080128 coco_evaluation.py:293] Performing evaluation on 1572 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0913 19:34:10.724837 139874090080128 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.21s)\n",
            "I0913 19:34:10.932593 139874090080128 coco_tools.py:138] DONE (t=0.21s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "INFO:tensorflow:Step 2800 per-step time 0.316s\n",
            "I0913 19:34:33.450232 140213675833216 model_lib_v2.py:707] Step 2800 per-step time 0.316s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.112732545,\n",
            " 'Loss/localization_loss': 0.06412159,\n",
            " 'Loss/regularization_loss': 0.14271218,\n",
            " 'Loss/total_loss': 0.3195663,\n",
            " 'learning_rate': 0.07973392}\n",
            "I0913 19:34:33.450619 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.112732545,\n",
            " 'Loss/localization_loss': 0.06412159,\n",
            " 'Loss/regularization_loss': 0.14271218,\n",
            " 'Loss/total_loss': 0.3195663,\n",
            " 'learning_rate': 0.07973392}\n",
            "INFO:tensorflow:Step 2900 per-step time 0.303s\n",
            "I0913 19:35:03.717127 140213675833216 model_lib_v2.py:707] Step 2900 per-step time 0.303s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.110125944,\n",
            " 'Loss/localization_loss': 0.06998106,\n",
            " 'Loss/regularization_loss': 0.14217728,\n",
            " 'Loss/total_loss': 0.32228428,\n",
            " 'learning_rate': 0.07970358}\n",
            "I0913 19:35:03.717497 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.110125944,\n",
            " 'Loss/localization_loss': 0.06998106,\n",
            " 'Loss/regularization_loss': 0.14217728,\n",
            " 'Loss/total_loss': 0.32228428,\n",
            " 'learning_rate': 0.07970358}\n",
            "DONE (t=73.62s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=3.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.331\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.647\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.306\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.263\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.399\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.333\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.055\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.292\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.492\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.372\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.568\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.537\n",
            "INFO:tensorflow:Eval metrics at step 2000\n",
            "I0913 19:35:27.878098 139874090080128 model_lib_v2.py:1015] Eval metrics at step 2000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.331439\n",
            "I0913 19:35:27.894123 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.331439\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.647488\n",
            "I0913 19:35:27.901352 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.647488\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.306054\n",
            "I0913 19:35:27.908791 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.306054\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.262861\n",
            "I0913 19:35:27.917037 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): 0.262861\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.399301\n",
            "I0913 19:35:27.922989 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): 0.399301\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.332531\n",
            "I0913 19:35:27.931037 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): 0.332531\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.055452\n",
            "I0913 19:35:27.933187 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.055452\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.292032\n",
            "I0913 19:35:27.935473 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.292032\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.491929\n",
            "I0913 19:35:27.937674 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.491929\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.372420\n",
            "I0913 19:35:27.939839 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): 0.372420\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.567834\n",
            "I0913 19:35:27.950498 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.567834\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.536594\n",
            "I0913 19:35:27.954360 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): 0.536594\n",
            "INFO:tensorflow:\t+ Loss/localization_loss: 0.236124\n",
            "I0913 19:35:27.957838 139874090080128 model_lib_v2.py:1018] \t+ Loss/localization_loss: 0.236124\n",
            "INFO:tensorflow:\t+ Loss/classification_loss: 0.361671\n",
            "I0913 19:35:27.966912 139874090080128 model_lib_v2.py:1018] \t+ Loss/classification_loss: 0.361671\n",
            "INFO:tensorflow:\t+ Loss/regularization_loss: 0.146973\n",
            "I0913 19:35:27.969628 139874090080128 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.146973\n",
            "INFO:tensorflow:\t+ Loss/total_loss: 0.744768\n",
            "I0913 19:35:27.975893 139874090080128 model_lib_v2.py:1018] \t+ Loss/total_loss: 0.744768\n",
            "INFO:tensorflow:Waiting for new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2\n",
            "I0913 19:35:28.270609 139874090080128 checkpoint_utils.py:136] Waiting for new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2\n",
            "INFO:tensorflow:Step 3000 per-step time 0.305s\n",
            "I0913 19:35:34.247658 140213675833216 model_lib_v2.py:707] Step 3000 per-step time 0.305s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.091576345,\n",
            " 'Loss/localization_loss': 0.053322457,\n",
            " 'Loss/regularization_loss': 0.1416606,\n",
            " 'Loss/total_loss': 0.2865594,\n",
            " 'learning_rate': 0.0796716}\n",
            "I0913 19:35:34.247957 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.091576345,\n",
            " 'Loss/localization_loss': 0.053322457,\n",
            " 'Loss/regularization_loss': 0.1416606,\n",
            " 'Loss/total_loss': 0.2865594,\n",
            " 'learning_rate': 0.0796716}\n",
            "INFO:tensorflow:Found new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-4\n",
            "I0913 19:35:35.282116 139874090080128 checkpoint_utils.py:145] Found new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-4\n",
            "INFO:tensorflow:Finished eval step 0\n",
            "I0913 19:35:46.376475 139874090080128 model_lib_v2.py:966] Finished eval step 0\n",
            "INFO:tensorflow:Step 3100 per-step time 0.322s\n",
            "I0913 19:36:06.405299 140213675833216 model_lib_v2.py:707] Step 3100 per-step time 0.322s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1366985,\n",
            " 'Loss/localization_loss': 0.08431091,\n",
            " 'Loss/regularization_loss': 0.14110051,\n",
            " 'Loss/total_loss': 0.3621099,\n",
            " 'learning_rate': 0.07963799}\n",
            "I0913 19:36:06.405680 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.1366985,\n",
            " 'Loss/localization_loss': 0.08431091,\n",
            " 'Loss/regularization_loss': 0.14110051,\n",
            " 'Loss/total_loss': 0.3621099,\n",
            " 'learning_rate': 0.07963799}\n",
            "INFO:tensorflow:Finished eval step 100\n",
            "I0913 19:36:21.372539 139874090080128 model_lib_v2.py:966] Finished eval step 100\n",
            "INFO:tensorflow:Finished eval step 200\n",
            "I0913 19:36:35.934988 139874090080128 model_lib_v2.py:966] Finished eval step 200\n",
            "INFO:tensorflow:Step 3200 per-step time 0.348s\n",
            "I0913 19:36:41.215774 140213675833216 model_lib_v2.py:707] Step 3200 per-step time 0.348s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.103657685,\n",
            " 'Loss/localization_loss': 0.06396575,\n",
            " 'Loss/regularization_loss': 0.14053756,\n",
            " 'Loss/total_loss': 0.308161,\n",
            " 'learning_rate': 0.07960275}\n",
            "I0913 19:36:41.216276 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.103657685,\n",
            " 'Loss/localization_loss': 0.06396575,\n",
            " 'Loss/regularization_loss': 0.14053756,\n",
            " 'Loss/total_loss': 0.308161,\n",
            " 'learning_rate': 0.07960275}\n",
            "INFO:tensorflow:Finished eval step 300\n",
            "I0913 19:36:49.922152 139874090080128 model_lib_v2.py:966] Finished eval step 300\n",
            "INFO:tensorflow:Finished eval step 400\n",
            "I0913 19:37:02.408694 139874090080128 model_lib_v2.py:966] Finished eval step 400\n",
            "INFO:tensorflow:Finished eval step 500\n",
            "I0913 19:37:15.042866 139874090080128 model_lib_v2.py:966] Finished eval step 500\n",
            "INFO:tensorflow:Step 3300 per-step time 0.348s\n",
            "I0913 19:37:16.030084 140213675833216 model_lib_v2.py:707] Step 3300 per-step time 0.348s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10694564,\n",
            " 'Loss/localization_loss': 0.064045295,\n",
            " 'Loss/regularization_loss': 0.14001842,\n",
            " 'Loss/total_loss': 0.31100935,\n",
            " 'learning_rate': 0.07956588}\n",
            "I0913 19:37:16.030462 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.10694564,\n",
            " 'Loss/localization_loss': 0.064045295,\n",
            " 'Loss/regularization_loss': 0.14001842,\n",
            " 'Loss/total_loss': 0.31100935,\n",
            " 'learning_rate': 0.07956588}\n",
            "INFO:tensorflow:Finished eval step 600\n",
            "I0913 19:37:27.198234 139874090080128 model_lib_v2.py:966] Finished eval step 600\n",
            "INFO:tensorflow:Finished eval step 700\n",
            "I0913 19:37:39.460899 139874090080128 model_lib_v2.py:966] Finished eval step 700\n",
            "INFO:tensorflow:Step 3400 per-step time 0.350s\n",
            "I0913 19:37:51.001323 140213675833216 model_lib_v2.py:707] Step 3400 per-step time 0.350s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.093409725,\n",
            " 'Loss/localization_loss': 0.06507321,\n",
            " 'Loss/regularization_loss': 0.13943101,\n",
            " 'Loss/total_loss': 0.29791397,\n",
            " 'learning_rate': 0.079527386}\n",
            "I0913 19:37:51.001694 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.093409725,\n",
            " 'Loss/localization_loss': 0.06507321,\n",
            " 'Loss/regularization_loss': 0.13943101,\n",
            " 'Loss/total_loss': 0.29791397,\n",
            " 'learning_rate': 0.079527386}\n",
            "INFO:tensorflow:Finished eval step 800\n",
            "I0913 19:37:51.808493 139874090080128 model_lib_v2.py:966] Finished eval step 800\n",
            "INFO:tensorflow:Finished eval step 900\n",
            "I0913 19:38:04.188069 139874090080128 model_lib_v2.py:966] Finished eval step 900\n",
            "INFO:tensorflow:Finished eval step 1000\n",
            "I0913 19:38:16.616024 139874090080128 model_lib_v2.py:966] Finished eval step 1000\n",
            "INFO:tensorflow:Step 3500 per-step time 0.349s\n",
            "I0913 19:38:25.876529 140213675833216 model_lib_v2.py:707] Step 3500 per-step time 0.349s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12794124,\n",
            " 'Loss/localization_loss': 0.08723262,\n",
            " 'Loss/regularization_loss': 0.1388365,\n",
            " 'Loss/total_loss': 0.35401034,\n",
            " 'learning_rate': 0.07948727}\n",
            "I0913 19:38:25.876897 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.12794124,\n",
            " 'Loss/localization_loss': 0.08723262,\n",
            " 'Loss/regularization_loss': 0.1388365,\n",
            " 'Loss/total_loss': 0.35401034,\n",
            " 'learning_rate': 0.07948727}\n",
            "INFO:tensorflow:Finished eval step 1100\n",
            "I0913 19:38:29.580486 139874090080128 model_lib_v2.py:966] Finished eval step 1100\n",
            "INFO:tensorflow:Finished eval step 1200\n",
            "I0913 19:38:42.107323 139874090080128 model_lib_v2.py:966] Finished eval step 1200\n",
            "INFO:tensorflow:Finished eval step 1300\n",
            "I0913 19:38:54.638818 139874090080128 model_lib_v2.py:966] Finished eval step 1300\n",
            "INFO:tensorflow:Step 3600 per-step time 0.348s\n",
            "I0913 19:39:00.677241 140213675833216 model_lib_v2.py:707] Step 3600 per-step time 0.348s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09768167,\n",
            " 'Loss/localization_loss': 0.056811266,\n",
            " 'Loss/regularization_loss': 0.13830107,\n",
            " 'Loss/total_loss': 0.29279402,\n",
            " 'learning_rate': 0.079445526}\n",
            "I0913 19:39:00.677640 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.09768167,\n",
            " 'Loss/localization_loss': 0.056811266,\n",
            " 'Loss/regularization_loss': 0.13830107,\n",
            " 'Loss/total_loss': 0.29279402,\n",
            " 'learning_rate': 0.079445526}\n",
            "INFO:tensorflow:Finished eval step 1400\n",
            "I0913 19:39:06.751610 139874090080128 model_lib_v2.py:966] Finished eval step 1400\n",
            "INFO:tensorflow:Finished eval step 1500\n",
            "I0913 19:39:19.112162 139874090080128 model_lib_v2.py:966] Finished eval step 1500\n",
            "INFO:tensorflow:Performing evaluation on 1572 images.\n",
            "I0913 19:39:27.926422 139874090080128 coco_evaluation.py:293] Performing evaluation on 1572 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0913 19:39:27.947083 139874090080128 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.14s)\n",
            "I0913 19:39:28.086927 139874090080128 coco_tools.py:138] DONE (t=0.14s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "INFO:tensorflow:Step 3700 per-step time 0.341s\n",
            "I0913 19:39:34.781048 140213675833216 model_lib_v2.py:707] Step 3700 per-step time 0.341s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10038168,\n",
            " 'Loss/localization_loss': 0.058277845,\n",
            " 'Loss/regularization_loss': 0.13774893,\n",
            " 'Loss/total_loss': 0.29640844,\n",
            " 'learning_rate': 0.07940216}\n",
            "I0913 19:39:34.781404 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.10038168,\n",
            " 'Loss/localization_loss': 0.058277845,\n",
            " 'Loss/regularization_loss': 0.13774893,\n",
            " 'Loss/total_loss': 0.29640844,\n",
            " 'learning_rate': 0.07940216}\n",
            "INFO:tensorflow:Step 3800 per-step time 0.309s\n",
            "I0913 19:40:05.675952 140213675833216 model_lib_v2.py:707] Step 3800 per-step time 0.309s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10256105,\n",
            " 'Loss/localization_loss': 0.06523007,\n",
            " 'Loss/regularization_loss': 0.1371139,\n",
            " 'Loss/total_loss': 0.30490503,\n",
            " 'learning_rate': 0.079357184}\n",
            "I0913 19:40:05.676302 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.10256105,\n",
            " 'Loss/localization_loss': 0.06523007,\n",
            " 'Loss/regularization_loss': 0.1371139,\n",
            " 'Loss/total_loss': 0.30490503,\n",
            " 'learning_rate': 0.079357184}\n",
            "INFO:tensorflow:Step 3900 per-step time 0.304s\n",
            "I0913 19:40:36.038015 140213675833216 model_lib_v2.py:707] Step 3900 per-step time 0.304s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08601553,\n",
            " 'Loss/localization_loss': 0.049192656,\n",
            " 'Loss/regularization_loss': 0.13652712,\n",
            " 'Loss/total_loss': 0.2717353,\n",
            " 'learning_rate': 0.07931058}\n",
            "I0913 19:40:36.038426 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.08601553,\n",
            " 'Loss/localization_loss': 0.049192656,\n",
            " 'Loss/regularization_loss': 0.13652712,\n",
            " 'Loss/total_loss': 0.2717353,\n",
            " 'learning_rate': 0.07931058}\n",
            "DONE (t=80.00s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=3.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.340\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.650\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.332\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.308\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.398\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.321\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.053\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.302\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.513\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.413\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.580\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.466\n",
            "INFO:tensorflow:Eval metrics at step 3000\n",
            "I0913 19:40:51.466266 139874090080128 model_lib_v2.py:1015] Eval metrics at step 3000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.340480\n",
            "I0913 19:40:51.471717 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.340480\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.649852\n",
            "I0913 19:40:51.475958 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.649852\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.331819\n",
            "I0913 19:40:51.480551 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.331819\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.308069\n",
            "I0913 19:40:51.485118 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): 0.308069\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.398126\n",
            "I0913 19:40:51.489740 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): 0.398126\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.321028\n",
            "I0913 19:40:51.494369 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): 0.321028\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.053098\n",
            "I0913 19:40:51.498983 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.053098\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.302219\n",
            "I0913 19:40:51.503664 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.302219\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.513321\n",
            "I0913 19:40:51.508318 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.513321\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.412556\n",
            "I0913 19:40:51.512972 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): 0.412556\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.580019\n",
            "I0913 19:40:51.517655 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.580019\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.465942\n",
            "I0913 19:40:51.522340 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): 0.465942\n",
            "INFO:tensorflow:\t+ Loss/localization_loss: 0.234234\n",
            "I0913 19:40:51.524565 139874090080128 model_lib_v2.py:1018] \t+ Loss/localization_loss: 0.234234\n",
            "INFO:tensorflow:\t+ Loss/classification_loss: 0.474930\n",
            "I0913 19:40:51.526887 139874090080128 model_lib_v2.py:1018] \t+ Loss/classification_loss: 0.474930\n",
            "INFO:tensorflow:\t+ Loss/regularization_loss: 0.141655\n",
            "I0913 19:40:51.529147 139874090080128 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.141655\n",
            "INFO:tensorflow:\t+ Loss/total_loss: 0.850819\n",
            "I0913 19:40:51.531457 139874090080128 model_lib_v2.py:1018] \t+ Loss/total_loss: 0.850819\n",
            "INFO:tensorflow:Waiting for new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2\n",
            "I0913 19:40:51.810750 139874090080128 checkpoint_utils.py:136] Waiting for new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2\n",
            "INFO:tensorflow:Step 4000 per-step time 0.306s\n",
            "I0913 19:41:06.598441 140213675833216 model_lib_v2.py:707] Step 4000 per-step time 0.306s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.098720014,\n",
            " 'Loss/localization_loss': 0.06395986,\n",
            " 'Loss/regularization_loss': 0.13596867,\n",
            " 'Loss/total_loss': 0.29864854,\n",
            " 'learning_rate': 0.07926236}\n",
            "I0913 19:41:06.598736 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.098720014,\n",
            " 'Loss/localization_loss': 0.06395986,\n",
            " 'Loss/regularization_loss': 0.13596867,\n",
            " 'Loss/total_loss': 0.29864854,\n",
            " 'learning_rate': 0.07926236}\n",
            "INFO:tensorflow:Found new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-5\n",
            "I0913 19:41:07.835194 139874090080128 checkpoint_utils.py:145] Found new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-5\n",
            "INFO:tensorflow:Finished eval step 0\n",
            "I0913 19:41:18.705226 139874090080128 model_lib_v2.py:966] Finished eval step 0\n",
            "INFO:tensorflow:Step 4100 per-step time 0.324s\n",
            "I0913 19:41:39.002709 140213675833216 model_lib_v2.py:707] Step 4100 per-step time 0.324s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08617192,\n",
            " 'Loss/localization_loss': 0.043396197,\n",
            " 'Loss/regularization_loss': 0.13538095,\n",
            " 'Loss/total_loss': 0.26494908,\n",
            " 'learning_rate': 0.07921253}\n",
            "I0913 19:41:39.003115 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.08617192,\n",
            " 'Loss/localization_loss': 0.043396197,\n",
            " 'Loss/regularization_loss': 0.13538095,\n",
            " 'Loss/total_loss': 0.26494908,\n",
            " 'learning_rate': 0.07921253}\n",
            "INFO:tensorflow:Finished eval step 100\n",
            "I0913 19:41:54.685026 139874090080128 model_lib_v2.py:966] Finished eval step 100\n",
            "INFO:tensorflow:Finished eval step 200\n",
            "I0913 19:42:07.032737 139874090080128 model_lib_v2.py:966] Finished eval step 200\n",
            "INFO:tensorflow:Step 4200 per-step time 0.339s\n",
            "I0913 19:42:12.952656 140213675833216 model_lib_v2.py:707] Step 4200 per-step time 0.339s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08576725,\n",
            " 'Loss/localization_loss': 0.04705501,\n",
            " 'Loss/regularization_loss': 0.13479674,\n",
            " 'Loss/total_loss': 0.267619,\n",
            " 'learning_rate': 0.07916109}\n",
            "I0913 19:42:12.953054 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.08576725,\n",
            " 'Loss/localization_loss': 0.04705501,\n",
            " 'Loss/regularization_loss': 0.13479674,\n",
            " 'Loss/total_loss': 0.267619,\n",
            " 'learning_rate': 0.07916109}\n",
            "INFO:tensorflow:Finished eval step 300\n",
            "I0913 19:42:19.255097 139874090080128 model_lib_v2.py:966] Finished eval step 300\n",
            "INFO:tensorflow:Finished eval step 400\n",
            "I0913 19:42:31.423458 139874090080128 model_lib_v2.py:966] Finished eval step 400\n",
            "INFO:tensorflow:Finished eval step 500\n",
            "I0913 19:42:43.984253 139874090080128 model_lib_v2.py:966] Finished eval step 500\n",
            "INFO:tensorflow:Step 4300 per-step time 0.350s\n",
            "I0913 19:42:47.991613 140213675833216 model_lib_v2.py:707] Step 4300 per-step time 0.350s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.104106456,\n",
            " 'Loss/localization_loss': 0.051033255,\n",
            " 'Loss/regularization_loss': 0.13424875,\n",
            " 'Loss/total_loss': 0.28938848,\n",
            " 'learning_rate': 0.07910804}\n",
            "I0913 19:42:47.992037 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.104106456,\n",
            " 'Loss/localization_loss': 0.051033255,\n",
            " 'Loss/regularization_loss': 0.13424875,\n",
            " 'Loss/total_loss': 0.28938848,\n",
            " 'learning_rate': 0.07910804}\n",
            "INFO:tensorflow:Finished eval step 600\n",
            "I0913 19:42:56.558318 139874090080128 model_lib_v2.py:966] Finished eval step 600\n",
            "INFO:tensorflow:Finished eval step 700\n",
            "I0913 19:43:11.707798 139874090080128 model_lib_v2.py:966] Finished eval step 700\n",
            "INFO:tensorflow:Step 4400 per-step time 0.359s\n",
            "I0913 19:43:23.911293 140213675833216 model_lib_v2.py:707] Step 4400 per-step time 0.359s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09719382,\n",
            " 'Loss/localization_loss': 0.04748638,\n",
            " 'Loss/regularization_loss': 0.13365906,\n",
            " 'Loss/total_loss': 0.27833927,\n",
            " 'learning_rate': 0.07905338}\n",
            "I0913 19:43:23.911644 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.09719382,\n",
            " 'Loss/localization_loss': 0.04748638,\n",
            " 'Loss/regularization_loss': 0.13365906,\n",
            " 'Loss/total_loss': 0.27833927,\n",
            " 'learning_rate': 0.07905338}\n",
            "INFO:tensorflow:Finished eval step 800\n",
            "I0913 19:43:24.057711 139874090080128 model_lib_v2.py:966] Finished eval step 800\n",
            "INFO:tensorflow:Finished eval step 900\n",
            "I0913 19:43:36.479407 139874090080128 model_lib_v2.py:966] Finished eval step 900\n",
            "INFO:tensorflow:Finished eval step 1000\n",
            "I0913 19:43:49.256120 139874090080128 model_lib_v2.py:966] Finished eval step 1000\n",
            "INFO:tensorflow:Step 4500 per-step time 0.350s\n",
            "I0913 19:43:58.912870 140213675833216 model_lib_v2.py:707] Step 4500 per-step time 0.350s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0924082,\n",
            " 'Loss/localization_loss': 0.050114293,\n",
            " 'Loss/regularization_loss': 0.133059,\n",
            " 'Loss/total_loss': 0.27558148,\n",
            " 'learning_rate': 0.07899711}\n",
            "I0913 19:43:58.913275 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.0924082,\n",
            " 'Loss/localization_loss': 0.050114293,\n",
            " 'Loss/regularization_loss': 0.133059,\n",
            " 'Loss/total_loss': 0.27558148,\n",
            " 'learning_rate': 0.07899711}\n",
            "INFO:tensorflow:Finished eval step 1100\n",
            "I0913 19:44:01.469777 139874090080128 model_lib_v2.py:966] Finished eval step 1100\n",
            "INFO:tensorflow:Finished eval step 1200\n",
            "I0913 19:44:13.993925 139874090080128 model_lib_v2.py:966] Finished eval step 1200\n",
            "INFO:tensorflow:Finished eval step 1300\n",
            "I0913 19:44:26.591051 139874090080128 model_lib_v2.py:966] Finished eval step 1300\n",
            "INFO:tensorflow:Step 4600 per-step time 0.347s\n",
            "I0913 19:44:33.645627 140213675833216 model_lib_v2.py:707] Step 4600 per-step time 0.347s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09015374,\n",
            " 'Loss/localization_loss': 0.03826148,\n",
            " 'Loss/regularization_loss': 0.13255005,\n",
            " 'Loss/total_loss': 0.2609653,\n",
            " 'learning_rate': 0.078939244}\n",
            "I0913 19:44:33.646010 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.09015374,\n",
            " 'Loss/localization_loss': 0.03826148,\n",
            " 'Loss/regularization_loss': 0.13255005,\n",
            " 'Loss/total_loss': 0.2609653,\n",
            " 'learning_rate': 0.078939244}\n",
            "INFO:tensorflow:Finished eval step 1400\n",
            "I0913 19:44:38.770298 139874090080128 model_lib_v2.py:966] Finished eval step 1400\n",
            "INFO:tensorflow:Finished eval step 1500\n",
            "I0913 19:44:51.355631 139874090080128 model_lib_v2.py:966] Finished eval step 1500\n",
            "INFO:tensorflow:Step 4700 per-step time 0.339s\n",
            "I0913 19:45:07.531843 140213675833216 model_lib_v2.py:707] Step 4700 per-step time 0.339s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09645994,\n",
            " 'Loss/localization_loss': 0.0663207,\n",
            " 'Loss/regularization_loss': 0.13197969,\n",
            " 'Loss/total_loss': 0.29476035,\n",
            " 'learning_rate': 0.07887978}\n",
            "I0913 19:45:07.532136 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.09645994,\n",
            " 'Loss/localization_loss': 0.0663207,\n",
            " 'Loss/regularization_loss': 0.13197969,\n",
            " 'Loss/total_loss': 0.29476035,\n",
            " 'learning_rate': 0.07887978}\n",
            "INFO:tensorflow:Performing evaluation on 1572 images.\n",
            "I0913 19:45:32.178718 139874090080128 coco_evaluation.py:293] Performing evaluation on 1572 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0913 19:45:32.197077 139874090080128 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.20s)\n",
            "I0913 19:45:32.392611 139874090080128 coco_tools.py:138] DONE (t=0.20s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "INFO:tensorflow:Step 4800 per-step time 0.303s\n",
            "I0913 19:45:37.800249 140213675833216 model_lib_v2.py:707] Step 4800 per-step time 0.303s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.082407616,\n",
            " 'Loss/localization_loss': 0.04215514,\n",
            " 'Loss/regularization_loss': 0.13140784,\n",
            " 'Loss/total_loss': 0.2559706,\n",
            " 'learning_rate': 0.07881871}\n",
            "I0913 19:45:37.800611 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.082407616,\n",
            " 'Loss/localization_loss': 0.04215514,\n",
            " 'Loss/regularization_loss': 0.13140784,\n",
            " 'Loss/total_loss': 0.2559706,\n",
            " 'learning_rate': 0.07881871}\n",
            "INFO:tensorflow:Step 4900 per-step time 0.302s\n",
            "I0913 19:46:07.990812 140213675833216 model_lib_v2.py:707] Step 4900 per-step time 0.302s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.089254804,\n",
            " 'Loss/localization_loss': 0.050042104,\n",
            " 'Loss/regularization_loss': 0.13089481,\n",
            " 'Loss/total_loss': 0.27019173,\n",
            " 'learning_rate': 0.07875605}\n",
            "I0913 19:46:07.991161 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.089254804,\n",
            " 'Loss/localization_loss': 0.050042104,\n",
            " 'Loss/regularization_loss': 0.13089481,\n",
            " 'Loss/total_loss': 0.27019173,\n",
            " 'learning_rate': 0.07875605}\n",
            "INFO:tensorflow:Step 5000 per-step time 0.309s\n",
            "I0913 19:46:38.877941 140213675833216 model_lib_v2.py:707] Step 5000 per-step time 0.309s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08642944,\n",
            " 'Loss/localization_loss': 0.050543107,\n",
            " 'Loss/regularization_loss': 0.13035625,\n",
            " 'Loss/total_loss': 0.2673288,\n",
            " 'learning_rate': 0.078691795}\n",
            "I0913 19:46:38.878345 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.08642944,\n",
            " 'Loss/localization_loss': 0.050543107,\n",
            " 'Loss/regularization_loss': 0.13035625,\n",
            " 'Loss/total_loss': 0.2673288,\n",
            " 'learning_rate': 0.078691795}\n",
            "DONE (t=79.21s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=3.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.372\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.700\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.370\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.351\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.407\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.342\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.057\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.312\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.530\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.464\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.574\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.470\n",
            "INFO:tensorflow:Eval metrics at step 4000\n",
            "I0913 19:46:54.970942 139874090080128 model_lib_v2.py:1015] Eval metrics at step 4000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.372436\n",
            "I0913 19:46:54.976753 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.372436\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.699936\n",
            "I0913 19:46:54.980893 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.699936\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.370298\n",
            "I0913 19:46:54.985528 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.370298\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.351341\n",
            "I0913 19:46:54.990150 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): 0.351341\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.407001\n",
            "I0913 19:46:54.994878 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): 0.407001\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.342280\n",
            "I0913 19:46:54.999621 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): 0.342280\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.056756\n",
            "I0913 19:46:55.004370 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.056756\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.311882\n",
            "I0913 19:46:55.009039 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.311882\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.530268\n",
            "I0913 19:46:55.019926 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.530268\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.464370\n",
            "I0913 19:46:55.024569 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): 0.464370\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.574419\n",
            "I0913 19:46:55.029195 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.574419\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.469565\n",
            "I0913 19:46:55.033882 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): 0.469565\n",
            "INFO:tensorflow:\t+ Loss/localization_loss: 0.231454\n",
            "I0913 19:46:55.036097 139874090080128 model_lib_v2.py:1018] \t+ Loss/localization_loss: 0.231454\n",
            "INFO:tensorflow:\t+ Loss/classification_loss: 0.473435\n",
            "I0913 19:46:55.038387 139874090080128 model_lib_v2.py:1018] \t+ Loss/classification_loss: 0.473435\n",
            "INFO:tensorflow:\t+ Loss/regularization_loss: 0.135963\n",
            "I0913 19:46:55.040688 139874090080128 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.135963\n",
            "INFO:tensorflow:\t+ Loss/total_loss: 0.840851\n",
            "I0913 19:46:55.043044 139874090080128 model_lib_v2.py:1018] \t+ Loss/total_loss: 0.840851\n",
            "INFO:tensorflow:Waiting for new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2\n",
            "I0913 19:46:55.335391 139874090080128 checkpoint_utils.py:136] Waiting for new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2\n",
            "INFO:tensorflow:Found new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-6\n",
            "I0913 19:46:55.336624 139874090080128 checkpoint_utils.py:145] Found new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-6\n",
            "INFO:tensorflow:Finished eval step 0\n",
            "I0913 19:47:06.261042 139874090080128 model_lib_v2.py:966] Finished eval step 0\n",
            "INFO:tensorflow:Step 5100 per-step time 0.315s\n",
            "I0913 19:47:10.387745 140213675833216 model_lib_v2.py:707] Step 5100 per-step time 0.315s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10158632,\n",
            " 'Loss/localization_loss': 0.06147108,\n",
            " 'Loss/regularization_loss': 0.12976845,\n",
            " 'Loss/total_loss': 0.29282585,\n",
            " 'learning_rate': 0.07862595}\n",
            "I0913 19:47:10.388121 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.10158632,\n",
            " 'Loss/localization_loss': 0.06147108,\n",
            " 'Loss/regularization_loss': 0.12976845,\n",
            " 'Loss/total_loss': 0.29282585,\n",
            " 'learning_rate': 0.07862595}\n",
            "INFO:tensorflow:Finished eval step 100\n",
            "I0913 19:47:41.970574 139874090080128 model_lib_v2.py:966] Finished eval step 100\n",
            "INFO:tensorflow:Step 5200 per-step time 0.322s\n",
            "I0913 19:47:42.606647 140213675833216 model_lib_v2.py:707] Step 5200 per-step time 0.322s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09380427,\n",
            " 'Loss/localization_loss': 0.06261729,\n",
            " 'Loss/regularization_loss': 0.12924539,\n",
            " 'Loss/total_loss': 0.28566694,\n",
            " 'learning_rate': 0.07855851}\n",
            "I0913 19:47:42.607029 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.09380427,\n",
            " 'Loss/localization_loss': 0.06261729,\n",
            " 'Loss/regularization_loss': 0.12924539,\n",
            " 'Loss/total_loss': 0.28566694,\n",
            " 'learning_rate': 0.07855851}\n",
            "INFO:tensorflow:Finished eval step 200\n",
            "I0913 19:47:54.277918 139874090080128 model_lib_v2.py:966] Finished eval step 200\n",
            "INFO:tensorflow:Finished eval step 300\n",
            "I0913 19:48:06.589063 139874090080128 model_lib_v2.py:966] Finished eval step 300\n",
            "INFO:tensorflow:Step 5300 per-step time 0.351s\n",
            "I0913 19:48:17.679758 140213675833216 model_lib_v2.py:707] Step 5300 per-step time 0.351s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08101532,\n",
            " 'Loss/localization_loss': 0.039081927,\n",
            " 'Loss/regularization_loss': 0.12874363,\n",
            " 'Loss/total_loss': 0.24884088,\n",
            " 'learning_rate': 0.07848949}\n",
            "I0913 19:48:17.680538 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.08101532,\n",
            " 'Loss/localization_loss': 0.039081927,\n",
            " 'Loss/regularization_loss': 0.12874363,\n",
            " 'Loss/total_loss': 0.24884088,\n",
            " 'learning_rate': 0.07848949}\n",
            "INFO:tensorflow:Finished eval step 400\n",
            "I0913 19:48:18.916801 139874090080128 model_lib_v2.py:966] Finished eval step 400\n",
            "INFO:tensorflow:Finished eval step 500\n",
            "I0913 19:48:31.181472 139874090080128 model_lib_v2.py:966] Finished eval step 500\n",
            "INFO:tensorflow:Finished eval step 600\n",
            "I0913 19:48:43.386640 139874090080128 model_lib_v2.py:966] Finished eval step 600\n",
            "INFO:tensorflow:Step 5400 per-step time 0.350s\n",
            "I0913 19:48:52.673116 140213675833216 model_lib_v2.py:707] Step 5400 per-step time 0.350s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09121681,\n",
            " 'Loss/localization_loss': 0.045872733,\n",
            " 'Loss/regularization_loss': 0.12815861,\n",
            " 'Loss/total_loss': 0.26524818,\n",
            " 'learning_rate': 0.078418896}\n",
            "I0913 19:48:52.673530 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.09121681,\n",
            " 'Loss/localization_loss': 0.045872733,\n",
            " 'Loss/regularization_loss': 0.12815861,\n",
            " 'Loss/total_loss': 0.26524818,\n",
            " 'learning_rate': 0.078418896}\n",
            "INFO:tensorflow:Finished eval step 700\n",
            "I0913 19:48:55.697588 139874090080128 model_lib_v2.py:966] Finished eval step 700\n",
            "INFO:tensorflow:Finished eval step 800\n",
            "I0913 19:49:08.296344 139874090080128 model_lib_v2.py:966] Finished eval step 800\n",
            "INFO:tensorflow:Finished eval step 900\n",
            "I0913 19:49:20.518548 139874090080128 model_lib_v2.py:966] Finished eval step 900\n",
            "INFO:tensorflow:Step 5500 per-step time 0.351s\n",
            "I0913 19:49:27.753329 140213675833216 model_lib_v2.py:707] Step 5500 per-step time 0.351s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.069827005,\n",
            " 'Loss/localization_loss': 0.036859866,\n",
            " 'Loss/regularization_loss': 0.12763232,\n",
            " 'Loss/total_loss': 0.2343192,\n",
            " 'learning_rate': 0.078346714}\n",
            "I0913 19:49:27.753694 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.069827005,\n",
            " 'Loss/localization_loss': 0.036859866,\n",
            " 'Loss/regularization_loss': 0.12763232,\n",
            " 'Loss/total_loss': 0.2343192,\n",
            " 'learning_rate': 0.078346714}\n",
            "INFO:tensorflow:Finished eval step 1000\n",
            "I0913 19:49:36.120517 139874090080128 model_lib_v2.py:966] Finished eval step 1000\n",
            "INFO:tensorflow:Finished eval step 1100\n",
            "I0913 19:49:48.459493 139874090080128 model_lib_v2.py:966] Finished eval step 1100\n",
            "INFO:tensorflow:Finished eval step 1200\n",
            "I0913 19:50:00.498568 139874090080128 model_lib_v2.py:966] Finished eval step 1200\n",
            "INFO:tensorflow:Step 5600 per-step time 0.360s\n",
            "I0913 19:50:03.703697 140213675833216 model_lib_v2.py:707] Step 5600 per-step time 0.360s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08267651,\n",
            " 'Loss/localization_loss': 0.04796706,\n",
            " 'Loss/regularization_loss': 0.12709093,\n",
            " 'Loss/total_loss': 0.2577345,\n",
            " 'learning_rate': 0.07827295}\n",
            "I0913 19:50:03.704056 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.08267651,\n",
            " 'Loss/localization_loss': 0.04796706,\n",
            " 'Loss/regularization_loss': 0.12709093,\n",
            " 'Loss/total_loss': 0.2577345,\n",
            " 'learning_rate': 0.07827295}\n",
            "INFO:tensorflow:Finished eval step 1300\n",
            "I0913 19:50:12.724839 139874090080128 model_lib_v2.py:966] Finished eval step 1300\n",
            "INFO:tensorflow:Finished eval step 1400\n",
            "I0913 19:50:24.884540 139874090080128 model_lib_v2.py:966] Finished eval step 1400\n",
            "INFO:tensorflow:Finished eval step 1500\n",
            "I0913 19:50:37.276635 139874090080128 model_lib_v2.py:966] Finished eval step 1500\n",
            "INFO:tensorflow:Step 5700 per-step time 0.350s\n",
            "I0913 19:50:38.743077 140213675833216 model_lib_v2.py:707] Step 5700 per-step time 0.350s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07485571,\n",
            " 'Loss/localization_loss': 0.04751949,\n",
            " 'Loss/regularization_loss': 0.12653328,\n",
            " 'Loss/total_loss': 0.24890849,\n",
            " 'learning_rate': 0.07819763}\n",
            "I0913 19:50:38.743487 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.07485571,\n",
            " 'Loss/localization_loss': 0.04751949,\n",
            " 'Loss/regularization_loss': 0.12653328,\n",
            " 'Loss/total_loss': 0.24890849,\n",
            " 'learning_rate': 0.07819763}\n",
            "INFO:tensorflow:Performing evaluation on 1572 images.\n",
            "I0913 19:50:46.103622 139874090080128 coco_evaluation.py:293] Performing evaluation on 1572 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0913 19:50:46.122749 139874090080128 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.17s)\n",
            "I0913 19:50:46.293508 139874090080128 coco_tools.py:138] DONE (t=0.17s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "INFO:tensorflow:Step 5800 per-step time 0.312s\n",
            "I0913 19:51:09.947406 140213675833216 model_lib_v2.py:707] Step 5800 per-step time 0.312s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.068877004,\n",
            " 'Loss/localization_loss': 0.030752268,\n",
            " 'Loss/regularization_loss': 0.12599379,\n",
            " 'Loss/total_loss': 0.22562306,\n",
            " 'learning_rate': 0.07812072}\n",
            "I0913 19:51:09.947768 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.068877004,\n",
            " 'Loss/localization_loss': 0.030752268,\n",
            " 'Loss/regularization_loss': 0.12599379,\n",
            " 'Loss/total_loss': 0.22562306,\n",
            " 'learning_rate': 0.07812072}\n",
            "INFO:tensorflow:Step 5900 per-step time 0.302s\n",
            "I0913 19:51:40.179417 140213675833216 model_lib_v2.py:707] Step 5900 per-step time 0.302s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07233257,\n",
            " 'Loss/localization_loss': 0.035844978,\n",
            " 'Loss/regularization_loss': 0.12548721,\n",
            " 'Loss/total_loss': 0.23366475,\n",
            " 'learning_rate': 0.078042254}\n",
            "I0913 19:51:40.179769 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.07233257,\n",
            " 'Loss/localization_loss': 0.035844978,\n",
            " 'Loss/regularization_loss': 0.12548721,\n",
            " 'Loss/total_loss': 0.23366475,\n",
            " 'learning_rate': 0.078042254}\n",
            "DONE (t=73.28s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=3.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.363\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.688\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.351\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.401\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.253\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.056\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.306\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.524\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.455\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.573\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.374\n",
            "INFO:tensorflow:Eval metrics at step 5000\n",
            "I0913 19:52:02.873452 139874090080128 model_lib_v2.py:1015] Eval metrics at step 5000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.362962\n",
            "I0913 19:52:02.879133 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.362962\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.688153\n",
            "I0913 19:52:02.883320 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.688153\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.351476\n",
            "I0913 19:52:02.887951 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.351476\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.350215\n",
            "I0913 19:52:02.892616 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): 0.350215\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.400666\n",
            "I0913 19:52:02.897380 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): 0.400666\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.252612\n",
            "I0913 19:52:02.901961 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): 0.252612\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.055804\n",
            "I0913 19:52:02.906615 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.055804\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.305979\n",
            "I0913 19:52:02.911270 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.305979\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.523655\n",
            "I0913 19:52:02.916372 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.523655\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.454845\n",
            "I0913 19:52:02.920431 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): 0.454845\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.572577\n",
            "I0913 19:52:02.925002 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.572577\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.373551\n",
            "I0913 19:52:02.929648 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): 0.373551\n",
            "INFO:tensorflow:\t+ Loss/localization_loss: 0.226922\n",
            "I0913 19:52:02.931796 139874090080128 model_lib_v2.py:1018] \t+ Loss/localization_loss: 0.226922\n",
            "INFO:tensorflow:\t+ Loss/classification_loss: 0.541842\n",
            "I0913 19:52:02.934024 139874090080128 model_lib_v2.py:1018] \t+ Loss/classification_loss: 0.541842\n",
            "INFO:tensorflow:\t+ Loss/regularization_loss: 0.130351\n",
            "I0913 19:52:02.936302 139874090080128 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.130351\n",
            "INFO:tensorflow:\t+ Loss/total_loss: 0.899115\n",
            "I0913 19:52:02.938585 139874090080128 model_lib_v2.py:1018] \t+ Loss/total_loss: 0.899115\n",
            "INFO:tensorflow:Waiting for new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2\n",
            "I0913 19:52:03.221087 139874090080128 checkpoint_utils.py:136] Waiting for new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2\n",
            "INFO:tensorflow:Step 6000 per-step time 0.303s\n",
            "I0913 19:52:10.504784 140213675833216 model_lib_v2.py:707] Step 6000 per-step time 0.303s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0920256,\n",
            " 'Loss/localization_loss': 0.053566113,\n",
            " 'Loss/regularization_loss': 0.12494805,\n",
            " 'Loss/total_loss': 0.27053976,\n",
            " 'learning_rate': 0.07796223}\n",
            "I0913 19:52:10.505095 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.0920256,\n",
            " 'Loss/localization_loss': 0.053566113,\n",
            " 'Loss/regularization_loss': 0.12494805,\n",
            " 'Loss/total_loss': 0.27053976,\n",
            " 'learning_rate': 0.07796223}\n",
            "INFO:tensorflow:Found new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-7\n",
            "I0913 19:52:11.237353 139874090080128 checkpoint_utils.py:145] Found new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-7\n",
            "INFO:tensorflow:Finished eval step 0\n",
            "I0913 19:52:22.199090 139874090080128 model_lib_v2.py:966] Finished eval step 0\n",
            "INFO:tensorflow:Step 6100 per-step time 0.328s\n",
            "I0913 19:52:43.289821 140213675833216 model_lib_v2.py:707] Step 6100 per-step time 0.328s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08311947,\n",
            " 'Loss/localization_loss': 0.034626912,\n",
            " 'Loss/regularization_loss': 0.12439448,\n",
            " 'Loss/total_loss': 0.24214086,\n",
            " 'learning_rate': 0.077880636}\n",
            "I0913 19:52:43.291075 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.08311947,\n",
            " 'Loss/localization_loss': 0.034626912,\n",
            " 'Loss/regularization_loss': 0.12439448,\n",
            " 'Loss/total_loss': 0.24214086,\n",
            " 'learning_rate': 0.077880636}\n",
            "INFO:tensorflow:Finished eval step 100\n",
            "I0913 19:53:02.650498 139874090080128 model_lib_v2.py:966] Finished eval step 100\n",
            "INFO:tensorflow:Finished eval step 200\n",
            "I0913 19:53:15.026835 139874090080128 model_lib_v2.py:966] Finished eval step 200\n",
            "INFO:tensorflow:Step 6200 per-step time 0.340s\n",
            "I0913 19:53:17.252728 140213675833216 model_lib_v2.py:707] Step 6200 per-step time 0.340s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07621065,\n",
            " 'Loss/localization_loss': 0.03677167,\n",
            " 'Loss/regularization_loss': 0.123889185,\n",
            " 'Loss/total_loss': 0.23687151,\n",
            " 'learning_rate': 0.07779749}\n",
            "I0913 19:53:17.253142 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.07621065,\n",
            " 'Loss/localization_loss': 0.03677167,\n",
            " 'Loss/regularization_loss': 0.123889185,\n",
            " 'Loss/total_loss': 0.23687151,\n",
            " 'learning_rate': 0.07779749}\n",
            "INFO:tensorflow:Finished eval step 300\n",
            "I0913 19:53:27.072836 139874090080128 model_lib_v2.py:966] Finished eval step 300\n",
            "INFO:tensorflow:Finished eval step 400\n",
            "I0913 19:53:39.270642 139874090080128 model_lib_v2.py:966] Finished eval step 400\n",
            "INFO:tensorflow:Finished eval step 500\n",
            "I0913 19:53:51.517131 139874090080128 model_lib_v2.py:966] Finished eval step 500\n",
            "INFO:tensorflow:Step 6300 per-step time 0.350s\n",
            "I0913 19:53:52.259997 140213675833216 model_lib_v2.py:707] Step 6300 per-step time 0.350s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08674489,\n",
            " 'Loss/localization_loss': 0.057460763,\n",
            " 'Loss/regularization_loss': 0.12333567,\n",
            " 'Loss/total_loss': 0.26754132,\n",
            " 'learning_rate': 0.07771279}\n",
            "I0913 19:53:52.260446 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.08674489,\n",
            " 'Loss/localization_loss': 0.057460763,\n",
            " 'Loss/regularization_loss': 0.12333567,\n",
            " 'Loss/total_loss': 0.26754132,\n",
            " 'learning_rate': 0.07771279}\n",
            "INFO:tensorflow:Finished eval step 600\n",
            "I0913 19:54:04.046026 139874090080128 model_lib_v2.py:966] Finished eval step 600\n",
            "INFO:tensorflow:Finished eval step 700\n",
            "I0913 19:54:16.271498 139874090080128 model_lib_v2.py:966] Finished eval step 700\n",
            "INFO:tensorflow:Step 6400 per-step time 0.353s\n",
            "I0913 19:54:27.531248 140213675833216 model_lib_v2.py:707] Step 6400 per-step time 0.353s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.078992106,\n",
            " 'Loss/localization_loss': 0.04168154,\n",
            " 'Loss/regularization_loss': 0.12280494,\n",
            " 'Loss/total_loss': 0.24347858,\n",
            " 'learning_rate': 0.077626534}\n",
            "I0913 19:54:27.531664 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.078992106,\n",
            " 'Loss/localization_loss': 0.04168154,\n",
            " 'Loss/regularization_loss': 0.12280494,\n",
            " 'Loss/total_loss': 0.24347858,\n",
            " 'learning_rate': 0.077626534}\n",
            "INFO:tensorflow:Finished eval step 800\n",
            "I0913 19:54:28.405778 139874090080128 model_lib_v2.py:966] Finished eval step 800\n",
            "INFO:tensorflow:Finished eval step 900\n",
            "I0913 19:54:40.556896 139874090080128 model_lib_v2.py:966] Finished eval step 900\n",
            "INFO:tensorflow:Finished eval step 1000\n",
            "I0913 19:54:52.734445 139874090080128 model_lib_v2.py:966] Finished eval step 1000\n",
            "INFO:tensorflow:Step 6500 per-step time 0.352s\n",
            "I0913 19:55:02.737797 140213675833216 model_lib_v2.py:707] Step 6500 per-step time 0.352s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08985984,\n",
            " 'Loss/localization_loss': 0.04452539,\n",
            " 'Loss/regularization_loss': 0.12228538,\n",
            " 'Loss/total_loss': 0.2566706,\n",
            " 'learning_rate': 0.077538736}\n",
            "I0913 19:55:02.738199 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.08985984,\n",
            " 'Loss/localization_loss': 0.04452539,\n",
            " 'Loss/regularization_loss': 0.12228538,\n",
            " 'Loss/total_loss': 0.2566706,\n",
            " 'learning_rate': 0.077538736}\n",
            "INFO:tensorflow:Finished eval step 1100\n",
            "I0913 19:55:04.796082 139874090080128 model_lib_v2.py:966] Finished eval step 1100\n",
            "INFO:tensorflow:Finished eval step 1200\n",
            "I0913 19:55:16.874198 139874090080128 model_lib_v2.py:966] Finished eval step 1200\n",
            "INFO:tensorflow:Finished eval step 1300\n",
            "I0913 19:55:29.243660 139874090080128 model_lib_v2.py:966] Finished eval step 1300\n",
            "INFO:tensorflow:Step 6600 per-step time 0.351s\n",
            "I0913 19:55:37.837248 140213675833216 model_lib_v2.py:707] Step 6600 per-step time 0.351s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09090168,\n",
            " 'Loss/localization_loss': 0.059758212,\n",
            " 'Loss/regularization_loss': 0.12175198,\n",
            " 'Loss/total_loss': 0.27241188,\n",
            " 'learning_rate': 0.077449396}\n",
            "I0913 19:55:37.837617 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.09090168,\n",
            " 'Loss/localization_loss': 0.059758212,\n",
            " 'Loss/regularization_loss': 0.12175198,\n",
            " 'Loss/total_loss': 0.27241188,\n",
            " 'learning_rate': 0.077449396}\n",
            "INFO:tensorflow:Finished eval step 1400\n",
            "I0913 19:55:41.725095 139874090080128 model_lib_v2.py:966] Finished eval step 1400\n",
            "INFO:tensorflow:Finished eval step 1500\n",
            "I0913 19:55:56.758809 139874090080128 model_lib_v2.py:966] Finished eval step 1500\n",
            "INFO:tensorflow:Step 6700 per-step time 0.352s\n",
            "I0913 19:56:13.003109 140213675833216 model_lib_v2.py:707] Step 6700 per-step time 0.352s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07556883,\n",
            " 'Loss/localization_loss': 0.03906877,\n",
            " 'Loss/regularization_loss': 0.12120857,\n",
            " 'Loss/total_loss': 0.23584616,\n",
            " 'learning_rate': 0.077358514}\n",
            "I0913 19:56:13.003437 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.07556883,\n",
            " 'Loss/localization_loss': 0.03906877,\n",
            " 'Loss/regularization_loss': 0.12120857,\n",
            " 'Loss/total_loss': 0.23584616,\n",
            " 'learning_rate': 0.077358514}\n",
            "INFO:tensorflow:Performing evaluation on 1572 images.\n",
            "I0913 19:56:35.690546 139874090080128 coco_evaluation.py:293] Performing evaluation on 1572 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0913 19:56:35.708010 139874090080128 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.13s)\n",
            "I0913 19:56:35.833387 139874090080128 coco_tools.py:138] DONE (t=0.13s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "INFO:tensorflow:Step 6800 per-step time 0.304s\n",
            "I0913 19:56:43.406912 140213675833216 model_lib_v2.py:707] Step 6800 per-step time 0.304s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07773637,\n",
            " 'Loss/localization_loss': 0.03264499,\n",
            " 'Loss/regularization_loss': 0.12072686,\n",
            " 'Loss/total_loss': 0.23110822,\n",
            " 'learning_rate': 0.0772661}\n",
            "I0913 19:56:43.407301 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.07773637,\n",
            " 'Loss/localization_loss': 0.03264499,\n",
            " 'Loss/regularization_loss': 0.12072686,\n",
            " 'Loss/total_loss': 0.23110822,\n",
            " 'learning_rate': 0.0772661}\n",
            "INFO:tensorflow:Step 6900 per-step time 0.303s\n",
            "I0913 19:57:13.667944 140213675833216 model_lib_v2.py:707] Step 6900 per-step time 0.303s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.088340215,\n",
            " 'Loss/localization_loss': 0.044459455,\n",
            " 'Loss/regularization_loss': 0.12023542,\n",
            " 'Loss/total_loss': 0.2530351,\n",
            " 'learning_rate': 0.077172145}\n",
            "I0913 19:57:13.668318 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.088340215,\n",
            " 'Loss/localization_loss': 0.044459455,\n",
            " 'Loss/regularization_loss': 0.12023542,\n",
            " 'Loss/total_loss': 0.2530351,\n",
            " 'learning_rate': 0.077172145}\n",
            "INFO:tensorflow:Step 7000 per-step time 0.303s\n",
            "I0913 19:57:44.008116 140213675833216 model_lib_v2.py:707] Step 7000 per-step time 0.303s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09074066,\n",
            " 'Loss/localization_loss': 0.050089695,\n",
            " 'Loss/regularization_loss': 0.1196932,\n",
            " 'Loss/total_loss': 0.26052356,\n",
            " 'learning_rate': 0.07707667}\n",
            "I0913 19:57:44.008483 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.09074066,\n",
            " 'Loss/localization_loss': 0.050089695,\n",
            " 'Loss/regularization_loss': 0.1196932,\n",
            " 'Loss/total_loss': 0.26052356,\n",
            " 'learning_rate': 0.07707667}\n",
            "DONE (t=73.53s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=2.94s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.378\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.704\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.379\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.364\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.407\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.308\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.059\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.308\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.527\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.466\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.569\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.407\n",
            "INFO:tensorflow:Eval metrics at step 6000\n",
            "I0913 19:57:52.566298 139874090080128 model_lib_v2.py:1015] Eval metrics at step 6000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.378301\n",
            "I0913 19:57:52.571553 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.378301\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.704201\n",
            "I0913 19:57:52.575628 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.704201\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.379153\n",
            "I0913 19:57:52.578845 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.379153\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.364424\n",
            "I0913 19:57:52.583379 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): 0.364424\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.407426\n",
            "I0913 19:57:52.601316 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): 0.407426\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.307669\n",
            "I0913 19:57:52.615392 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): 0.307669\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.059065\n",
            "I0913 19:57:52.620378 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.059065\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.308486\n",
            "I0913 19:57:52.631840 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.308486\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.526623\n",
            "I0913 19:57:52.638437 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.526623\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.465629\n",
            "I0913 19:57:52.644897 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): 0.465629\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.569194\n",
            "I0913 19:57:52.651303 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.569194\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.407246\n",
            "I0913 19:57:52.658473 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): 0.407246\n",
            "INFO:tensorflow:\t+ Loss/localization_loss: 0.226076\n",
            "I0913 19:57:52.664050 139874090080128 model_lib_v2.py:1018] \t+ Loss/localization_loss: 0.226076\n",
            "INFO:tensorflow:\t+ Loss/classification_loss: 0.488037\n",
            "I0913 19:57:52.665779 139874090080128 model_lib_v2.py:1018] \t+ Loss/classification_loss: 0.488037\n",
            "INFO:tensorflow:\t+ Loss/regularization_loss: 0.124942\n",
            "I0913 19:57:52.668305 139874090080128 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.124942\n",
            "INFO:tensorflow:\t+ Loss/total_loss: 0.839055\n",
            "I0913 19:57:52.672770 139874090080128 model_lib_v2.py:1018] \t+ Loss/total_loss: 0.839055\n",
            "INFO:tensorflow:Waiting for new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2\n",
            "I0913 19:57:52.912762 139874090080128 checkpoint_utils.py:136] Waiting for new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2\n",
            "INFO:tensorflow:Found new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-8\n",
            "I0913 19:57:52.914249 139874090080128 checkpoint_utils.py:145] Found new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-8\n",
            "INFO:tensorflow:Finished eval step 0\n",
            "I0913 19:58:03.536162 139874090080128 model_lib_v2.py:966] Finished eval step 0\n",
            "INFO:tensorflow:Step 7100 per-step time 0.321s\n",
            "I0913 19:58:16.163293 140213675833216 model_lib_v2.py:707] Step 7100 per-step time 0.321s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06510778,\n",
            " 'Loss/localization_loss': 0.030259853,\n",
            " 'Loss/regularization_loss': 0.11917937,\n",
            " 'Loss/total_loss': 0.21454701,\n",
            " 'learning_rate': 0.07697967}\n",
            "I0913 19:58:16.163707 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.06510778,\n",
            " 'Loss/localization_loss': 0.030259853,\n",
            " 'Loss/regularization_loss': 0.11917937,\n",
            " 'Loss/total_loss': 0.21454701,\n",
            " 'learning_rate': 0.07697967}\n",
            "INFO:tensorflow:Finished eval step 100\n",
            "I0913 19:58:38.913989 139874090080128 model_lib_v2.py:966] Finished eval step 100\n",
            "INFO:tensorflow:Step 7200 per-step time 0.331s\n",
            "I0913 19:58:49.292850 140213675833216 model_lib_v2.py:707] Step 7200 per-step time 0.331s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07716318,\n",
            " 'Loss/localization_loss': 0.032469507,\n",
            " 'Loss/regularization_loss': 0.11870177,\n",
            " 'Loss/total_loss': 0.22833446,\n",
            " 'learning_rate': 0.07688115}\n",
            "I0913 19:58:49.293256 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.07716318,\n",
            " 'Loss/localization_loss': 0.032469507,\n",
            " 'Loss/regularization_loss': 0.11870177,\n",
            " 'Loss/total_loss': 0.22833446,\n",
            " 'learning_rate': 0.07688115}\n",
            "INFO:tensorflow:Finished eval step 200\n",
            "I0913 19:58:50.986710 139874090080128 model_lib_v2.py:966] Finished eval step 200\n",
            "INFO:tensorflow:Finished eval step 300\n",
            "I0913 19:59:04.764505 139874090080128 model_lib_v2.py:966] Finished eval step 300\n",
            "INFO:tensorflow:Finished eval step 400\n",
            "I0913 19:59:18.986397 139874090080128 model_lib_v2.py:966] Finished eval step 400\n",
            "INFO:tensorflow:Step 7300 per-step time 0.359s\n",
            "I0913 19:59:25.214598 140213675833216 model_lib_v2.py:707] Step 7300 per-step time 0.359s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.079993285,\n",
            " 'Loss/localization_loss': 0.039977003,\n",
            " 'Loss/regularization_loss': 0.11817422,\n",
            " 'Loss/total_loss': 0.23814452,\n",
            " 'learning_rate': 0.07678111}\n",
            "I0913 19:59:25.215004 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.079993285,\n",
            " 'Loss/localization_loss': 0.039977003,\n",
            " 'Loss/regularization_loss': 0.11817422,\n",
            " 'Loss/total_loss': 0.23814452,\n",
            " 'learning_rate': 0.07678111}\n",
            "INFO:tensorflow:Finished eval step 500\n",
            "I0913 19:59:31.257427 139874090080128 model_lib_v2.py:966] Finished eval step 500\n",
            "INFO:tensorflow:Finished eval step 600\n",
            "I0913 19:59:43.270298 139874090080128 model_lib_v2.py:966] Finished eval step 600\n",
            "INFO:tensorflow:Finished eval step 700\n",
            "I0913 19:59:55.448085 139874090080128 model_lib_v2.py:966] Finished eval step 700\n",
            "INFO:tensorflow:Step 7400 per-step time 0.351s\n",
            "I0913 20:00:00.297163 140213675833216 model_lib_v2.py:707] Step 7400 per-step time 0.351s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.074029125,\n",
            " 'Loss/localization_loss': 0.027349558,\n",
            " 'Loss/regularization_loss': 0.11764912,\n",
            " 'Loss/total_loss': 0.2190278,\n",
            " 'learning_rate': 0.076679565}\n",
            "I0913 20:00:00.297581 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.074029125,\n",
            " 'Loss/localization_loss': 0.027349558,\n",
            " 'Loss/regularization_loss': 0.11764912,\n",
            " 'Loss/total_loss': 0.2190278,\n",
            " 'learning_rate': 0.076679565}\n",
            "INFO:tensorflow:Finished eval step 800\n",
            "I0913 20:00:07.717470 139874090080128 model_lib_v2.py:966] Finished eval step 800\n",
            "INFO:tensorflow:Finished eval step 900\n",
            "I0913 20:00:19.974969 139874090080128 model_lib_v2.py:966] Finished eval step 900\n",
            "INFO:tensorflow:Finished eval step 1000\n",
            "I0913 20:00:32.436628 139874090080128 model_lib_v2.py:966] Finished eval step 1000\n",
            "INFO:tensorflow:Step 7500 per-step time 0.350s\n",
            "I0913 20:00:35.295342 140213675833216 model_lib_v2.py:707] Step 7500 per-step time 0.350s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07527117,\n",
            " 'Loss/localization_loss': 0.036096636,\n",
            " 'Loss/regularization_loss': 0.117170274,\n",
            " 'Loss/total_loss': 0.22853808,\n",
            " 'learning_rate': 0.0765765}\n",
            "I0913 20:00:35.295719 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.07527117,\n",
            " 'Loss/localization_loss': 0.036096636,\n",
            " 'Loss/regularization_loss': 0.117170274,\n",
            " 'Loss/total_loss': 0.22853808,\n",
            " 'learning_rate': 0.0765765}\n",
            "INFO:tensorflow:Finished eval step 1100\n",
            "I0913 20:00:44.525631 139874090080128 model_lib_v2.py:966] Finished eval step 1100\n",
            "INFO:tensorflow:Finished eval step 1200\n",
            "I0913 20:00:56.775068 139874090080128 model_lib_v2.py:966] Finished eval step 1200\n",
            "INFO:tensorflow:Finished eval step 1300\n",
            "I0913 20:01:08.866945 139874090080128 model_lib_v2.py:966] Finished eval step 1300\n",
            "INFO:tensorflow:Step 7600 per-step time 0.351s\n",
            "I0913 20:01:10.364071 140213675833216 model_lib_v2.py:707] Step 7600 per-step time 0.351s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08450145,\n",
            " 'Loss/localization_loss': 0.05061962,\n",
            " 'Loss/regularization_loss': 0.11664637,\n",
            " 'Loss/total_loss': 0.25176746,\n",
            " 'learning_rate': 0.07647194}\n",
            "I0913 20:01:10.364851 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.08450145,\n",
            " 'Loss/localization_loss': 0.05061962,\n",
            " 'Loss/regularization_loss': 0.11664637,\n",
            " 'Loss/total_loss': 0.25176746,\n",
            " 'learning_rate': 0.07647194}\n",
            "INFO:tensorflow:Finished eval step 1400\n",
            "I0913 20:01:20.952814 139874090080128 model_lib_v2.py:966] Finished eval step 1400\n",
            "INFO:tensorflow:Finished eval step 1500\n",
            "I0913 20:01:33.037919 139874090080128 model_lib_v2.py:966] Finished eval step 1500\n",
            "INFO:tensorflow:Step 7700 per-step time 0.346s\n",
            "I0913 20:01:44.973336 140213675833216 model_lib_v2.py:707] Step 7700 per-step time 0.346s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08584898,\n",
            " 'Loss/localization_loss': 0.04490343,\n",
            " 'Loss/regularization_loss': 0.11614022,\n",
            " 'Loss/total_loss': 0.24689263,\n",
            " 'learning_rate': 0.07636588}\n",
            "I0913 20:01:44.973637 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.08584898,\n",
            " 'Loss/localization_loss': 0.04490343,\n",
            " 'Loss/regularization_loss': 0.11614022,\n",
            " 'Loss/total_loss': 0.24689263,\n",
            " 'learning_rate': 0.07636588}\n",
            "INFO:tensorflow:Step 7800 per-step time 0.307s\n",
            "I0913 20:02:15.714747 140213675833216 model_lib_v2.py:707] Step 7800 per-step time 0.307s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07043356,\n",
            " 'Loss/localization_loss': 0.03365752,\n",
            " 'Loss/regularization_loss': 0.1156773,\n",
            " 'Loss/total_loss': 0.21976838,\n",
            " 'learning_rate': 0.07625833}\n",
            "I0913 20:02:15.715149 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.07043356,\n",
            " 'Loss/localization_loss': 0.03365752,\n",
            " 'Loss/regularization_loss': 0.1156773,\n",
            " 'Loss/total_loss': 0.21976838,\n",
            " 'learning_rate': 0.07625833}\n",
            "INFO:tensorflow:Performing evaluation on 1572 images.\n",
            "I0913 20:02:17.205722 139874090080128 coco_evaluation.py:293] Performing evaluation on 1572 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0913 20:02:17.244328 139874090080128 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.31s)\n",
            "I0913 20:02:17.553233 139874090080128 coco_tools.py:138] DONE (t=0.31s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "INFO:tensorflow:Step 7900 per-step time 0.305s\n",
            "I0913 20:02:46.256387 140213675833216 model_lib_v2.py:707] Step 7900 per-step time 0.305s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07966098,\n",
            " 'Loss/localization_loss': 0.04170166,\n",
            " 'Loss/regularization_loss': 0.11519033,\n",
            " 'Loss/total_loss': 0.23655297,\n",
            " 'learning_rate': 0.07614928}\n",
            "I0913 20:02:46.256767 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.07966098,\n",
            " 'Loss/localization_loss': 0.04170166,\n",
            " 'Loss/regularization_loss': 0.11519033,\n",
            " 'Loss/total_loss': 0.23655297,\n",
            " 'learning_rate': 0.07614928}\n",
            "INFO:tensorflow:Step 8000 per-step time 0.304s\n",
            "I0913 20:03:16.668464 140213675833216 model_lib_v2.py:707] Step 8000 per-step time 0.304s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08369093,\n",
            " 'Loss/localization_loss': 0.038557947,\n",
            " 'Loss/regularization_loss': 0.11470582,\n",
            " 'Loss/total_loss': 0.23695469,\n",
            " 'learning_rate': 0.07603875}\n",
            "I0913 20:03:16.668869 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.08369093,\n",
            " 'Loss/localization_loss': 0.038557947,\n",
            " 'Loss/regularization_loss': 0.11470582,\n",
            " 'Loss/total_loss': 0.23695469,\n",
            " 'learning_rate': 0.07603875}\n",
            "DONE (t=74.49s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=3.69s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.376\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.702\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.371\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.346\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.417\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.307\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.058\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.311\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.518\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.448\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.567\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.374\n",
            "INFO:tensorflow:Eval metrics at step 7000\n",
            "I0913 20:03:36.173875 139874090080128 model_lib_v2.py:1015] Eval metrics at step 7000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.376018\n",
            "I0913 20:03:36.179563 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.376018\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.702027\n",
            "I0913 20:03:36.183784 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.702027\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.371260\n",
            "I0913 20:03:36.188361 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.371260\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.346165\n",
            "I0913 20:03:36.192954 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): 0.346165\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.416988\n",
            "I0913 20:03:36.197726 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): 0.416988\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.306519\n",
            "I0913 20:03:36.202402 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): 0.306519\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.057914\n",
            "I0913 20:03:36.207061 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.057914\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.311019\n",
            "I0913 20:03:36.211837 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.311019\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.517606\n",
            "I0913 20:03:36.216306 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.517606\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.447573\n",
            "I0913 20:03:36.220888 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): 0.447573\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.566999\n",
            "I0913 20:03:36.226141 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.566999\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.373913\n",
            "I0913 20:03:36.230432 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): 0.373913\n",
            "INFO:tensorflow:\t+ Loss/localization_loss: 0.234511\n",
            "I0913 20:03:36.232581 139874090080128 model_lib_v2.py:1018] \t+ Loss/localization_loss: 0.234511\n",
            "INFO:tensorflow:\t+ Loss/classification_loss: 0.487791\n",
            "I0913 20:03:36.234934 139874090080128 model_lib_v2.py:1018] \t+ Loss/classification_loss: 0.487791\n",
            "INFO:tensorflow:\t+ Loss/regularization_loss: 0.119688\n",
            "I0913 20:03:36.237208 139874090080128 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.119688\n",
            "INFO:tensorflow:\t+ Loss/total_loss: 0.841991\n",
            "I0913 20:03:36.239598 139874090080128 model_lib_v2.py:1018] \t+ Loss/total_loss: 0.841991\n",
            "INFO:tensorflow:Waiting for new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2\n",
            "I0913 20:03:36.498014 139874090080128 checkpoint_utils.py:136] Waiting for new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2\n",
            "INFO:tensorflow:Found new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-9\n",
            "I0913 20:03:36.499319 139874090080128 checkpoint_utils.py:145] Found new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-9\n",
            "INFO:tensorflow:Finished eval step 0\n",
            "I0913 20:03:47.750557 139874090080128 model_lib_v2.py:966] Finished eval step 0\n",
            "INFO:tensorflow:Step 8100 per-step time 0.315s\n",
            "I0913 20:03:48.123335 140213675833216 model_lib_v2.py:707] Step 8100 per-step time 0.315s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.077956736,\n",
            " 'Loss/localization_loss': 0.042770643,\n",
            " 'Loss/regularization_loss': 0.114244625,\n",
            " 'Loss/total_loss': 0.234972,\n",
            " 'learning_rate': 0.07592674}\n",
            "I0913 20:03:48.123720 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.077956736,\n",
            " 'Loss/localization_loss': 0.042770643,\n",
            " 'Loss/regularization_loss': 0.114244625,\n",
            " 'Loss/total_loss': 0.234972,\n",
            " 'learning_rate': 0.07592674}\n",
            "INFO:tensorflow:Step 8200 per-step time 0.324s\n",
            "I0913 20:04:20.554936 140213675833216 model_lib_v2.py:707] Step 8200 per-step time 0.324s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.086499594,\n",
            " 'Loss/localization_loss': 0.049958955,\n",
            " 'Loss/regularization_loss': 0.113766894,\n",
            " 'Loss/total_loss': 0.25022542,\n",
            " 'learning_rate': 0.075813256}\n",
            "I0913 20:04:20.555711 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.086499594,\n",
            " 'Loss/localization_loss': 0.049958955,\n",
            " 'Loss/regularization_loss': 0.113766894,\n",
            " 'Loss/total_loss': 0.25022542,\n",
            " 'learning_rate': 0.075813256}\n",
            "INFO:tensorflow:Finished eval step 100\n",
            "I0913 20:04:24.618549 139874090080128 model_lib_v2.py:966] Finished eval step 100\n",
            "INFO:tensorflow:Finished eval step 200\n",
            "I0913 20:04:37.158354 139874090080128 model_lib_v2.py:966] Finished eval step 200\n",
            "INFO:tensorflow:Finished eval step 300\n",
            "I0913 20:04:49.565158 139874090080128 model_lib_v2.py:966] Finished eval step 300\n",
            "INFO:tensorflow:Step 8300 per-step time 0.347s\n",
            "I0913 20:04:55.211996 140213675833216 model_lib_v2.py:707] Step 8300 per-step time 0.347s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07779274,\n",
            " 'Loss/localization_loss': 0.034531794,\n",
            " 'Loss/regularization_loss': 0.113261685,\n",
            " 'Loss/total_loss': 0.22558622,\n",
            " 'learning_rate': 0.07569829}\n",
            "I0913 20:04:55.212422 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.07779274,\n",
            " 'Loss/localization_loss': 0.034531794,\n",
            " 'Loss/regularization_loss': 0.113261685,\n",
            " 'Loss/total_loss': 0.22558622,\n",
            " 'learning_rate': 0.07569829}\n",
            "INFO:tensorflow:Finished eval step 400\n",
            "I0913 20:05:02.140361 139874090080128 model_lib_v2.py:966] Finished eval step 400\n",
            "INFO:tensorflow:Finished eval step 500\n",
            "I0913 20:05:16.783133 139874090080128 model_lib_v2.py:966] Finished eval step 500\n",
            "INFO:tensorflow:Finished eval step 600\n",
            "I0913 20:05:30.622437 139874090080128 model_lib_v2.py:966] Finished eval step 600\n",
            "INFO:tensorflow:Step 8400 per-step time 0.362s\n",
            "I0913 20:05:31.447652 140213675833216 model_lib_v2.py:707] Step 8400 per-step time 0.362s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06364072,\n",
            " 'Loss/localization_loss': 0.023411514,\n",
            " 'Loss/regularization_loss': 0.11279694,\n",
            " 'Loss/total_loss': 0.19984917,\n",
            " 'learning_rate': 0.07558186}\n",
            "I0913 20:05:31.448048 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.06364072,\n",
            " 'Loss/localization_loss': 0.023411514,\n",
            " 'Loss/regularization_loss': 0.11279694,\n",
            " 'Loss/total_loss': 0.19984917,\n",
            " 'learning_rate': 0.07558186}\n",
            "INFO:tensorflow:Finished eval step 700\n",
            "I0913 20:05:42.743013 139874090080128 model_lib_v2.py:966] Finished eval step 700\n",
            "INFO:tensorflow:Finished eval step 800\n",
            "I0913 20:05:55.688963 139874090080128 model_lib_v2.py:966] Finished eval step 800\n",
            "INFO:tensorflow:Step 8500 per-step time 0.349s\n",
            "I0913 20:06:06.362368 140213675833216 model_lib_v2.py:707] Step 8500 per-step time 0.349s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.081999466,\n",
            " 'Loss/localization_loss': 0.049105603,\n",
            " 'Loss/regularization_loss': 0.112332344,\n",
            " 'Loss/total_loss': 0.24343741,\n",
            " 'learning_rate': 0.07546397}\n",
            "I0913 20:06:06.362789 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.081999466,\n",
            " 'Loss/localization_loss': 0.049105603,\n",
            " 'Loss/regularization_loss': 0.112332344,\n",
            " 'Loss/total_loss': 0.24343741,\n",
            " 'learning_rate': 0.07546397}\n",
            "INFO:tensorflow:Finished eval step 900\n",
            "I0913 20:06:08.381751 139874090080128 model_lib_v2.py:966] Finished eval step 900\n",
            "INFO:tensorflow:Finished eval step 1000\n",
            "I0913 20:06:21.000689 139874090080128 model_lib_v2.py:966] Finished eval step 1000\n",
            "INFO:tensorflow:Finished eval step 1100\n",
            "I0913 20:06:33.555386 139874090080128 model_lib_v2.py:966] Finished eval step 1100\n",
            "INFO:tensorflow:Step 8600 per-step time 0.350s\n",
            "I0913 20:06:41.314266 140213675833216 model_lib_v2.py:707] Step 8600 per-step time 0.350s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07573027,\n",
            " 'Loss/localization_loss': 0.037416834,\n",
            " 'Loss/regularization_loss': 0.111836545,\n",
            " 'Loss/total_loss': 0.22498366,\n",
            " 'learning_rate': 0.075344615}\n",
            "I0913 20:06:41.314739 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.07573027,\n",
            " 'Loss/localization_loss': 0.037416834,\n",
            " 'Loss/regularization_loss': 0.111836545,\n",
            " 'Loss/total_loss': 0.22498366,\n",
            " 'learning_rate': 0.075344615}\n",
            "INFO:tensorflow:Finished eval step 1200\n",
            "I0913 20:06:46.213889 139874090080128 model_lib_v2.py:966] Finished eval step 1200\n",
            "INFO:tensorflow:Finished eval step 1300\n",
            "I0913 20:06:58.713551 139874090080128 model_lib_v2.py:966] Finished eval step 1300\n",
            "INFO:tensorflow:Finished eval step 1400\n",
            "I0913 20:07:11.202491 139874090080128 model_lib_v2.py:966] Finished eval step 1400\n",
            "INFO:tensorflow:Step 8700 per-step time 0.348s\n",
            "I0913 20:07:16.159867 140213675833216 model_lib_v2.py:707] Step 8700 per-step time 0.348s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08524953,\n",
            " 'Loss/localization_loss': 0.035274796,\n",
            " 'Loss/regularization_loss': 0.11138047,\n",
            " 'Loss/total_loss': 0.2319048,\n",
            " 'learning_rate': 0.07522382}\n",
            "I0913 20:07:16.160231 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.08524953,\n",
            " 'Loss/localization_loss': 0.035274796,\n",
            " 'Loss/regularization_loss': 0.11138047,\n",
            " 'Loss/total_loss': 0.2319048,\n",
            " 'learning_rate': 0.07522382}\n",
            "INFO:tensorflow:Finished eval step 1500\n",
            "I0913 20:07:23.688457 139874090080128 model_lib_v2.py:966] Finished eval step 1500\n",
            "INFO:tensorflow:Step 8800 per-step time 0.325s\n",
            "I0913 20:07:48.683775 140213675833216 model_lib_v2.py:707] Step 8800 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07336065,\n",
            " 'Loss/localization_loss': 0.036230933,\n",
            " 'Loss/regularization_loss': 0.11092395,\n",
            " 'Loss/total_loss': 0.22051555,\n",
            " 'learning_rate': 0.07510157}\n",
            "I0913 20:07:48.684080 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.07336065,\n",
            " 'Loss/localization_loss': 0.036230933,\n",
            " 'Loss/regularization_loss': 0.11092395,\n",
            " 'Loss/total_loss': 0.22051555,\n",
            " 'learning_rate': 0.07510157}\n",
            "INFO:tensorflow:Performing evaluation on 1572 images.\n",
            "I0913 20:08:00.910937 139874090080128 coco_evaluation.py:293] Performing evaluation on 1572 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0913 20:08:00.951986 139874090080128 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.15s)\n",
            "I0913 20:08:01.098977 139874090080128 coco_tools.py:138] DONE (t=0.15s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "INFO:tensorflow:Step 8900 per-step time 0.306s\n",
            "I0913 20:08:19.280266 140213675833216 model_lib_v2.py:707] Step 8900 per-step time 0.306s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07956825,\n",
            " 'Loss/localization_loss': 0.036167603,\n",
            " 'Loss/regularization_loss': 0.110441506,\n",
            " 'Loss/total_loss': 0.22617736,\n",
            " 'learning_rate': 0.074977875}\n",
            "I0913 20:08:19.280743 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.07956825,\n",
            " 'Loss/localization_loss': 0.036167603,\n",
            " 'Loss/regularization_loss': 0.110441506,\n",
            " 'Loss/total_loss': 0.22617736,\n",
            " 'learning_rate': 0.074977875}\n",
            "INFO:tensorflow:Step 9000 per-step time 0.308s\n",
            "I0913 20:08:50.057760 140213675833216 model_lib_v2.py:707] Step 9000 per-step time 0.308s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07217475,\n",
            " 'Loss/localization_loss': 0.023340307,\n",
            " 'Loss/regularization_loss': 0.109980196,\n",
            " 'Loss/total_loss': 0.20549525,\n",
            " 'learning_rate': 0.07485275}\n",
            "I0913 20:08:50.058150 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.07217475,\n",
            " 'Loss/localization_loss': 0.023340307,\n",
            " 'Loss/regularization_loss': 0.109980196,\n",
            " 'Loss/total_loss': 0.20549525,\n",
            " 'learning_rate': 0.07485275}\n",
            "DONE (t=79.35s).\n",
            "Accumulating evaluation results...\n",
            "INFO:tensorflow:Step 9100 per-step time 0.316s\n",
            "I0913 20:09:21.664029 140213675833216 model_lib_v2.py:707] Step 9100 per-step time 0.316s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07209107,\n",
            " 'Loss/localization_loss': 0.023515254,\n",
            " 'Loss/regularization_loss': 0.1095557,\n",
            " 'Loss/total_loss': 0.20516202,\n",
            " 'learning_rate': 0.07472619}\n",
            "I0913 20:09:21.664548 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.07209107,\n",
            " 'Loss/localization_loss': 0.023515254,\n",
            " 'Loss/regularization_loss': 0.1095557,\n",
            " 'Loss/total_loss': 0.20516202,\n",
            " 'learning_rate': 0.07472619}\n",
            "DONE (t=3.17s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.379\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.699\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.382\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.360\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.413\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.381\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.057\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.316\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.537\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.477\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.577\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.494\n",
            "INFO:tensorflow:Eval metrics at step 8000\n",
            "I0913 20:09:23.954626 139874090080128 model_lib_v2.py:1015] Eval metrics at step 8000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.379307\n",
            "I0913 20:09:23.965521 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.379307\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.698511\n",
            "I0913 20:09:23.971428 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.698511\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.382250\n",
            "I0913 20:09:23.976520 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.382250\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.359620\n",
            "I0913 20:09:23.979986 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): 0.359620\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.412781\n",
            "I0913 20:09:23.985022 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): 0.412781\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.380723\n",
            "I0913 20:09:23.987235 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): 0.380723\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.056520\n",
            "I0913 20:09:23.991960 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.056520\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.315809\n",
            "I0913 20:09:23.993870 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.315809\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.537347\n",
            "I0913 20:09:24.004067 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.537347\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.476909\n",
            "I0913 20:09:24.015628 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): 0.476909\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.577460\n",
            "I0913 20:09:24.027314 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.577460\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.493841\n",
            "I0913 20:09:24.035743 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): 0.493841\n",
            "INFO:tensorflow:\t+ Loss/localization_loss: 0.240435\n",
            "I0913 20:09:24.043544 139874090080128 model_lib_v2.py:1018] \t+ Loss/localization_loss: 0.240435\n",
            "INFO:tensorflow:\t+ Loss/classification_loss: 0.511286\n",
            "I0913 20:09:24.055223 139874090080128 model_lib_v2.py:1018] \t+ Loss/classification_loss: 0.511286\n",
            "INFO:tensorflow:\t+ Loss/regularization_loss: 0.114701\n",
            "I0913 20:09:24.057729 139874090080128 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.114701\n",
            "INFO:tensorflow:\t+ Loss/total_loss: 0.866422\n",
            "I0913 20:09:24.059874 139874090080128 model_lib_v2.py:1018] \t+ Loss/total_loss: 0.866422\n",
            "INFO:tensorflow:Waiting for new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2\n",
            "I0913 20:09:24.364130 139874090080128 checkpoint_utils.py:136] Waiting for new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2\n",
            "INFO:tensorflow:Found new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-10\n",
            "I0913 20:09:24.365618 139874090080128 checkpoint_utils.py:145] Found new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-10\n",
            "INFO:tensorflow:Finished eval step 0\n",
            "I0913 20:09:35.721487 139874090080128 model_lib_v2.py:966] Finished eval step 0\n",
            "INFO:tensorflow:Step 9200 per-step time 0.319s\n",
            "I0913 20:09:53.531814 140213675833216 model_lib_v2.py:707] Step 9200 per-step time 0.319s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0833654,\n",
            " 'Loss/localization_loss': 0.044355106,\n",
            " 'Loss/regularization_loss': 0.10908833,\n",
            " 'Loss/total_loss': 0.23680884,\n",
            " 'learning_rate': 0.07459819}\n",
            "I0913 20:09:53.532190 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.0833654,\n",
            " 'Loss/localization_loss': 0.044355106,\n",
            " 'Loss/regularization_loss': 0.10908833,\n",
            " 'Loss/total_loss': 0.23680884,\n",
            " 'learning_rate': 0.07459819}\n",
            "INFO:tensorflow:Finished eval step 100\n",
            "I0913 20:10:11.202818 139874090080128 model_lib_v2.py:966] Finished eval step 100\n",
            "INFO:tensorflow:Finished eval step 200\n",
            "I0913 20:10:23.687787 139874090080128 model_lib_v2.py:966] Finished eval step 200\n",
            "INFO:tensorflow:Step 9300 per-step time 0.339s\n",
            "I0913 20:10:27.391081 140213675833216 model_lib_v2.py:707] Step 9300 per-step time 0.339s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.071840025,\n",
            " 'Loss/localization_loss': 0.03130238,\n",
            " 'Loss/regularization_loss': 0.10862794,\n",
            " 'Loss/total_loss': 0.21177036,\n",
            " 'learning_rate': 0.074468784}\n",
            "I0913 20:10:27.391540 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.071840025,\n",
            " 'Loss/localization_loss': 0.03130238,\n",
            " 'Loss/regularization_loss': 0.10862794,\n",
            " 'Loss/total_loss': 0.21177036,\n",
            " 'learning_rate': 0.074468784}\n",
            "INFO:tensorflow:Finished eval step 300\n",
            "I0913 20:10:35.969089 139874090080128 model_lib_v2.py:966] Finished eval step 300\n",
            "INFO:tensorflow:Finished eval step 400\n",
            "I0913 20:10:48.462275 139874090080128 model_lib_v2.py:966] Finished eval step 400\n",
            "INFO:tensorflow:Finished eval step 500\n",
            "I0913 20:11:01.290699 139874090080128 model_lib_v2.py:966] Finished eval step 500\n",
            "INFO:tensorflow:Step 9400 per-step time 0.351s\n",
            "I0913 20:11:02.478522 140213675833216 model_lib_v2.py:707] Step 9400 per-step time 0.351s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07870376,\n",
            " 'Loss/localization_loss': 0.034841187,\n",
            " 'Loss/regularization_loss': 0.10821578,\n",
            " 'Loss/total_loss': 0.22176072,\n",
            " 'learning_rate': 0.074337944}\n",
            "I0913 20:11:02.478912 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.07870376,\n",
            " 'Loss/localization_loss': 0.034841187,\n",
            " 'Loss/regularization_loss': 0.10821578,\n",
            " 'Loss/total_loss': 0.22176072,\n",
            " 'learning_rate': 0.074337944}\n",
            "INFO:tensorflow:Finished eval step 600\n",
            "I0913 20:11:13.615106 139874090080128 model_lib_v2.py:966] Finished eval step 600\n",
            "INFO:tensorflow:Finished eval step 700\n",
            "I0913 20:11:29.489879 139874090080128 model_lib_v2.py:966] Finished eval step 700\n",
            "INFO:tensorflow:Step 9500 per-step time 0.357s\n",
            "I0913 20:11:38.207697 140213675833216 model_lib_v2.py:707] Step 9500 per-step time 0.357s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07650865,\n",
            " 'Loss/localization_loss': 0.034030803,\n",
            " 'Loss/regularization_loss': 0.107747704,\n",
            " 'Loss/total_loss': 0.21828716,\n",
            " 'learning_rate': 0.074205704}\n",
            "I0913 20:11:38.208056 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.07650865,\n",
            " 'Loss/localization_loss': 0.034030803,\n",
            " 'Loss/regularization_loss': 0.107747704,\n",
            " 'Loss/total_loss': 0.21828716,\n",
            " 'learning_rate': 0.074205704}\n",
            "INFO:tensorflow:Finished eval step 800\n",
            "I0913 20:11:42.381333 139874090080128 model_lib_v2.py:966] Finished eval step 800\n",
            "INFO:tensorflow:Finished eval step 900\n",
            "I0913 20:11:54.836889 139874090080128 model_lib_v2.py:966] Finished eval step 900\n",
            "INFO:tensorflow:Finished eval step 1000\n",
            "I0913 20:12:07.462986 139874090080128 model_lib_v2.py:966] Finished eval step 1000\n",
            "INFO:tensorflow:Step 9600 per-step time 0.348s\n",
            "I0913 20:12:13.024295 140213675833216 model_lib_v2.py:707] Step 9600 per-step time 0.348s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08618773,\n",
            " 'Loss/localization_loss': 0.037964538,\n",
            " 'Loss/regularization_loss': 0.107288554,\n",
            " 'Loss/total_loss': 0.23144081,\n",
            " 'learning_rate': 0.07407206}\n",
            "I0913 20:12:13.024659 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.08618773,\n",
            " 'Loss/localization_loss': 0.037964538,\n",
            " 'Loss/regularization_loss': 0.107288554,\n",
            " 'Loss/total_loss': 0.23144081,\n",
            " 'learning_rate': 0.07407206}\n",
            "INFO:tensorflow:Finished eval step 1100\n",
            "I0913 20:12:19.716087 139874090080128 model_lib_v2.py:966] Finished eval step 1100\n",
            "INFO:tensorflow:Finished eval step 1200\n",
            "I0913 20:12:32.302088 139874090080128 model_lib_v2.py:966] Finished eval step 1200\n",
            "INFO:tensorflow:Finished eval step 1300\n",
            "I0913 20:12:45.376033 139874090080128 model_lib_v2.py:966] Finished eval step 1300\n",
            "INFO:tensorflow:Step 9700 per-step time 0.348s\n",
            "I0913 20:12:47.841811 140213675833216 model_lib_v2.py:707] Step 9700 per-step time 0.348s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07386013,\n",
            " 'Loss/localization_loss': 0.029665561,\n",
            " 'Loss/regularization_loss': 0.106885,\n",
            " 'Loss/total_loss': 0.21041068,\n",
            " 'learning_rate': 0.073937014}\n",
            "I0913 20:12:47.842249 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.07386013,\n",
            " 'Loss/localization_loss': 0.029665561,\n",
            " 'Loss/regularization_loss': 0.106885,\n",
            " 'Loss/total_loss': 0.21041068,\n",
            " 'learning_rate': 0.073937014}\n",
            "INFO:tensorflow:Finished eval step 1400\n",
            "I0913 20:12:57.608794 139874090080128 model_lib_v2.py:966] Finished eval step 1400\n",
            "INFO:tensorflow:Finished eval step 1500\n",
            "I0913 20:13:10.072781 139874090080128 model_lib_v2.py:966] Finished eval step 1500\n",
            "INFO:tensorflow:Step 9800 per-step time 0.346s\n",
            "I0913 20:13:22.463238 140213675833216 model_lib_v2.py:707] Step 9800 per-step time 0.346s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.085004345,\n",
            " 'Loss/localization_loss': 0.0423407,\n",
            " 'Loss/regularization_loss': 0.10643427,\n",
            " 'Loss/total_loss': 0.23377931,\n",
            " 'learning_rate': 0.07380057}\n",
            "I0913 20:13:22.463559 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.085004345,\n",
            " 'Loss/localization_loss': 0.0423407,\n",
            " 'Loss/regularization_loss': 0.10643427,\n",
            " 'Loss/total_loss': 0.23377931,\n",
            " 'learning_rate': 0.07380057}\n",
            "INFO:tensorflow:Performing evaluation on 1572 images.\n",
            "I0913 20:13:48.864973 139874090080128 coco_evaluation.py:293] Performing evaluation on 1572 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0913 20:13:48.921132 139874090080128 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.17s)\n",
            "I0913 20:13:49.089585 139874090080128 coco_tools.py:138] DONE (t=0.17s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "INFO:tensorflow:Step 9900 per-step time 0.303s\n",
            "I0913 20:13:52.789411 140213675833216 model_lib_v2.py:707] Step 9900 per-step time 0.303s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.062317237,\n",
            " 'Loss/localization_loss': 0.032684457,\n",
            " 'Loss/regularization_loss': 0.10597655,\n",
            " 'Loss/total_loss': 0.20097825,\n",
            " 'learning_rate': 0.073662736}\n",
            "I0913 20:13:52.789763 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.062317237,\n",
            " 'Loss/localization_loss': 0.032684457,\n",
            " 'Loss/regularization_loss': 0.10597655,\n",
            " 'Loss/total_loss': 0.20097825,\n",
            " 'learning_rate': 0.073662736}\n",
            "INFO:tensorflow:Step 10000 per-step time 0.305s\n",
            "I0913 20:14:23.317104 140213675833216 model_lib_v2.py:707] Step 10000 per-step time 0.305s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0746606,\n",
            " 'Loss/localization_loss': 0.033241697,\n",
            " 'Loss/regularization_loss': 0.105550125,\n",
            " 'Loss/total_loss': 0.21345243,\n",
            " 'learning_rate': 0.07352352}\n",
            "I0913 20:14:23.317507 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.0746606,\n",
            " 'Loss/localization_loss': 0.033241697,\n",
            " 'Loss/regularization_loss': 0.105550125,\n",
            " 'Loss/total_loss': 0.21345243,\n",
            " 'learning_rate': 0.07352352}\n",
            "INFO:tensorflow:Step 10100 per-step time 0.321s\n",
            "I0913 20:14:55.435914 140213675833216 model_lib_v2.py:707] Step 10100 per-step time 0.321s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.071271375,\n",
            " 'Loss/localization_loss': 0.034984857,\n",
            " 'Loss/regularization_loss': 0.105125576,\n",
            " 'Loss/total_loss': 0.21138181,\n",
            " 'learning_rate': 0.07338293}\n",
            "I0913 20:14:55.436305 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.071271375,\n",
            " 'Loss/localization_loss': 0.034984857,\n",
            " 'Loss/regularization_loss': 0.105125576,\n",
            " 'Loss/total_loss': 0.21138181,\n",
            " 'learning_rate': 0.07338293}\n",
            "DONE (t=80.60s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=2.94s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.397\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.718\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.411\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.372\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.435\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.357\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.060\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.323\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.539\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.476\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.582\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.437\n",
            "INFO:tensorflow:Eval metrics at step 9000\n",
            "I0913 20:15:12.892142 139874090080128 model_lib_v2.py:1015] Eval metrics at step 9000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.396546\n",
            "I0913 20:15:12.899890 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.396546\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.717715\n",
            "I0913 20:15:12.913975 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.717715\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.411367\n",
            "I0913 20:15:12.919553 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.411367\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.372490\n",
            "I0913 20:15:12.926866 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): 0.372490\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.434753\n",
            "I0913 20:15:12.930747 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): 0.434753\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.357045\n",
            "I0913 20:15:12.935402 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): 0.357045\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.059679\n",
            "I0913 20:15:12.939924 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.059679\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.322914\n",
            "I0913 20:15:12.944624 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.322914\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.538786\n",
            "I0913 20:15:12.949310 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.538786\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.476263\n",
            "I0913 20:15:12.953912 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): 0.476263\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.581797\n",
            "I0913 20:15:12.958588 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.581797\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.436957\n",
            "I0913 20:15:12.963315 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): 0.436957\n",
            "INFO:tensorflow:\t+ Loss/localization_loss: 0.225830\n",
            "I0913 20:15:12.965492 139874090080128 model_lib_v2.py:1018] \t+ Loss/localization_loss: 0.225830\n",
            "INFO:tensorflow:\t+ Loss/classification_loss: 0.491832\n",
            "I0913 20:15:12.967742 139874090080128 model_lib_v2.py:1018] \t+ Loss/classification_loss: 0.491832\n",
            "INFO:tensorflow:\t+ Loss/regularization_loss: 0.109976\n",
            "I0913 20:15:12.970055 139874090080128 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.109976\n",
            "INFO:tensorflow:\t+ Loss/total_loss: 0.827638\n",
            "I0913 20:15:12.972433 139874090080128 model_lib_v2.py:1018] \t+ Loss/total_loss: 0.827638\n",
            "INFO:tensorflow:Waiting for new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2\n",
            "I0913 20:15:13.274868 139874090080128 checkpoint_utils.py:136] Waiting for new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2\n",
            "INFO:tensorflow:Found new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-11\n",
            "I0913 20:15:13.276232 139874090080128 checkpoint_utils.py:145] Found new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-11\n",
            "INFO:tensorflow:Finished eval step 0\n",
            "I0913 20:15:24.516386 139874090080128 model_lib_v2.py:966] Finished eval step 0\n",
            "INFO:tensorflow:Step 10200 per-step time 0.306s\n",
            "I0913 20:15:26.060450 140213675833216 model_lib_v2.py:707] Step 10200 per-step time 0.306s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07812243,\n",
            " 'Loss/localization_loss': 0.05023388,\n",
            " 'Loss/regularization_loss': 0.10468066,\n",
            " 'Loss/total_loss': 0.23303697,\n",
            " 'learning_rate': 0.073240966}\n",
            "I0913 20:15:26.060796 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.07812243,\n",
            " 'Loss/localization_loss': 0.05023388,\n",
            " 'Loss/regularization_loss': 0.10468066,\n",
            " 'Loss/total_loss': 0.23303697,\n",
            " 'learning_rate': 0.073240966}\n",
            "INFO:tensorflow:Step 10300 per-step time 0.325s\n",
            "I0913 20:15:58.519427 140213675833216 model_lib_v2.py:707] Step 10300 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07047928,\n",
            " 'Loss/localization_loss': 0.029829731,\n",
            " 'Loss/regularization_loss': 0.10426298,\n",
            " 'Loss/total_loss': 0.20457199,\n",
            " 'learning_rate': 0.07309763}\n",
            "I0913 20:15:58.519801 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.07047928,\n",
            " 'Loss/localization_loss': 0.029829731,\n",
            " 'Loss/regularization_loss': 0.10426298,\n",
            " 'Loss/total_loss': 0.20457199,\n",
            " 'learning_rate': 0.07309763}\n",
            "INFO:tensorflow:Finished eval step 100\n",
            "I0913 20:16:00.282577 139874090080128 model_lib_v2.py:966] Finished eval step 100\n",
            "INFO:tensorflow:Finished eval step 200\n",
            "I0913 20:16:13.218882 139874090080128 model_lib_v2.py:966] Finished eval step 200\n",
            "INFO:tensorflow:Finished eval step 300\n",
            "I0913 20:16:25.468822 139874090080128 model_lib_v2.py:966] Finished eval step 300\n",
            "INFO:tensorflow:Step 10400 per-step time 0.352s\n",
            "I0913 20:16:33.697481 140213675833216 model_lib_v2.py:707] Step 10400 per-step time 0.352s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06197642,\n",
            " 'Loss/localization_loss': 0.024553418,\n",
            " 'Loss/regularization_loss': 0.103858694,\n",
            " 'Loss/total_loss': 0.19038853,\n",
            " 'learning_rate': 0.07295293}\n",
            "I0913 20:16:33.697914 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.06197642,\n",
            " 'Loss/localization_loss': 0.024553418,\n",
            " 'Loss/regularization_loss': 0.103858694,\n",
            " 'Loss/total_loss': 0.19038853,\n",
            " 'learning_rate': 0.07295293}\n",
            "INFO:tensorflow:Finished eval step 400\n",
            "I0913 20:16:37.887038 139874090080128 model_lib_v2.py:966] Finished eval step 400\n",
            "INFO:tensorflow:Finished eval step 500\n",
            "I0913 20:16:50.504326 139874090080128 model_lib_v2.py:966] Finished eval step 500\n",
            "INFO:tensorflow:Finished eval step 600\n",
            "I0913 20:17:02.846601 139874090080128 model_lib_v2.py:966] Finished eval step 600\n",
            "INFO:tensorflow:Step 10500 per-step time 0.351s\n",
            "I0913 20:17:08.815995 140213675833216 model_lib_v2.py:707] Step 10500 per-step time 0.351s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.061214272,\n",
            " 'Loss/localization_loss': 0.021463813,\n",
            " 'Loss/regularization_loss': 0.1034163,\n",
            " 'Loss/total_loss': 0.18609439,\n",
            " 'learning_rate': 0.07280689}\n",
            "I0913 20:17:08.816628 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.061214272,\n",
            " 'Loss/localization_loss': 0.021463813,\n",
            " 'Loss/regularization_loss': 0.1034163,\n",
            " 'Loss/total_loss': 0.18609439,\n",
            " 'learning_rate': 0.07280689}\n",
            "INFO:tensorflow:Finished eval step 700\n",
            "I0913 20:17:15.060639 139874090080128 model_lib_v2.py:966] Finished eval step 700\n",
            "INFO:tensorflow:Finished eval step 800\n",
            "I0913 20:17:30.109057 139874090080128 model_lib_v2.py:966] Finished eval step 800\n",
            "INFO:tensorflow:Finished eval step 900\n",
            "I0913 20:17:43.867195 139874090080128 model_lib_v2.py:966] Finished eval step 900\n",
            "INFO:tensorflow:Step 10600 per-step time 0.357s\n",
            "I0913 20:17:44.495285 140213675833216 model_lib_v2.py:707] Step 10600 per-step time 0.357s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06778003,\n",
            " 'Loss/localization_loss': 0.030927625,\n",
            " 'Loss/regularization_loss': 0.102986835,\n",
            " 'Loss/total_loss': 0.20169449,\n",
            " 'learning_rate': 0.07265949}\n",
            "I0913 20:17:44.495679 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.06778003,\n",
            " 'Loss/localization_loss': 0.030927625,\n",
            " 'Loss/regularization_loss': 0.102986835,\n",
            " 'Loss/total_loss': 0.20169449,\n",
            " 'learning_rate': 0.07265949}\n",
            "INFO:tensorflow:Finished eval step 1000\n",
            "I0913 20:17:56.334097 139874090080128 model_lib_v2.py:966] Finished eval step 1000\n",
            "INFO:tensorflow:Finished eval step 1100\n",
            "I0913 20:18:08.715889 139874090080128 model_lib_v2.py:966] Finished eval step 1100\n",
            "INFO:tensorflow:Step 10700 per-step time 0.350s\n",
            "I0913 20:18:19.520598 140213675833216 model_lib_v2.py:707] Step 10700 per-step time 0.350s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.065049365,\n",
            " 'Loss/localization_loss': 0.036291365,\n",
            " 'Loss/regularization_loss': 0.10259006,\n",
            " 'Loss/total_loss': 0.2039308,\n",
            " 'learning_rate': 0.07251076}\n",
            "I0913 20:18:19.521005 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.065049365,\n",
            " 'Loss/localization_loss': 0.036291365,\n",
            " 'Loss/regularization_loss': 0.10259006,\n",
            " 'Loss/total_loss': 0.2039308,\n",
            " 'learning_rate': 0.07251076}\n",
            "INFO:tensorflow:Finished eval step 1200\n",
            "I0913 20:18:20.978119 139874090080128 model_lib_v2.py:966] Finished eval step 1200\n",
            "INFO:tensorflow:Finished eval step 1300\n",
            "I0913 20:18:33.551344 139874090080128 model_lib_v2.py:966] Finished eval step 1300\n",
            "INFO:tensorflow:Finished eval step 1400\n",
            "I0913 20:18:45.934374 139874090080128 model_lib_v2.py:966] Finished eval step 1400\n",
            "INFO:tensorflow:Step 10800 per-step time 0.351s\n",
            "I0913 20:18:54.580395 140213675833216 model_lib_v2.py:707] Step 10800 per-step time 0.351s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0656619,\n",
            " 'Loss/localization_loss': 0.029260255,\n",
            " 'Loss/regularization_loss': 0.102155074,\n",
            " 'Loss/total_loss': 0.19707723,\n",
            " 'learning_rate': 0.07236068}\n",
            "I0913 20:18:54.580815 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.0656619,\n",
            " 'Loss/localization_loss': 0.029260255,\n",
            " 'Loss/regularization_loss': 0.102155074,\n",
            " 'Loss/total_loss': 0.19707723,\n",
            " 'learning_rate': 0.07236068}\n",
            "INFO:tensorflow:Finished eval step 1500\n",
            "I0913 20:18:58.453444 139874090080128 model_lib_v2.py:966] Finished eval step 1500\n",
            "INFO:tensorflow:Performing evaluation on 1572 images.\n",
            "I0913 20:19:07.201193 139874090080128 coco_evaluation.py:293] Performing evaluation on 1572 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0913 20:19:07.220077 139874090080128 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.14s)\n",
            "I0913 20:19:07.363478 139874090080128 coco_tools.py:138] DONE (t=0.14s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "INFO:tensorflow:Step 10900 per-step time 0.322s\n",
            "I0913 20:19:26.760868 140213675833216 model_lib_v2.py:707] Step 10900 per-step time 0.322s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.059755825,\n",
            " 'Loss/localization_loss': 0.028081354,\n",
            " 'Loss/regularization_loss': 0.101739325,\n",
            " 'Loss/total_loss': 0.1895765,\n",
            " 'learning_rate': 0.07220927}\n",
            "I0913 20:19:26.761244 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.059755825,\n",
            " 'Loss/localization_loss': 0.028081354,\n",
            " 'Loss/regularization_loss': 0.101739325,\n",
            " 'Loss/total_loss': 0.1895765,\n",
            " 'learning_rate': 0.07220927}\n",
            "INFO:tensorflow:Step 11000 per-step time 0.303s\n",
            "I0913 20:19:57.036382 140213675833216 model_lib_v2.py:707] Step 11000 per-step time 0.303s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0693985,\n",
            " 'Loss/localization_loss': 0.041152384,\n",
            " 'Loss/regularization_loss': 0.101334244,\n",
            " 'Loss/total_loss': 0.21188512,\n",
            " 'learning_rate': 0.07205655}\n",
            "I0913 20:19:57.036728 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.0693985,\n",
            " 'Loss/localization_loss': 0.041152384,\n",
            " 'Loss/regularization_loss': 0.101334244,\n",
            " 'Loss/total_loss': 0.21188512,\n",
            " 'learning_rate': 0.07205655}\n",
            "DONE (t=80.57s).\n",
            "Accumulating evaluation results...\n",
            "INFO:tensorflow:Step 11100 per-step time 0.319s\n",
            "I0913 20:20:28.977261 140213675833216 model_lib_v2.py:707] Step 11100 per-step time 0.319s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06768018,\n",
            " 'Loss/localization_loss': 0.032927886,\n",
            " 'Loss/regularization_loss': 0.10090766,\n",
            " 'Loss/total_loss': 0.20151573,\n",
            " 'learning_rate': 0.07190249}\n",
            "I0913 20:20:28.977640 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.06768018,\n",
            " 'Loss/localization_loss': 0.032927886,\n",
            " 'Loss/regularization_loss': 0.10090766,\n",
            " 'Loss/total_loss': 0.20151573,\n",
            " 'learning_rate': 0.07190249}\n",
            "DONE (t=4.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.374\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.690\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.374\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.368\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.395\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.364\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.056\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.303\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.522\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.475\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.554\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.468\n",
            "INFO:tensorflow:Eval metrics at step 10000\n",
            "I0913 20:20:32.319265 139874090080128 model_lib_v2.py:1015] Eval metrics at step 10000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.373517\n",
            "I0913 20:20:32.325586 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.373517\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.689930\n",
            "I0913 20:20:32.333808 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.689930\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.373511\n",
            "I0913 20:20:32.337592 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.373511\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.368346\n",
            "I0913 20:20:32.342374 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): 0.368346\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.394966\n",
            "I0913 20:20:32.351411 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): 0.394966\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.364033\n",
            "I0913 20:20:32.362308 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): 0.364033\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.055759\n",
            "I0913 20:20:32.366548 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.055759\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.303466\n",
            "I0913 20:20:32.371067 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.303466\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.522114\n",
            "I0913 20:20:32.377909 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.522114\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.475153\n",
            "I0913 20:20:32.382809 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): 0.475153\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.553839\n",
            "I0913 20:20:32.387196 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.553839\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.468478\n",
            "I0913 20:20:32.391880 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): 0.468478\n",
            "INFO:tensorflow:\t+ Loss/localization_loss: 0.248431\n",
            "I0913 20:20:32.394043 139874090080128 model_lib_v2.py:1018] \t+ Loss/localization_loss: 0.248431\n",
            "INFO:tensorflow:\t+ Loss/classification_loss: 0.548113\n",
            "I0913 20:20:32.396400 139874090080128 model_lib_v2.py:1018] \t+ Loss/classification_loss: 0.548113\n",
            "INFO:tensorflow:\t+ Loss/regularization_loss: 0.105546\n",
            "I0913 20:20:32.398702 139874090080128 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.105546\n",
            "INFO:tensorflow:\t+ Loss/total_loss: 0.902090\n",
            "I0913 20:20:32.400975 139874090080128 model_lib_v2.py:1018] \t+ Loss/total_loss: 0.902090\n",
            "INFO:tensorflow:Waiting for new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2\n",
            "I0913 20:20:32.693766 139874090080128 checkpoint_utils.py:136] Waiting for new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2\n",
            "INFO:tensorflow:Found new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-12\n",
            "I0913 20:20:32.695037 139874090080128 checkpoint_utils.py:145] Found new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-12\n",
            "INFO:tensorflow:Finished eval step 0\n",
            "I0913 20:20:44.081446 139874090080128 model_lib_v2.py:966] Finished eval step 0\n",
            "INFO:tensorflow:Step 11200 per-step time 0.318s\n",
            "I0913 20:21:00.729190 140213675833216 model_lib_v2.py:707] Step 11200 per-step time 0.318s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07416497,\n",
            " 'Loss/localization_loss': 0.03092219,\n",
            " 'Loss/regularization_loss': 0.10051233,\n",
            " 'Loss/total_loss': 0.20559949,\n",
            " 'learning_rate': 0.07174714}\n",
            "I0913 20:21:00.729583 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.07416497,\n",
            " 'Loss/localization_loss': 0.03092219,\n",
            " 'Loss/regularization_loss': 0.10051233,\n",
            " 'Loss/total_loss': 0.20559949,\n",
            " 'learning_rate': 0.07174714}\n",
            "INFO:tensorflow:Finished eval step 100\n",
            "I0913 20:21:19.197275 139874090080128 model_lib_v2.py:966] Finished eval step 100\n",
            "INFO:tensorflow:Finished eval step 200\n",
            "I0913 20:21:31.680819 139874090080128 model_lib_v2.py:966] Finished eval step 200\n",
            "INFO:tensorflow:Step 11300 per-step time 0.335s\n",
            "I0913 20:21:34.226243 140213675833216 model_lib_v2.py:707] Step 11300 per-step time 0.335s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0820262,\n",
            " 'Loss/localization_loss': 0.03440952,\n",
            " 'Loss/regularization_loss': 0.10011658,\n",
            " 'Loss/total_loss': 0.2165523,\n",
            " 'learning_rate': 0.071590476}\n",
            "I0913 20:21:34.226567 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.0820262,\n",
            " 'Loss/localization_loss': 0.03440952,\n",
            " 'Loss/regularization_loss': 0.10011658,\n",
            " 'Loss/total_loss': 0.2165523,\n",
            " 'learning_rate': 0.071590476}\n",
            "INFO:tensorflow:Finished eval step 300\n",
            "I0913 20:21:43.920323 139874090080128 model_lib_v2.py:966] Finished eval step 300\n",
            "INFO:tensorflow:Finished eval step 400\n",
            "I0913 20:21:56.412835 139874090080128 model_lib_v2.py:966] Finished eval step 400\n",
            "INFO:tensorflow:Finished eval step 500\n",
            "I0913 20:22:08.852749 139874090080128 model_lib_v2.py:966] Finished eval step 500\n",
            "INFO:tensorflow:Step 11400 per-step time 0.351s\n",
            "I0913 20:22:09.372683 140213675833216 model_lib_v2.py:707] Step 11400 per-step time 0.351s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07607987,\n",
            " 'Loss/localization_loss': 0.038822472,\n",
            " 'Loss/regularization_loss': 0.09971413,\n",
            " 'Loss/total_loss': 0.21461648,\n",
            " 'learning_rate': 0.071432516}\n",
            "I0913 20:22:09.373063 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.07607987,\n",
            " 'Loss/localization_loss': 0.038822472,\n",
            " 'Loss/regularization_loss': 0.09971413,\n",
            " 'Loss/total_loss': 0.21461648,\n",
            " 'learning_rate': 0.071432516}\n",
            "INFO:tensorflow:Finished eval step 600\n",
            "I0913 20:22:21.262197 139874090080128 model_lib_v2.py:966] Finished eval step 600\n",
            "INFO:tensorflow:Finished eval step 700\n",
            "I0913 20:22:34.187709 139874090080128 model_lib_v2.py:966] Finished eval step 700\n",
            "INFO:tensorflow:Step 11500 per-step time 0.347s\n",
            "I0913 20:22:44.105004 140213675833216 model_lib_v2.py:707] Step 11500 per-step time 0.347s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07775591,\n",
            " 'Loss/localization_loss': 0.03777888,\n",
            " 'Loss/regularization_loss': 0.09931049,\n",
            " 'Loss/total_loss': 0.21484528,\n",
            " 'learning_rate': 0.07127326}\n",
            "I0913 20:22:44.105479 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.07775591,\n",
            " 'Loss/localization_loss': 0.03777888,\n",
            " 'Loss/regularization_loss': 0.09931049,\n",
            " 'Loss/total_loss': 0.21484528,\n",
            " 'learning_rate': 0.07127326}\n",
            "INFO:tensorflow:Finished eval step 800\n",
            "I0913 20:22:46.752679 139874090080128 model_lib_v2.py:966] Finished eval step 800\n",
            "INFO:tensorflow:Finished eval step 900\n",
            "I0913 20:22:59.353356 139874090080128 model_lib_v2.py:966] Finished eval step 900\n",
            "INFO:tensorflow:Finished eval step 1000\n",
            "I0913 20:23:11.807753 139874090080128 model_lib_v2.py:966] Finished eval step 1000\n",
            "INFO:tensorflow:Step 11600 per-step time 0.355s\n",
            "I0913 20:23:19.575243 140213675833216 model_lib_v2.py:707] Step 11600 per-step time 0.355s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06578624,\n",
            " 'Loss/localization_loss': 0.024889754,\n",
            " 'Loss/regularization_loss': 0.09896821,\n",
            " 'Loss/total_loss': 0.1896442,\n",
            " 'learning_rate': 0.071112715}\n",
            "I0913 20:23:19.575628 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.06578624,\n",
            " 'Loss/localization_loss': 0.024889754,\n",
            " 'Loss/regularization_loss': 0.09896821,\n",
            " 'Loss/total_loss': 0.1896442,\n",
            " 'learning_rate': 0.071112715}\n",
            "INFO:tensorflow:Finished eval step 1100\n",
            "I0913 20:23:27.733089 139874090080128 model_lib_v2.py:966] Finished eval step 1100\n",
            "INFO:tensorflow:Finished eval step 1200\n",
            "I0913 20:23:40.172808 139874090080128 model_lib_v2.py:966] Finished eval step 1200\n",
            "INFO:tensorflow:Finished eval step 1300\n",
            "I0913 20:23:52.652951 139874090080128 model_lib_v2.py:966] Finished eval step 1300\n",
            "INFO:tensorflow:Step 11700 per-step time 0.356s\n",
            "I0913 20:23:55.118100 140213675833216 model_lib_v2.py:707] Step 11700 per-step time 0.356s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.062186535,\n",
            " 'Loss/localization_loss': 0.025586506,\n",
            " 'Loss/regularization_loss': 0.09859129,\n",
            " 'Loss/total_loss': 0.18636432,\n",
            " 'learning_rate': 0.070950896}\n",
            "I0913 20:23:55.118490 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.062186535,\n",
            " 'Loss/localization_loss': 0.025586506,\n",
            " 'Loss/regularization_loss': 0.09859129,\n",
            " 'Loss/total_loss': 0.18636432,\n",
            " 'learning_rate': 0.070950896}\n",
            "INFO:tensorflow:Finished eval step 1400\n",
            "I0913 20:24:05.137426 139874090080128 model_lib_v2.py:966] Finished eval step 1400\n",
            "INFO:tensorflow:Finished eval step 1500\n",
            "I0913 20:24:18.227429 139874090080128 model_lib_v2.py:966] Finished eval step 1500\n",
            "INFO:tensorflow:Performing evaluation on 1572 images.\n",
            "I0913 20:24:27.126217 139874090080128 coco_evaluation.py:293] Performing evaluation on 1572 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0913 20:24:27.152027 139874090080128 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.16s)\n",
            "I0913 20:24:27.307335 139874090080128 coco_tools.py:138] DONE (t=0.16s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "INFO:tensorflow:Step 11800 per-step time 0.347s\n",
            "I0913 20:24:29.794077 140213675833216 model_lib_v2.py:707] Step 11800 per-step time 0.347s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08186963,\n",
            " 'Loss/localization_loss': 0.044306725,\n",
            " 'Loss/regularization_loss': 0.098188534,\n",
            " 'Loss/total_loss': 0.22436489,\n",
            " 'learning_rate': 0.07078781}\n",
            "I0913 20:24:29.794473 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.08186963,\n",
            " 'Loss/localization_loss': 0.044306725,\n",
            " 'Loss/regularization_loss': 0.098188534,\n",
            " 'Loss/total_loss': 0.22436489,\n",
            " 'learning_rate': 0.07078781}\n",
            "INFO:tensorflow:Step 11900 per-step time 0.304s\n",
            "I0913 20:25:00.163194 140213675833216 model_lib_v2.py:707] Step 11900 per-step time 0.304s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07241035,\n",
            " 'Loss/localization_loss': 0.0388352,\n",
            " 'Loss/regularization_loss': 0.097811565,\n",
            " 'Loss/total_loss': 0.20905712,\n",
            " 'learning_rate': 0.07062345}\n",
            "I0913 20:25:00.163545 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.07241035,\n",
            " 'Loss/localization_loss': 0.0388352,\n",
            " 'Loss/regularization_loss': 0.097811565,\n",
            " 'Loss/total_loss': 0.20905712,\n",
            " 'learning_rate': 0.07062345}\n",
            "INFO:tensorflow:Step 12000 per-step time 0.303s\n",
            "I0913 20:25:30.445004 140213675833216 model_lib_v2.py:707] Step 12000 per-step time 0.303s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06717736,\n",
            " 'Loss/localization_loss': 0.035623413,\n",
            " 'Loss/regularization_loss': 0.09744992,\n",
            " 'Loss/total_loss': 0.20025069,\n",
            " 'learning_rate': 0.07045784}\n",
            "I0913 20:25:30.445406 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.06717736,\n",
            " 'Loss/localization_loss': 0.035623413,\n",
            " 'Loss/regularization_loss': 0.09744992,\n",
            " 'Loss/total_loss': 0.20025069,\n",
            " 'learning_rate': 0.07045784}\n",
            "DONE (t=74.82s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=3.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.374\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.688\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.377\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.344\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.413\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.354\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.058\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.309\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.518\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.447\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.566\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.436\n",
            "INFO:tensorflow:Eval metrics at step 11000\n",
            "I0913 20:25:45.507800 139874090080128 model_lib_v2.py:1015] Eval metrics at step 11000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.373575\n",
            "I0913 20:25:45.513705 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.373575\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.687754\n",
            "I0913 20:25:45.517552 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.687754\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.376941\n",
            "I0913 20:25:45.522168 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.376941\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.343856\n",
            "I0913 20:25:45.526944 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): 0.343856\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.412747\n",
            "I0913 20:25:45.531503 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): 0.412747\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.353912\n",
            "I0913 20:25:45.536136 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): 0.353912\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.057741\n",
            "I0913 20:25:45.540788 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.057741\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.308857\n",
            "I0913 20:25:45.545460 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.308857\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.518111\n",
            "I0913 20:25:45.550054 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.518111\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.446927\n",
            "I0913 20:25:45.554650 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): 0.446927\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.566292\n",
            "I0913 20:25:45.559241 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.566292\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.435870\n",
            "I0913 20:25:45.573080 139874090080128 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): 0.435870\n",
            "INFO:tensorflow:\t+ Loss/localization_loss: 0.236319\n",
            "I0913 20:25:45.575922 139874090080128 model_lib_v2.py:1018] \t+ Loss/localization_loss: 0.236319\n",
            "INFO:tensorflow:\t+ Loss/classification_loss: 0.596307\n",
            "I0913 20:25:45.577197 139874090080128 model_lib_v2.py:1018] \t+ Loss/classification_loss: 0.596307\n",
            "INFO:tensorflow:\t+ Loss/regularization_loss: 0.101330\n",
            "I0913 20:25:45.579069 139874090080128 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.101330\n",
            "INFO:tensorflow:\t+ Loss/total_loss: 0.933956\n",
            "I0913 20:25:45.581430 139874090080128 model_lib_v2.py:1018] \t+ Loss/total_loss: 0.933956\n",
            "INFO:tensorflow:Waiting for new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2\n",
            "I0913 20:25:45.832273 139874090080128 checkpoint_utils.py:136] Waiting for new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2\n",
            "INFO:tensorflow:Found new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-13\n",
            "I0913 20:25:45.833554 139874090080128 checkpoint_utils.py:145] Found new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-13\n",
            "INFO:tensorflow:Finished eval step 0\n",
            "I0913 20:25:57.058681 139874090080128 model_lib_v2.py:966] Finished eval step 0\n",
            "INFO:tensorflow:Step 12100 per-step time 0.314s\n",
            "I0913 20:26:01.896475 140213675833216 model_lib_v2.py:707] Step 12100 per-step time 0.314s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07446249,\n",
            " 'Loss/localization_loss': 0.033909336,\n",
            " 'Loss/regularization_loss': 0.09704838,\n",
            " 'Loss/total_loss': 0.2054202,\n",
            " 'learning_rate': 0.07029097}\n",
            "I0913 20:26:01.897008 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.07446249,\n",
            " 'Loss/localization_loss': 0.033909336,\n",
            " 'Loss/regularization_loss': 0.09704838,\n",
            " 'Loss/total_loss': 0.2054202,\n",
            " 'learning_rate': 0.07029097}\n",
            "INFO:tensorflow:Step 12200 per-step time 0.330s\n",
            "I0913 20:26:34.917752 140213675833216 model_lib_v2.py:707] Step 12200 per-step time 0.330s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06717828,\n",
            " 'Loss/localization_loss': 0.026470562,\n",
            " 'Loss/regularization_loss': 0.09669816,\n",
            " 'Loss/total_loss': 0.190347,\n",
            " 'learning_rate': 0.07012285}\n",
            "I0913 20:26:34.918167 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.06717828,\n",
            " 'Loss/localization_loss': 0.026470562,\n",
            " 'Loss/regularization_loss': 0.09669816,\n",
            " 'Loss/total_loss': 0.190347,\n",
            " 'learning_rate': 0.07012285}\n",
            "INFO:tensorflow:Finished eval step 100\n",
            "I0913 20:26:37.793111 139874090080128 model_lib_v2.py:966] Finished eval step 100\n",
            "INFO:tensorflow:Finished eval step 200\n",
            "I0913 20:26:50.231603 139874090080128 model_lib_v2.py:966] Finished eval step 200\n",
            "INFO:tensorflow:Finished eval step 300\n",
            "I0913 20:27:02.735523 139874090080128 model_lib_v2.py:966] Finished eval step 300\n",
            "INFO:tensorflow:Step 12300 per-step time 0.349s\n",
            "I0913 20:27:09.815029 140213675833216 model_lib_v2.py:707] Step 12300 per-step time 0.349s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06857068,\n",
            " 'Loss/localization_loss': 0.032713328,\n",
            " 'Loss/regularization_loss': 0.096325986,\n",
            " 'Loss/total_loss': 0.19760999,\n",
            " 'learning_rate': 0.06995351}\n",
            "I0913 20:27:09.815430 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.06857068,\n",
            " 'Loss/localization_loss': 0.032713328,\n",
            " 'Loss/regularization_loss': 0.096325986,\n",
            " 'Loss/total_loss': 0.19760999,\n",
            " 'learning_rate': 0.06995351}\n",
            "INFO:tensorflow:Finished eval step 400\n",
            "I0913 20:27:15.333564 139874090080128 model_lib_v2.py:966] Finished eval step 400\n",
            "INFO:tensorflow:Finished eval step 500\n",
            "I0913 20:27:28.303731 139874090080128 model_lib_v2.py:966] Finished eval step 500\n",
            "INFO:tensorflow:Finished eval step 600\n",
            "I0913 20:27:40.486095 139874090080128 model_lib_v2.py:966] Finished eval step 600\n",
            "INFO:tensorflow:Step 12400 per-step time 0.350s\n",
            "I0913 20:27:44.831723 140213675833216 model_lib_v2.py:707] Step 12400 per-step time 0.350s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07373339,\n",
            " 'Loss/localization_loss': 0.040586922,\n",
            " 'Loss/regularization_loss': 0.09594543,\n",
            " 'Loss/total_loss': 0.21026574,\n",
            " 'learning_rate': 0.06978292}\n",
            "I0913 20:27:44.832108 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.07373339,\n",
            " 'Loss/localization_loss': 0.040586922,\n",
            " 'Loss/regularization_loss': 0.09594543,\n",
            " 'Loss/total_loss': 0.21026574,\n",
            " 'learning_rate': 0.06978292}\n",
            "INFO:tensorflow:Finished eval step 700\n",
            "I0913 20:27:52.597588 139874090080128 model_lib_v2.py:966] Finished eval step 700\n",
            "INFO:tensorflow:Finished eval step 800\n",
            "I0913 20:28:04.996066 139874090080128 model_lib_v2.py:966] Finished eval step 800\n",
            "INFO:tensorflow:Finished eval step 900\n",
            "I0913 20:28:17.517132 139874090080128 model_lib_v2.py:966] Finished eval step 900\n",
            "INFO:tensorflow:Step 12500 per-step time 0.350s\n",
            "I0913 20:28:19.825885 140213675833216 model_lib_v2.py:707] Step 12500 per-step time 0.350s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.063139886,\n",
            " 'Loss/localization_loss': 0.028767476,\n",
            " 'Loss/regularization_loss': 0.09558435,\n",
            " 'Loss/total_loss': 0.18749171,\n",
            " 'learning_rate': 0.06961112}\n",
            "I0913 20:28:19.826271 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.063139886,\n",
            " 'Loss/localization_loss': 0.028767476,\n",
            " 'Loss/regularization_loss': 0.09558435,\n",
            " 'Loss/total_loss': 0.18749171,\n",
            " 'learning_rate': 0.06961112}\n",
            "INFO:tensorflow:Finished eval step 1000\n",
            "I0913 20:28:29.967849 139874090080128 model_lib_v2.py:966] Finished eval step 1000\n",
            "INFO:tensorflow:Finished eval step 1100\n",
            "I0913 20:28:42.380297 139874090080128 model_lib_v2.py:966] Finished eval step 1100\n",
            "INFO:tensorflow:Step 12600 per-step time 0.352s\n",
            "I0913 20:28:55.011422 140213675833216 model_lib_v2.py:707] Step 12600 per-step time 0.352s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06830117,\n",
            " 'Loss/localization_loss': 0.027503945,\n",
            " 'Loss/regularization_loss': 0.09524624,\n",
            " 'Loss/total_loss': 0.19105136,\n",
            " 'learning_rate': 0.06943809}\n",
            "I0913 20:28:55.011985 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.06830117,\n",
            " 'Loss/localization_loss': 0.027503945,\n",
            " 'Loss/regularization_loss': 0.09524624,\n",
            " 'Loss/total_loss': 0.19105136,\n",
            " 'learning_rate': 0.06943809}\n",
            "INFO:tensorflow:Finished eval step 1200\n",
            "I0913 20:28:55.023248 139874090080128 model_lib_v2.py:966] Finished eval step 1200\n",
            "INFO:tensorflow:Finished eval step 1300\n",
            "I0913 20:29:08.226069 139874090080128 model_lib_v2.py:966] Finished eval step 1300\n",
            "INFO:tensorflow:Finished eval step 1400\n",
            "I0913 20:29:23.552650 139874090080128 model_lib_v2.py:966] Finished eval step 1400\n",
            "INFO:tensorflow:Step 12700 per-step time 0.362s\n",
            "I0913 20:29:31.190310 140213675833216 model_lib_v2.py:707] Step 12700 per-step time 0.362s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08591244,\n",
            " 'Loss/localization_loss': 0.037197717,\n",
            " 'Loss/regularization_loss': 0.09486357,\n",
            " 'Loss/total_loss': 0.21797374,\n",
            " 'learning_rate': 0.06926386}\n",
            "I0913 20:29:31.190692 140213675833216 model_lib_v2.py:708] {'Loss/classification_loss': 0.08591244,\n",
            " 'Loss/localization_loss': 0.037197717,\n",
            " 'Loss/regularization_loss': 0.09486357,\n",
            " 'Loss/total_loss': 0.21797374,\n",
            " 'learning_rate': 0.06926386}\n",
            "INFO:tensorflow:Finished eval step 1500\n",
            "I0913 20:29:36.253109 139874090080128 model_lib_v2.py:966] Finished eval step 1500\n",
            "INFO:tensorflow:Performing evaluation on 1572 images.\n",
            "I0913 20:29:44.987945 139874090080128 coco_evaluation.py:293] Performing evaluation on 1572 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0913 20:29:45.031602 139874090080128 coco_tools.py:116] Loading and preparing annotation results...\n"
          ]
        }
      ],
      "source": [
        "TRAINING_SCRIPT = os.path.join(paths[\"obj_detection_api\"],\"model_main_tf2.py\")\n",
        "\n",
        "trainCmd = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps={}\".format(TRAINING_SCRIPT, os.path.join(paths[\"custom_models\"], CUSTOM_MODEL_NAME), paths[\"custom_model_config\"],NOF_STEPS)\n",
        "evalCmd = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths[\"custom_model_dir\"], paths[\"custom_model_config\"], paths[\"custom_model_dir\"])\n",
        "\n",
        "\n",
        "!{trainCmd} & {evalCmd}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48UbAlBYABdm"
      },
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znEgFtf8FBFb"
      },
      "source": [
        "Create evaluation files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVU-sCcKAEsl"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths[\"custom_model_dir\"], paths[\"custom_model_config\"], paths[\"custom_model_dir\"])\n",
        "print(command)\n",
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-7T7lCXFDkB"
      },
      "source": [
        "load tensorboard extension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtrLXvLkFGDa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d7d0742-a657-4ebf-a398-54a7d91216c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wSwNl4KC5ad"
      },
      "source": [
        "Evaluate training loss with Tensorbord"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTVjx1iNCoI5"
      },
      "outputs": [],
      "source": [
        "trainingLogDir = os.path.join(paths[\"custom_model_dir\"],\"train\")\n",
        "%tensorboard --logdir {trainingLogDir}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_C4MS6sJFI8L"
      },
      "source": [
        "Evaluate Test results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Q9fomE9FmSk"
      },
      "outputs": [],
      "source": [
        "evalLogDir = paths[\"custom_model_dir\"]\n",
        "%tensorboard --logdir {evalLogDir} --samples_per_plugin=images=100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8vcvgfDGqRY"
      },
      "source": [
        "# Export and save the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfhZPheA7J8N"
      },
      "source": [
        "Export the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcCmhsRwX8t9"
      },
      "outputs": [],
      "source": [
        "import shutil as sh\n",
        "\n",
        "# Copy exporter script\n",
        "expScriptLocalPath = os.path.join(paths[\"training\"],\"exporter_main_v2.py\")\n",
        "if not os.path.exists(expScriptLocalPath):\n",
        "  sh.copyfile(os.path.join(paths['obj_detection_api'], \"exporter_main_v2.py\"), expScriptLocalPath)\n",
        "\n",
        "# run the script\n",
        "!python {expScriptLocalPath} --input_type image_tensor --pipeline_config_path {paths['custom_model_config']} --trained_checkpoint_dir {paths['custom_model_dir']} --output_directory {os.path.join(paths[\"model_export_dir\"], CUSTOM_MODEL_NAME)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e04RputVaKyP"
      },
      "source": [
        "Push exported model to git branch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKElQdVvaNEQ"
      },
      "outputs": [],
      "source": [
        "%cd {paths[\"github_repo\"]}\n",
        "!git fetch\n",
        "!git status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AupXj-N3aSYR"
      },
      "outputs": [],
      "source": [
        "!git pull\n",
        "!git status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsxN-SIMabF9"
      },
      "outputs": [],
      "source": [
        "!git add {paths[\"model_export_dir\"]}\n",
        "!git status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzIjIfBea7KQ"
      },
      "outputs": [],
      "source": [
        "!git config --global user.email \"linus.heinzelmann@uni-ulm.de\"\n",
        "!git config --global user.name \"lheinzel\"\n",
        "!git commit -m \"model trained on colab\"\n",
        "!git status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eS6NmonQlI_z"
      },
      "outputs": [],
      "source": [
        "!git remote"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exRRBU4VlMn_"
      },
      "outputs": [],
      "source": [
        "!git push origin {GIT_BRANCH}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HneSlBWyh7Rh"
      },
      "source": [
        "# Save the current training state\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KF8S_t6iFJV",
        "outputId": "7c2c128b-446a-486c-c52d-6105d41a3255"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UAVHRBuildingDetection\n",
            "On branch SSD_MobNet_320x320_Augmenter\n",
            "Your branch is up to date with 'origin/SSD_MobNet_320x320_Augmenter'.\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add/rm <file>...\" to update what will be committed)\n",
            "  (use \"git checkout -- <file>...\" to discard changes in working directory)\n",
            "\n",
            "\t\u001b[31mmodified:   Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/checkpoint\u001b[m\n",
            "\t\u001b[31mdeleted:    Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-10.data-00000-of-00001\u001b[m\n",
            "\t\u001b[31mdeleted:    Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-10.index\u001b[m\n",
            "\t\u001b[31mdeleted:    Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-11.data-00000-of-00001\u001b[m\n",
            "\t\u001b[31mdeleted:    Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-11.index\u001b[m\n",
            "\t\u001b[31mdeleted:    Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-5.data-00000-of-00001\u001b[m\n",
            "\t\u001b[31mdeleted:    Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-5.index\u001b[m\n",
            "\t\u001b[31mdeleted:    Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-6.data-00000-of-00001\u001b[m\n",
            "\t\u001b[31mdeleted:    Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-6.index\u001b[m\n",
            "\t\u001b[31mdeleted:    Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-7.data-00000-of-00001\u001b[m\n",
            "\t\u001b[31mdeleted:    Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-7.index\u001b[m\n",
            "\t\u001b[31mdeleted:    Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-8.data-00000-of-00001\u001b[m\n",
            "\t\u001b[31mdeleted:    Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-8.index\u001b[m\n",
            "\t\u001b[31mdeleted:    Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-9.data-00000-of-00001\u001b[m\n",
            "\t\u001b[31mdeleted:    Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-9.index\u001b[m\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\n",
            "\t\u001b[31mTensorflow/scripts/preprocessing/__pycache__/\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/annotations/test.record\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/annotations/train.record\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/images/\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/pretrained_model/\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-15.data-00000-of-00001\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-15.index\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-16.data-00000-of-00001\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-16.index\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-17.data-00000-of-00001\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-17.index\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-18.data-00000-of-00001\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-18.index\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-19.data-00000-of-00001\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-19.index\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-20.data-00000-of-00001\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-20.index\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-21.data-00000-of-00001\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-21.index\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663084211.6f95152c6f26.1567.0.v2\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663084636.6f95152c6f26.1567.1.v2\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663084947.6f95152c6f26.1567.2.v2\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663085259.6f95152c6f26.1567.3.v2\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663085573.6f95152c6f26.1567.4.v2\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663085888.6f95152c6f26.1567.5.v2\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663086202.6f95152c6f26.1567.6.v2\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663086516.6f95152c6f26.1567.7.v2\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663086827.6f95152c6f26.1567.8.v2\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663087140.6f95152c6f26.1567.9.v2\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663087452.6f95152c6f26.1567.10.v2\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/train/events.out.tfevents.1663084221.6f95152c6f26.1566.0.v2\u001b[m\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
          ]
        }
      ],
      "source": [
        "%cd {paths[\"github_repo\"]}\n",
        "!git fetch\n",
        "!git status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4YaB3LOiFvU",
        "outputId": "d40e9806-1083-4f10-c00c-cfcdafa609c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n",
            "On branch SSD_MobNet_320x320_Augmenter\n",
            "Your branch is up to date with 'origin/SSD_MobNet_320x320_Augmenter'.\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add/rm <file>...\" to update what will be committed)\n",
            "  (use \"git checkout -- <file>...\" to discard changes in working directory)\n",
            "\n",
            "\t\u001b[31mmodified:   Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/checkpoint\u001b[m\n",
            "\t\u001b[31mdeleted:    Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-10.data-00000-of-00001\u001b[m\n",
            "\t\u001b[31mdeleted:    Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-10.index\u001b[m\n",
            "\t\u001b[31mdeleted:    Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-11.data-00000-of-00001\u001b[m\n",
            "\t\u001b[31mdeleted:    Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-11.index\u001b[m\n",
            "\t\u001b[31mdeleted:    Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-5.data-00000-of-00001\u001b[m\n",
            "\t\u001b[31mdeleted:    Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-5.index\u001b[m\n",
            "\t\u001b[31mdeleted:    Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-6.data-00000-of-00001\u001b[m\n",
            "\t\u001b[31mdeleted:    Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-6.index\u001b[m\n",
            "\t\u001b[31mdeleted:    Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-7.data-00000-of-00001\u001b[m\n",
            "\t\u001b[31mdeleted:    Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-7.index\u001b[m\n",
            "\t\u001b[31mdeleted:    Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-8.data-00000-of-00001\u001b[m\n",
            "\t\u001b[31mdeleted:    Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-8.index\u001b[m\n",
            "\t\u001b[31mdeleted:    Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-9.data-00000-of-00001\u001b[m\n",
            "\t\u001b[31mdeleted:    Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-9.index\u001b[m\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\n",
            "\t\u001b[31mTensorflow/scripts/preprocessing/__pycache__/\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/annotations/test.record\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/annotations/train.record\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/images/\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/pretrained_model/\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-15.data-00000-of-00001\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-15.index\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-16.data-00000-of-00001\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-16.index\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-17.data-00000-of-00001\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-17.index\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-18.data-00000-of-00001\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-18.index\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-19.data-00000-of-00001\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-19.index\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-20.data-00000-of-00001\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-20.index\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-21.data-00000-of-00001\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-21.index\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663084211.6f95152c6f26.1567.0.v2\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663084636.6f95152c6f26.1567.1.v2\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663084947.6f95152c6f26.1567.2.v2\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663085259.6f95152c6f26.1567.3.v2\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663085573.6f95152c6f26.1567.4.v2\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663085888.6f95152c6f26.1567.5.v2\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663086202.6f95152c6f26.1567.6.v2\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663086516.6f95152c6f26.1567.7.v2\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663086827.6f95152c6f26.1567.8.v2\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663087140.6f95152c6f26.1567.9.v2\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663087452.6f95152c6f26.1567.10.v2\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/train/events.out.tfevents.1663084221.6f95152c6f26.1566.0.v2\u001b[m\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
          ]
        }
      ],
      "source": [
        "!git pull\n",
        "!git status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxMFPySLiPeJ",
        "outputId": "0b13c932-b206-40c1-aa85-eda27087ebb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch SSD_MobNet_320x320_Augmenter\n",
            "Your branch is up to date with 'origin/SSD_MobNet_320x320_Augmenter'.\n",
            "\n",
            "Changes to be committed:\n",
            "  (use \"git reset HEAD <file>...\" to unstage)\n",
            "\n",
            "\t\u001b[32mmodified:   Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/checkpoint\u001b[m\n",
            "\t\u001b[32mdeleted:    Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-10.index\u001b[m\n",
            "\t\u001b[32mdeleted:    Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-11.index\u001b[m\n",
            "\t\u001b[32mrenamed:    Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-9.data-00000-of-00001 -> Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-15.data-00000-of-00001\u001b[m\n",
            "\t\u001b[32mnew file:   Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-15.index\u001b[m\n",
            "\t\u001b[32mrenamed:    Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-5.data-00000-of-00001 -> Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-16.data-00000-of-00001\u001b[m\n",
            "\t\u001b[32mnew file:   Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-16.index\u001b[m\n",
            "\t\u001b[32mrenamed:    Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-10.data-00000-of-00001 -> Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-17.data-00000-of-00001\u001b[m\n",
            "\t\u001b[32mnew file:   Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-17.index\u001b[m\n",
            "\t\u001b[32mnew file:   Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-18.data-00000-of-00001\u001b[m\n",
            "\t\u001b[32mnew file:   Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-18.index\u001b[m\n",
            "\t\u001b[32mrenamed:    Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-7.data-00000-of-00001 -> Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-19.data-00000-of-00001\u001b[m\n",
            "\t\u001b[32mnew file:   Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-19.index\u001b[m\n",
            "\t\u001b[32mrenamed:    Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-11.data-00000-of-00001 -> Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-20.data-00000-of-00001\u001b[m\n",
            "\t\u001b[32mnew file:   Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-20.index\u001b[m\n",
            "\t\u001b[32mrenamed:    Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-8.data-00000-of-00001 -> Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-21.data-00000-of-00001\u001b[m\n",
            "\t\u001b[32mnew file:   Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-21.index\u001b[m\n",
            "\t\u001b[32mdeleted:    Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-5.index\u001b[m\n",
            "\t\u001b[32mdeleted:    Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-6.index\u001b[m\n",
            "\t\u001b[32mdeleted:    Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-7.index\u001b[m\n",
            "\t\u001b[32mdeleted:    Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-8.index\u001b[m\n",
            "\t\u001b[32mdeleted:    Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-9.index\u001b[m\n",
            "\t\u001b[32mrenamed:    Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-6.data-00000-of-00001 -> Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663084211.6f95152c6f26.1567.0.v2\u001b[m\n",
            "\t\u001b[32mnew file:   Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663084636.6f95152c6f26.1567.1.v2\u001b[m\n",
            "\t\u001b[32mnew file:   Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663084947.6f95152c6f26.1567.2.v2\u001b[m\n",
            "\t\u001b[32mnew file:   Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663085259.6f95152c6f26.1567.3.v2\u001b[m\n",
            "\t\u001b[32mnew file:   Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663085573.6f95152c6f26.1567.4.v2\u001b[m\n",
            "\t\u001b[32mnew file:   Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663085888.6f95152c6f26.1567.5.v2\u001b[m\n",
            "\t\u001b[32mnew file:   Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663086202.6f95152c6f26.1567.6.v2\u001b[m\n",
            "\t\u001b[32mnew file:   Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663086516.6f95152c6f26.1567.7.v2\u001b[m\n",
            "\t\u001b[32mnew file:   Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663086827.6f95152c6f26.1567.8.v2\u001b[m\n",
            "\t\u001b[32mnew file:   Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663087140.6f95152c6f26.1567.9.v2\u001b[m\n",
            "\t\u001b[32mnew file:   Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663087452.6f95152c6f26.1567.10.v2\u001b[m\n",
            "\t\u001b[32mnew file:   Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/train/events.out.tfevents.1663084221.6f95152c6f26.1566.0.v2\u001b[m\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\n",
            "\t\u001b[31mTensorflow/scripts/preprocessing/__pycache__/\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/annotations/test.record\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/annotations/train.record\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/images/\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/pretrained_model/\u001b[m\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!git add {paths[\"custom_models\"]}\n",
        "!git status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfIE7gV2imR_",
        "outputId": "199c8731-a2b3-47b2-9895-355dfa734534"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SSD_MobNet_320x320_Augmenter cc69b44] model trained on colab\n",
            " 34 files changed, 16 insertions(+), 16 deletions(-)\n",
            " rewrite Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/checkpoint (93%)\n",
            " delete mode 100644 Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-10.index\n",
            " delete mode 100644 Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-11.index\n",
            " rename Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/{ckpt-9.data-00000-of-00001 => ckpt-15.data-00000-of-00001} (68%)\n",
            " create mode 100644 Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-15.index\n",
            " rename Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/{ckpt-5.data-00000-of-00001 => ckpt-16.data-00000-of-00001} (68%)\n",
            " create mode 100644 Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-16.index\n",
            " rename Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/{ckpt-10.data-00000-of-00001 => ckpt-17.data-00000-of-00001} (68%)\n",
            " create mode 100644 Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-17.index\n",
            " create mode 100644 Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-18.data-00000-of-00001\n",
            " create mode 100644 Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-18.index\n",
            " rename Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/{ckpt-7.data-00000-of-00001 => ckpt-19.data-00000-of-00001} (68%)\n",
            " create mode 100644 Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-19.index\n",
            " rename Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/{ckpt-11.data-00000-of-00001 => ckpt-20.data-00000-of-00001} (68%)\n",
            " create mode 100644 Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-20.index\n",
            " rename Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/{ckpt-8.data-00000-of-00001 => ckpt-21.data-00000-of-00001} (68%)\n",
            " create mode 100644 Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-21.index\n",
            " delete mode 100644 Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-5.index\n",
            " delete mode 100644 Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-6.index\n",
            " delete mode 100644 Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-7.index\n",
            " delete mode 100644 Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-8.index\n",
            " delete mode 100644 Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/ckpt-9.index\n",
            " rename Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/{ckpt-6.data-00000-of-00001 => eval/events.out.tfevents.1663084211.6f95152c6f26.1567.0.v2} (55%)\n",
            " create mode 100644 Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663084636.6f95152c6f26.1567.1.v2\n",
            " create mode 100644 Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663084947.6f95152c6f26.1567.2.v2\n",
            " create mode 100644 Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663085259.6f95152c6f26.1567.3.v2\n",
            " create mode 100644 Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663085573.6f95152c6f26.1567.4.v2\n",
            " create mode 100644 Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663085888.6f95152c6f26.1567.5.v2\n",
            " create mode 100644 Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663086202.6f95152c6f26.1567.6.v2\n",
            " create mode 100644 Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663086516.6f95152c6f26.1567.7.v2\n",
            " create mode 100644 Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663086827.6f95152c6f26.1567.8.v2\n",
            " create mode 100644 Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663087140.6f95152c6f26.1567.9.v2\n",
            " create mode 100644 Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/eval/events.out.tfevents.1663087452.6f95152c6f26.1567.10.v2\n",
            " create mode 100644 Tensorflow/workspace/training_SSD-MobnetV2_320x320_MoreAugments/models/HRDetection_MobNetV2/train/events.out.tfevents.1663084221.6f95152c6f26.1566.0.v2\n",
            "On branch SSD_MobNet_320x320_Augmenter\n",
            "Your branch is ahead of 'origin/SSD_MobNet_320x320_Augmenter' by 1 commit.\n",
            "  (use \"git push\" to publish your local commits)\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\n",
            "\t\u001b[31mTensorflow/scripts/preprocessing/__pycache__/\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/annotations/test.record\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/annotations/train.record\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/images/\u001b[m\n",
            "\t\u001b[31mTensorflow/workspace/pretrained_model/\u001b[m\n",
            "\n",
            "nothing added to commit but untracked files present (use \"git add\" to track)\n"
          ]
        }
      ],
      "source": [
        "!git config --global user.email \"linus.heinzelmann@uni-ulm.de\"\n",
        "!git config --global user.name \"lheinzel\"\n",
        "!git commit -m \"model trained on colab\"\n",
        "!git status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skLMvbofin-S",
        "outputId": "3e4e11df-45a8-4c7f-f2e9-660fd4c2503f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counting objects: 36, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects: 100% (35/35), done.\n",
            "Writing objects: 100% (36/36), 292.90 MiB | 7.54 MiB/s, done.\n",
            "Total 36 (delta 10), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (10/10), completed with 3 local objects.\u001b[K\n",
            "To https://github.com/lheinzel/UAVHRBuildingDetection.git\n",
            "   849462f..cc69b44  SSD_MobNet_320x320_Augmenter -> SSD_MobNet_320x320_Augmenter\n"
          ]
        }
      ],
      "source": [
        "!git push origin {GIT_BRANCH}"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "HR_BuildingDetector_Training.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.5 ('.venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "9b770e305961dc0abb9a6ba30fcb22311445fc021163a190ce871a4494dafc24"
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}