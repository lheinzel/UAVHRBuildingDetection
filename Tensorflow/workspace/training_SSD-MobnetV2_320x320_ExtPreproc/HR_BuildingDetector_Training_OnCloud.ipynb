{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lheinzel/UAVHRBuildingDetection/blob/SSD_MobNet_320x320_Augmenter/Tensorflow/workspace/training_SSD-MobnetV2_320x320_ExtPreproc/HR_BuildingDetector_Training_OnCloud.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzx9J_TlztU2"
      },
      "source": [
        "# Setup Project Parameters and Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQUQ5KGU1dxB"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsUgUFXIz23i"
      },
      "source": [
        "Project parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wQ7GzPHz5WH"
      },
      "outputs": [],
      "source": [
        "CUSTOM_MODEL_NAME = 'HRDetection_MobNetV2'\n",
        "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
        "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
        "GITHUB_REPO_URL = 'https://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@github.com/lheinzel/UAVHRBuildingDetection.git'\n",
        "GIT_BRANCH = \"SSD_MobNet_320x320_Augmenter\"\n",
        "SAVESTATE_NAME = \"HRDetection_MobNetV2_2022-10-28_19-41-54\"\n",
        "INPUT_DIMS = [320, 320]\n",
        "LABEL_MAP_NAME = 'labelmap.pbtxt'\n",
        "NOF_CLASSES = 1\n",
        "NOF_STEPS = 50000\n",
        "BATCH_SIZE = 16\n",
        "SIZE_TEST_VALID_SET = 1350\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaAB_EZw04EW"
      },
      "source": [
        "Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WQG9nQK05hv"
      },
      "outputs": [],
      "source": [
        "paths = {\"github_repo\" : os.path.join(\"//content\",\"UAVHRBuildingDetection\"),\n",
        "         \"gdrive_data\" : os.path.join(\"//content\", \"drive\", \"MyDrive\", \"UAVHRBuildingDetection\"),\n",
        "         \"workspace\" : os.path.join(\"//content\",\"UAVHRBuildingDetection\",\"Tensorflow\",\"workspace\"),\n",
        "         \"annotations\" : os.path.join(\"//content\",\"UAVHRBuildingDetection\",\"Tensorflow\",\"workspace\",\"annotations\"),\n",
        "         \"images\": os.path.join(\"//content\",\"UAVHRBuildingDetection\",\"Tensorflow\",\"workspace\",\"images\"),\n",
        "         \"scripts_pre\" : os.path.join(\"//content\",\"UAVHRBuildingDetection\",\"Tensorflow\",\"scripts\",\"preprocessing\"),\n",
        "         \"scripts_post\": os.path.join(\"//content\",\"UAVHRBuildingDetection\",\"Tensorflow\",\"scripts\",\"postprocessing\"),\n",
        "         \"pretrained_models\" : os.path.join(\"//content\",\"UAVHRBuildingDetection\",\"Tensorflow\",\"workspace\",\"pretrained_model\"),\n",
        "         \"obj_detection_api\" : os.path.join(\"//content\",\"UAVHRBuildingDetection\",\"Tensorflow\", \"models\", \"research\", \"object_detection\"),\n",
        "         \"custom_model_dir\" : os.path.join(r\"//content\", \"drive\", \"MyDrive\", \"UAVHRBuildingDetection\",\"workspace\",\"models\",CUSTOM_MODEL_NAME),\n",
        "         \"custom_model_config\" : os.path.join(\"//content\", \"drive\", \"MyDrive\", \"UAVHRBuildingDetection\",\"workspace\",\"models\",CUSTOM_MODEL_NAME, \"pipeline.config\"),\n",
        "         \"savestate_path\" : os.path.join(\"//content\", \"drive\", \"MyDrive\", \"UAVHRBuildingDetection\",\"save_state\",SAVESTATE_NAME + \".tar.gz\"),\n",
        "         \"ckpt_dir\" : os.path.join(\"//content\", \"drive\", \"MyDrive\", \"UAVHRBuildingDetection\",\"workspace\",\"models\",CUSTOM_MODEL_NAME, \"checkpoints\"),\n",
        "         }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CecPFTsQfH3"
      },
      "source": [
        "# Environment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount Google Drive"
      ],
      "metadata": {
        "id": "9RChn368YGb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M63hV2z3YJ3L",
        "outputId": "df30e2fd-a594-49da-8021-b8225e0b9a97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1ZaBbmBTJvC"
      },
      "source": [
        "Clone the project repository from github"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIN-rdTzTO6e",
        "outputId": "09df23a8-5f10-4ca4-8f6a-b6508a967af2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'UAVHRBuildingDetection'...\n",
            "remote: Enumerating objects: 6489, done.\u001b[K\n",
            "remote: Counting objects: 100% (399/399), done.\u001b[K\n",
            "remote: Compressing objects: 100% (294/294), done.\u001b[K\n",
            "remote: Total 6489 (delta 120), reused 325 (delta 89), pack-reused 6090\u001b[K\n",
            "Receiving objects: 100% (6489/6489), 4.18 GiB | 16.40 MiB/s, done.\n",
            "Resolving deltas: 100% (688/688), done.\n",
            "Checking out files: 100% (81/81), done.\n",
            "/content/UAVHRBuildingDetection\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(paths[\"github_repo\"]):\n",
        "    !git clone -b {GIT_BRANCH} --single-branch {GITHUB_REPO_URL}\n",
        "\n",
        "%cd {paths[\"github_repo\"]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YE9tdhlZTRK1"
      },
      "source": [
        "Install the object detection api and all other necessary things on the runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JD8AsOp3QoNR",
        "outputId": "928bee5f-e8a3-42db-e021-7073926103d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UAVHRBuildingDetection\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following packages will be REMOVED:\n",
            "  libcudnn8-dev\n",
            "The following held packages will be changed:\n",
            "  libcudnn8\n",
            "The following packages will be DOWNGRADED:\n",
            "  libcudnn8\n",
            "0 upgraded, 0 newly installed, 1 downgraded, 1 to remove and 3 not upgraded.\n",
            "Need to get 430 MB of archives.\n",
            "After this operation, 1,392 MB disk space will be freed.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcudnn8 8.1.0.77-1+cuda11.2 [430 MB]\n",
            "Fetched 430 MB in 10s (41.2 MB/s)\n",
            "(Reading database ... 123991 files and directories currently installed.)\n",
            "Removing libcudnn8-dev (8.1.1.33-1+cuda11.2) ...\n",
            "update-alternatives: removing manually selected alternative - switching libcudnn to auto mode\n",
            "\u001b[1mdpkg:\u001b[0m \u001b[1;33mwarning:\u001b[0m downgrading libcudnn8 from 8.1.1.33-1+cuda11.2 to 8.1.0.77-1+cuda11.2\n",
            "(Reading database ... 123968 files and directories currently installed.)\n",
            "Preparing to unpack .../libcudnn8_8.1.0.77-1+cuda11.2_amd64.deb ...\n",
            "Unpacking libcudnn8 (8.1.0.77-1+cuda11.2) over (8.1.1.33-1+cuda11.2) ...\n",
            "Setting up libcudnn8 (8.1.0.77-1+cuda11.2) ...\n",
            "2022-11-18 08:57:38.752021: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "tf.Tensor(-150.60219, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "%cd {paths[\"github_repo\"]}\n",
        "\n",
        "# install/upgrade tensorflow\n",
        "#!pip install --ignore-installed --upgrade tensorflow==2.5.0\n",
        "#!pip install tensorflow==2.8\n",
        "!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2\n",
        "\n",
        "# verify installation\n",
        "!python -c \"import tensorflow as tf; print(tf.reduce_sum(tf.random.normal([1000, 1000])))\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eUZ2lN6xJrr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85cb5252-200d-4bfa-ef6b-5c239ccbbc37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/UAVHRBuildingDetection/Tensorflow’: File exists\n",
            "/content/UAVHRBuildingDetection/Tensorflow\n",
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 78938, done.\u001b[K\n",
            "remote: Counting objects: 100% (279/279), done.\u001b[K\n",
            "remote: Compressing objects: 100% (187/187), done.\u001b[K\n",
            "remote: Total 78938 (delta 122), reused 219 (delta 91), pack-reused 78659\u001b[K\n",
            "Receiving objects: 100% (78938/78938), 593.83 MiB | 16.85 MiB/s, done.\n",
            "Resolving deltas: 100% (56089/56089), done.\n"
          ]
        }
      ],
      "source": [
        "# download model zoo if not present\n",
        "if not os.path.exists(r\"/content/UAVHRBuildingDetection/Tensorflow/models\"):\n",
        "  !mkdir /content/UAVHRBuildingDetection/Tensorflow\n",
        "  %cd /content/UAVHRBuildingDetection/Tensorflow\n",
        "  !git clone https://github.com/tensorflow/models.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BjKgzSLxMW9",
        "outputId": "3c78cf50-06eb-4c09-c7fd-7229684fd5db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UAVHRBuildingDetection/Tensorflow/models/research\n"
          ]
        }
      ],
      "source": [
        "# protobuf compilation\n",
        "%cd /content/UAVHRBuildingDetection/Tensorflow/models/research/\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiyKej9ZxQO_",
        "outputId": "bd65376a-b858-4f89-8842-8367282ef14d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UAVHRBuildingDetection\n",
            "Cloning into 'cocoapi'...\n",
            "remote: Enumerating objects: 975, done.\u001b[K\n",
            "remote: Total 975 (delta 0), reused 0 (delta 0), pack-reused 975\u001b[K\n",
            "Receiving objects: 100% (975/975), 11.72 MiB | 15.08 MiB/s, done.\n",
            "Resolving deltas: 100% (576/576), done.\n",
            "/content/UAVHRBuildingDetection/cocoapi/PythonAPI\n",
            "python setup.py build_ext --inplace\n",
            "running build_ext\n",
            "cythoning pycocotools/_mask.pyx to pycocotools/_mask.c\n",
            "/usr/local/lib/python3.7/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/UAVHRBuildingDetection/cocoapi/PythonAPI/pycocotools/_mask.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "building 'pycocotools._mask' extension\n",
            "creating build\n",
            "creating build/common\n",
            "creating build/temp.linux-x86_64-3.7\n",
            "creating build/temp.linux-x86_64-3.7/pycocotools\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c ../common/maskApi.c -o build/temp.linux-x86_64-3.7/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleDecode\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:46:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n",
            "       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:46:49:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; \u001b[01;36m\u001b[Kv\u001b[m\u001b[K=!v; }}\n",
            "                                                 \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrPoly\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:166:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n",
            "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:166:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); \u001b[01;36m\u001b[Kx\u001b[m\u001b[K[k]=x[0];\n",
            "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:167:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n",
            "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:167:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); \u001b[01;36m\u001b[Ky\u001b[m\u001b[K[k]=y[0];\n",
            "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:212:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "       \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(more) c |= 0x20; c+=48; s[p++]=c;\n",
            "       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:212:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "       if(more) c |= 0x20; \u001b[01;36m\u001b[Kc\u001b[m\u001b[K+=48; s[p++]=c;\n",
            "                           \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:220:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kwhile\u001b[m\u001b[K( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n",
            "   \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:220:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’\n",
            "   while( s[m] ) m++; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K=malloc(sizeof(uint)*m); m=0;\n",
            "                      \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:228:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "     \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n",
            "     \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:228:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "     if(m>2) x+=(long) cnts[m-2]; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K[m++]=(uint) x;\n",
            "                                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToBbox\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:141:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kxp\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
            "       if(j%2==0) xp=x; else if\u001b[01;35m\u001b[K(\u001b[m\u001b[Kxp<x) { ys=0; ye=h-1; }\n",
            "                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c pycocotools/_mask.c -o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "creating build/lib.linux-x86_64-3.7\n",
            "creating build/lib.linux-x86_64-3.7/pycocotools\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/../common/maskApi.o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -o build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so -> pycocotools\n",
            "rm -rf build\n"
          ]
        }
      ],
      "source": [
        "%cd /content/UAVHRBuildingDetection\n",
        "\n",
        "# install cocoapi\n",
        "if not os.path.exists(r\"/content/UAVHRBuildingDetection/Tensorflow/models/research/cocoapi\"):\n",
        "  !git clone https://github.com/cocodataset/cocoapi.git\n",
        "  %cd /content/UAVHRBuildingDetection/cocoapi/PythonAPI\n",
        "  !make\n",
        "  !cp -r pycocotools /content/UAVHRBuildingDetection/Tensorflow/models/research/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LTQ82a_KxUgQ",
        "outputId": "fe7094ed-1766-4567-e83f-970a4c0426a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UAVHRBuildingDetection/Tensorflow/models/research\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/UAVHRBuildingDetection/Tensorflow/models/research\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.43.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.2 MB 52.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.9.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.32)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 54.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.6)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.7.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.3.5)\n",
            "Collecting tf-models-official>=2.5.1\n",
            "  Downloading tf_models_official-2.10.1-py2.py3-none-any.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 53.7 MB/s \n",
            "\u001b[?25hCollecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.27.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (25.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.0 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.9.0)\n",
            "Collecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 6.7 MB/s \n",
            "\u001b[?25hCollecting sacrebleu<=2.2.0\n",
            "  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
            "\u001b[K     |████████████████████████████████| 116 kB 73.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (1.21.6)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.8.10)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2022.6.2)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.6.0)\n",
            "Collecting tensorflow~=2.10.0\n",
            "  Downloading tensorflow-2.10.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 578.1 MB 26 kB/s \n",
            "\u001b[?25hCollecting py-cpuinfo>=3.3.0\n",
            "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Collecting tensorflow-text~=2.10.0\n",
            "  Downloading tensorflow_text-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 58.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 61.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.11)\n",
            "Collecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.3-py2.py3-none-any.whl (238 kB)\n",
            "\u001b[K     |████████████████████████████████| 238 kB 69.8 MB/s \n",
            "\u001b[?25hCollecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.6.0.66)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.18.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 57.9 MB/s \n",
            "\u001b[?25hCollecting pyyaml<6.0,>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 71.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
            "Collecting immutabledict\n",
            "  Downloading immutabledict-2.2.3-py3-none-any.whl (4.0 kB)\n",
            "Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.14.1)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n",
            "Requirement already satisfied: protobuf<5.0.0dev,>=3.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.19.6)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.56.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2022.9.24)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->object-detection==0.1) (2022.6)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.50.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
            "Collecting keras\n",
            "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 60.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (2.1.0)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-22.10.26-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (14.0.6)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n",
            "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
            "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[K     |████████████████████████████████| 438 kB 72.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.27.0)\n",
            "Collecting tensorboard<2.11,>=2.10\n",
            "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 44.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.38.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.10.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.7)\n",
            "Collecting pymongo<4.0.0,>=3.8.0\n",
            "  Downloading pymongo-3.13.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (506 kB)\n",
            "\u001b[K     |████████████████████████████████| 506 kB 66.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Collecting orjson<4.0\n",
            "  Downloading orjson-3.8.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\n",
            "\u001b[K     |████████████████████████████████| 272 kB 71.6 MB/s \n",
            "\u001b[?25hCollecting requests<3.0.0dev,>=2.18.0\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.5 MB/s \n",
            "\u001b[?25hCollecting fastavro<2,>=0.23.6\n",
            "  Downloading fastavro-1.7.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4 MB 50.5 MB/s \n",
            "\u001b[?25hCollecting zstandard<1,>=0.18.0\n",
            "  Downloading zstandard-0.19.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 55.5 MB/s \n",
            "\u001b[?25hCollecting fasteners<1.0,>=0.3\n",
            "  Downloading fasteners-0.18-py3-none-any.whl (18 kB)\n",
            "Collecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: pyarrow<10.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (6.0.1)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Collecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 69.0 MB/s \n",
            "\u001b[?25hCollecting objsize<0.6.0,>=0.5.2\n",
            "  Downloading objsize-0.5.2-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.22.1)\n",
            "Collecting cloudpickle~=2.2.0\n",
            "  Downloading cloudpickle-2.2.0-py3-none-any.whl (25 kB)\n",
            "Collecting docopt\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.1.1)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.6.0.66)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.4.4)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.9.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.10.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.10.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n",
            "Building wheels for collected packages: object-detection, dill, avro-python3, docopt, seqeval\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1696454 sha256=31f8468266d71f589e91fb36f126e64da3854a20fd10d37c3abea545c7b9e3d7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4aqhv1gg/wheels/d1/88/4c/6e266386b82f3ada7b4a0729eeff3721d08a9ba6a71efc7a13\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78545 sha256=dbc466eb7d4d1e00804a0a0f2dd1c2a77e1318affbfb9b912279d988ff519afe\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44010 sha256=cb8b4bff37c934e12e79870c3bb58d0c75e2e2ee3f2483094131f74932774e8c\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/e5/b1/6b151d9b535ee50aaa6ab27d145a0104b6df02e5636f0376da\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=a8dc2a345258e1d4c0722c6b8028ffeef20218412f5466e98b13a07ca7eadce9\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/b0/3f/1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16182 sha256=4bfff8942a8b03b2433a7dde050bb380712c7853c3bffecdcb47e6b4b492549b\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built object-detection dill avro-python3 docopt seqeval\n",
            "Installing collected packages: requests, pyparsing, tensorflow-estimator, tensorboard, keras, flatbuffers, tensorflow, portalocker, docopt, dill, colorama, zstandard, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, pymongo, py-cpuinfo, orjson, objsize, immutabledict, hdfs, fasteners, fastavro, cloudpickle, tf-models-official, tensorflow-io, lvis, avro-python3, apache-beam, object-detection\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.6\n",
            "    Uninstalling dill-0.3.6:\n",
            "      Successfully uninstalled dill-0.3.6\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "  Attempting uninstall: pymongo\n",
            "    Found existing installation: pymongo 4.3.2\n",
            "    Uninstalling pymongo-4.3.2:\n",
            "      Successfully uninstalled pymongo-4.3.2\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.5.0\n",
            "    Uninstalling cloudpickle-1.5.0:\n",
            "      Successfully uninstalled cloudpickle-1.5.0\n",
            "Successfully installed apache-beam-2.43.0 avro-python3-1.10.2 cloudpickle-2.2.0 colorama-0.4.6 dill-0.3.1.1 docopt-0.6.2 fastavro-1.7.0 fasteners-0.18 flatbuffers-22.10.26 hdfs-2.7.0 immutabledict-2.2.3 keras-2.10.0 lvis-0.5.3 object-detection-0.1 objsize-0.5.2 orjson-3.8.1 portalocker-2.6.0 py-cpuinfo-9.0.0 pymongo-3.13.0 pyparsing-2.4.7 pyyaml-5.4.1 requests-2.28.1 sacrebleu-2.2.0 sentencepiece-0.1.97 seqeval-1.2.2 tensorboard-2.10.1 tensorflow-2.10.1 tensorflow-addons-0.18.0 tensorflow-estimator-2.10.0 tensorflow-io-0.27.0 tensorflow-model-optimization-0.7.3 tensorflow-text-2.10.0 tf-models-official-2.10.1 tf-slim-1.1.0 zstandard-0.19.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pyparsing"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# install object detection api\n",
        "%cd /content/UAVHRBuildingDetection/Tensorflow/models/research/\n",
        "!cp object_detection/packages/tf2/setup.py .\n",
        "!pip install ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVHMexLgxV_6",
        "outputId": "dafac138-061e-4f3c-d7d0-dcec97492453"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UAVHRBuildingDetection/Tensorflow/models/research\n",
            "2022-11-18 09:01:24.918009: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-11-18 09:01:25.091581: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2022-11-18 09:01:25.945406: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-11-18 09:01:25.945628: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-11-18 09:01:25.945664: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2022-11-18 09:01:29.015089: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-18 09:01:29.201208: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-18 09:01:29.201938: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "Running tests under Python 3.7.15: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2022-11-18 09:01:29.211765: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-11-18 09:01:29.212025: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-18 09:01:29.212671: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-18 09:01:29.213247: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-18 09:01:30.193438: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-18 09:01:30.194185: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-18 09:01:30.194805: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-18 09:01:30.195319: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2022-11-18 09:01:30.195372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13735 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "W1118 09:01:30.540754 139995511547776 model_builder.py:1109] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.57s\n",
            "I1118 09:01:30.779518 139995511547776 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.57s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.5s\n",
            "I1118 09:01:31.278779 139995511547776 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.5s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.25s\n",
            "I1118 09:01:31.530576 139995511547776 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.25s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.35s\n",
            "I1118 09:01:31.877971 139995511547776 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.35s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.94s\n",
            "I1118 09:01:33.815225 139995511547776 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.94s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I1118 09:01:33.821006 139995511547776 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "I1118 09:01:33.847101 139995511547776 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
            "I1118 09:01:33.862356 139995511547776 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "I1118 09:01:33.877912 139995511547776 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.09s\n",
            "I1118 09:01:33.969171 139995511547776 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.09s\n",
            "I1118 09:01:34.058975 139995511547776 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n",
            "I1118 09:01:34.150992 139995511547776 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.09s\n",
            "I1118 09:01:34.243045 139995511547776 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.09s\n",
            "I1118 09:01:34.333445 139995511547776 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "I1118 09:01:34.361199 139995511547776 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I1118 09:01:34.535580 139995511547776 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I1118 09:01:34.535743 139995511547776 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 64\n",
            "I1118 09:01:34.535813 139995511547776 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 3\n",
            "I1118 09:01:34.537989 139995511547776 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1118 09:01:34.565287 139995511547776 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1118 09:01:34.565416 139995511547776 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1118 09:01:34.646455 139995511547776 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1118 09:01:34.646629 139995511547776 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1118 09:01:34.836172 139995511547776 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1118 09:01:34.836377 139995511547776 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1118 09:01:35.028023 139995511547776 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1118 09:01:35.028199 139995511547776 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1118 09:01:35.307008 139995511547776 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1118 09:01:35.307189 139995511547776 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1118 09:01:35.755514 139995511547776 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1118 09:01:35.755729 139995511547776 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1118 09:01:36.118124 139995511547776 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1118 09:01:36.118291 139995511547776 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I1118 09:01:36.201367 139995511547776 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I1118 09:01:36.243764 139995511547776 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1118 09:01:36.291243 139995511547776 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I1118 09:01:36.291370 139995511547776 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 88\n",
            "I1118 09:01:36.291472 139995511547776 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 4\n",
            "I1118 09:01:36.293107 139995511547776 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1118 09:01:36.309915 139995511547776 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1118 09:01:36.310025 139995511547776 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1118 09:01:36.452433 139995511547776 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1118 09:01:36.452613 139995511547776 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1118 09:01:36.716035 139995511547776 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1118 09:01:36.716206 139995511547776 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1118 09:01:36.981909 139995511547776 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1118 09:01:36.982073 139995511547776 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1118 09:01:37.316394 139995511547776 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1118 09:01:37.316578 139995511547776 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1118 09:01:37.661271 139995511547776 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1118 09:01:37.661451 139995511547776 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1118 09:01:38.103374 139995511547776 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1118 09:01:38.103579 139995511547776 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I1118 09:01:38.278707 139995511547776 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I1118 09:01:38.310988 139995511547776 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1118 09:01:38.372479 139995511547776 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I1118 09:01:38.372658 139995511547776 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 112\n",
            "I1118 09:01:38.372746 139995511547776 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 5\n",
            "I1118 09:01:38.374201 139995511547776 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1118 09:01:38.391556 139995511547776 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1118 09:01:38.391685 139995511547776 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1118 09:01:38.524443 139995511547776 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1118 09:01:38.524610 139995511547776 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1118 09:01:38.789635 139995511547776 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1118 09:01:38.789802 139995511547776 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I1118 09:01:39.060425 139995511547776 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I1118 09:01:39.060606 139995511547776 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I1118 09:01:39.419384 139995511547776 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I1118 09:01:39.419570 139995511547776 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I1118 09:01:39.786807 139995511547776 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I1118 09:01:39.786996 139995511547776 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I1118 09:01:40.235267 139995511547776 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I1118 09:01:40.235440 139995511547776 efficientnet_model.py:143] round_filter input=320 output=352\n",
            "I1118 09:01:40.419614 139995511547776 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
            "I1118 09:01:40.456293 139995511547776 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1118 09:01:40.515163 139995511547776 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I1118 09:01:40.515331 139995511547776 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 160\n",
            "I1118 09:01:40.515414 139995511547776 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 6\n",
            "I1118 09:01:40.516938 139995511547776 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I1118 09:01:40.536467 139995511547776 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I1118 09:01:40.536601 139995511547776 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1118 09:01:40.691483 139995511547776 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1118 09:01:40.691694 139995511547776 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I1118 09:01:40.960175 139995511547776 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I1118 09:01:40.960347 139995511547776 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I1118 09:01:41.401903 139995511547776 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I1118 09:01:41.402085 139995511547776 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I1118 09:01:41.850451 139995511547776 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I1118 09:01:41.850633 139995511547776 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I1118 09:01:42.300544 139995511547776 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I1118 09:01:42.300710 139995511547776 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I1118 09:01:42.839657 139995511547776 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I1118 09:01:42.839827 139995511547776 efficientnet_model.py:143] round_filter input=320 output=384\n",
            "I1118 09:01:43.023045 139995511547776 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
            "I1118 09:01:43.059546 139995511547776 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1118 09:01:43.125627 139995511547776 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I1118 09:01:43.125782 139995511547776 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 224\n",
            "I1118 09:01:43.125852 139995511547776 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 7\n",
            "I1118 09:01:43.127313 139995511547776 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I1118 09:01:43.146425 139995511547776 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I1118 09:01:43.146548 139995511547776 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1118 09:01:43.284240 139995511547776 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1118 09:01:43.284388 139995511547776 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I1118 09:01:43.618254 139995511547776 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I1118 09:01:43.618419 139995511547776 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I1118 09:01:43.985877 139995511547776 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I1118 09:01:43.986065 139995511547776 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I1118 09:01:44.505145 139995511547776 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I1118 09:01:44.505325 139995511547776 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I1118 09:01:45.057737 139995511547776 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I1118 09:01:45.057908 139995511547776 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I1118 09:01:45.777037 139995511547776 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I1118 09:01:45.777235 139995511547776 efficientnet_model.py:143] round_filter input=320 output=448\n",
            "I1118 09:01:45.967342 139995511547776 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
            "I1118 09:01:46.007898 139995511547776 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1118 09:01:46.079783 139995511547776 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I1118 09:01:46.079982 139995511547776 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 288\n",
            "I1118 09:01:46.080064 139995511547776 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 7\n",
            "I1118 09:01:46.081573 139995511547776 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I1118 09:01:46.099237 139995511547776 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I1118 09:01:46.099362 139995511547776 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1118 09:01:46.304476 139995511547776 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1118 09:01:46.304645 139995511547776 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I1118 09:01:46.729326 139995511547776 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I1118 09:01:46.729503 139995511547776 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I1118 09:01:47.166750 139995511547776 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I1118 09:01:47.166915 139995511547776 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I1118 09:01:47.992452 139995511547776 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I1118 09:01:47.992636 139995511547776 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I1118 09:01:48.615883 139995511547776 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I1118 09:01:48.616054 139995511547776 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I1118 09:01:49.399673 139995511547776 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I1118 09:01:49.399838 139995511547776 efficientnet_model.py:143] round_filter input=320 output=512\n",
            "I1118 09:01:49.670090 139995511547776 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
            "I1118 09:01:49.709359 139995511547776 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1118 09:01:49.790253 139995511547776 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I1118 09:01:49.790419 139995511547776 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 384\n",
            "I1118 09:01:49.790498 139995511547776 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 8\n",
            "I1118 09:01:49.792025 139995511547776 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I1118 09:01:49.813017 139995511547776 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I1118 09:01:49.813161 139995511547776 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I1118 09:01:50.034842 139995511547776 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I1118 09:01:50.035010 139995511547776 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I1118 09:01:50.549985 139995511547776 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I1118 09:01:50.550154 139995511547776 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I1118 09:01:51.086500 139995511547776 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I1118 09:01:51.086710 139995511547776 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I1118 09:01:51.781816 139995511547776 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I1118 09:01:51.781982 139995511547776 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I1118 09:01:52.493383 139995511547776 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I1118 09:01:52.493572 139995511547776 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I1118 09:01:53.493425 139995511547776 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I1118 09:01:53.493622 139995511547776 efficientnet_model.py:143] round_filter input=320 output=576\n",
            "I1118 09:01:53.786779 139995511547776 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
            "I1118 09:01:53.824161 139995511547776 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1118 09:01:53.934338 139995511547776 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I1118 09:01:53.934510 139995511547776 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 384\n",
            "I1118 09:01:53.934601 139995511547776 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 8\n",
            "I1118 09:01:53.936195 139995511547776 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I1118 09:01:53.956319 139995511547776 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I1118 09:01:53.956439 139995511547776 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I1118 09:01:54.243345 139995511547776 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I1118 09:01:54.243538 139995511547776 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I1118 09:01:55.111340 139995511547776 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I1118 09:01:55.111552 139995511547776 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I1118 09:01:55.706159 139995511547776 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I1118 09:01:55.706334 139995511547776 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I1118 09:01:56.605462 139995511547776 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I1118 09:01:56.605639 139995511547776 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I1118 09:01:57.487547 139995511547776 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I1118 09:01:57.487721 139995511547776 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I1118 09:01:58.612628 139995511547776 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I1118 09:01:58.612799 139995511547776 efficientnet_model.py:143] round_filter input=320 output=640\n",
            "I1118 09:01:58.967612 139995511547776 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
            "I1118 09:01:59.020328 139995511547776 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 24.77s\n",
            "I1118 09:01:59.128752 139995511547776 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 24.77s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I1118 09:01:59.154383 139995511547776 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I1118 09:01:59.156070 139995511547776 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I1118 09:01:59.156586 139995511547776 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I1118 09:01:59.157971 139995511547776 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I1118 09:01:59.159276 139995511547776 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I1118 09:01:59.159770 139995511547776 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I1118 09:01:59.160766 139995511547776 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 29.956s\n",
            "\n",
            "OK (skipped=1)\n",
            "/content/UAVHRBuildingDetection\n"
          ]
        }
      ],
      "source": [
        "# Verify installation\n",
        "%cd /content/UAVHRBuildingDetection/Tensorflow/models/research/\n",
        "!python object_detection/builders/model_builder_tf2_test.py\n",
        "\n",
        "# return to content directory\n",
        "%cd /content/UAVHRBuildingDetection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDNCmFR1CnSt"
      },
      "source": [
        "Create local directorie for pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMLy0Wx3Csxj"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(paths[\"pretrained_models\"]):\n",
        "  os.makedirs(paths[\"pretrained_models\"])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P267uD75lE2_"
      },
      "source": [
        "Install other python packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvHMyrW6lI4r",
        "outputId": "f4548fac-f32a-4e81-cdec-8ea953f901c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9657 sha256=00dbe0871fe67bb73d0e0cec44bf19238b10b6d8d21746e79e5e106954611787\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting opencv-python==4.5.2.52\n",
            "  Downloading opencv_python-4.5.2.52-cp37-cp37m-manylinux2014_x86_64.whl (51.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 51.0 MB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python==4.5.2.52) (1.21.6)\n",
            "Installing collected packages: opencv-python\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.6.0.66\n",
            "    Uninstalling opencv-python-4.6.0.66:\n",
            "      Successfully uninstalled opencv-python-4.6.0.66\n",
            "Successfully installed opencv-python-4.6.0.66\n"
          ]
        }
      ],
      "source": [
        "!pip install wget\n",
        "!pip install opencv-python==4.5.2.52\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIUttk2BkFi-"
      },
      "source": [
        "# Download pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sLzYy5BkLg_",
        "outputId": "3cbffb7b-e660-45a2-b1d6-6dcd0fd9c3b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UAVHRBuildingDetection/Tensorflow/workspace/pretrained_model\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n",
            "/content/UAVHRBuildingDetection\n"
          ]
        }
      ],
      "source": [
        "import wget\n",
        "# download pretrained model\n",
        "%cd {paths[\"pretrained_models\"]}\n",
        "preModZipName = PRETRAINED_MODEL_NAME + \".tar.gz\"\n",
        "\n",
        "if not os.path.exists(preModZipName):\n",
        "  wget.download(PRETRAINED_MODEL_URL)\n",
        "\n",
        "if not os.path.exists(PRETRAINED_MODEL_NAME):\n",
        "  !tar -zxvf {PRETRAINED_MODEL_NAME + \".tar.gz\"}\n",
        "\n",
        "%cd {paths[\"github_repo\"]}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAlZZ0yXyoQ6"
      },
      "source": [
        "# Setup Training Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract Dataset locally"
      ],
      "metadata": {
        "id": "EnW1Gz4vXgM2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tHwGkWc66aC"
      },
      "outputs": [],
      "source": [
        "from shutil import copyfile\n",
        "from shutil import rmtree\n",
        "\n",
        "%cd {paths[\"github_repo\"]}\n",
        "\n",
        "# Copy compressed data\n",
        "if os.path.exists(paths[\"annotations\"]):\n",
        "  rmtree(paths[\"annotations\"])\n",
        "\n",
        "copyfile(os.path.join(paths[\"gdrive_data\"],\"dataset\", \"annotations.tar.gz\"), os.path.join(paths[\"workspace\"],\"annotations.tar.gz\"))\n",
        "\n",
        "# Decompress Data\n",
        "%cd {paths[\"workspace\"]}\n",
        "!tar -zxvf {\"annotations.tar.gz\"}\n",
        "\n",
        "# Return to project repo directory\n",
        "%cd {paths[\"github_repo\"]}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEWJr8-M9qBB"
      },
      "source": [
        "copy and adapt pipline config if necessary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMHo2Mfp9umt"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from google.protobuf import text_format\n",
        "from shutil import rmtree\n",
        "\n",
        "if not os.path.exists(paths[\"custom_model_dir\"] ):\n",
        "  os.makedirs(paths[\"custom_model_dir\"])\n",
        "\n",
        "if not os.path.exists(paths[\"custom_model_config\"]):\n",
        "  # Copy Config if necessary\n",
        "  if os.name == \"posix\":\n",
        "    !cp {os.path.join(paths[\"pretrained_models\"], PRETRAINED_MODEL_NAME,\"pipeline.config\")} {paths[\"custom_model_config\"]}\n",
        "  elif os.name == \"nt\":\n",
        "    !copy {os.path.join(paths[\"pretrained_models\"], PRETRAINED_MODEL_NAME,\"pipeline.config\")} {paths[\"custom_model_config\"]}\n",
        "  \n",
        "\n",
        "  # adapt config\n",
        "  config = config_util.get_configs_from_pipeline_file(paths[\"custom_model_config\"])\n",
        "\n",
        "  pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "  with tf.io.gfile.GFile(paths['custom_model_config'], \"r\") as f:                                                                                                                                                                                                                     \n",
        "      proto_str = f.read()                                                                                                                                                                                                                                          \n",
        "      text_format.Merge(proto_str, pipeline_config)  \n",
        "\n",
        "  pipeline_config.model.ssd.image_resizer.fixed_shape_resizer.height = INPUT_DIMS[0]\n",
        "  pipeline_config.model.ssd.image_resizer.fixed_shape_resizer.width = INPUT_DIMS[1]\n",
        "  pipeline_config.model.ssd.num_classes = NOF_CLASSES\n",
        "  pipeline_config.train_config.batch_size = BATCH_SIZE\n",
        "  pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths[\"pretrained_models\"], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
        "  pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
        "  pipeline_config.train_input_reader.label_map_path= os.path.join(paths[\"annotations\"],LABEL_MAP_NAME)\n",
        "  pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths[\"annotations\"], 'train.record')]\n",
        "  pipeline_config.eval_input_reader[0].label_map_path = os.path.join(paths[\"annotations\"],LABEL_MAP_NAME)\n",
        "  pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths[\"annotations\"], 'eval.record')]\n",
        "\n",
        "  pipeline_config.eval_config.num_visualizations=100\n",
        "  pipeline_config.eval_config.max_num_boxes_to_visualize = 100\n",
        "  pipeline_config.eval_config.num_examples = SIZE_TEST_VALID_SET\n",
        "  pipeline_config.eval_config.eval_interval_secs = 10\n",
        "  pipeline_config.eval_config.batch_size = BATCH_SIZE\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
        "  with tf.io.gfile.GFile(paths[\"custom_model_config\"], \"wb\") as f:                                                                                                                                                                                                                     \n",
        "      f.write(config_text)   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpTdLaJ5O59u"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model for the number of steps specified in the project parameters. Since the training function of the Object Detection API would only keep the latest 7 model checkpoints during the traiing process, a custom function has to run in parallel, that extracts the previously created checkpoint file in each training step and stores it in a separate directory. Thus, the evaluation for all checkpoints can be performed after the training has completed."
      ],
      "metadata": {
        "id": "DWJkGNi7Oi-G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCP97JHVO-56"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "from math import ceil\n",
        "\n",
        "# Build the command line call for the script that extracts the checkpoint files and run it in a subprocess\n",
        "scriptPathCkpt = os.path.join(paths[\"scripts_post\"],\"doGreedyCheckpointExtraction.py\")\n",
        "cmdArgsCkpt = \"{} --modelDir={} --destDir={} --lastCkpt={} --maxRunTime={}\".format(scriptPathCkpt, paths[\"custom_model_dir\"],\n",
        "                                                                                   paths[\"ckpt_dir\"], ceil(NOF_STEPS/1000), 300)\n",
        "cmdCkpt = [\"python\"] + cmdArgsCkpt.split(\" \")\n",
        "\n",
        "# Create file for checkpoint extraction log\n",
        "ckptExtractionLogPath = os.path.join(paths[\"custom_model_dir\"],\"ckptExtraction.log\")\n",
        "ckptExtractionLogFile = open(ckptExtractionLogPath, \"w\")\n",
        "\n",
        "# Start extraction script in subprocess\n",
        "pCheckpointHandling = subprocess.Popen(cmdCkpt, stdout=ckptExtractionLogFile, stderr=subprocess.STDOUT)\n",
        "\n",
        "\n",
        "# Build the command line call for the training function and run it in a subprocess\n",
        "TRAINING_SCRIPT = os.path.join(paths[\"obj_detection_api\"],\"model_main_tf2.py\")\n",
        "cmdArgsTraining = \"{} --model_dir={} --pipeline_config_path={} --num_train_steps={}\".format(TRAINING_SCRIPT, paths[\"custom_model_dir\"], paths[\"custom_model_config\"],NOF_STEPS)\n",
        "cmdTraining = [\"python\"] + cmdArgsTraining.split(\" \")\n",
        "\n",
        "# Create file for training log\n",
        "trainingLogPath = os.path.join(paths[\"custom_model_dir\"],\"training.log\")\n",
        "trainingLogFile = open(trainingLogPath, \"w\")\n",
        "pTraining = subprocess.Popen(cmdTraining, stdout=trainingLogFile, stderr=subprocess.STDOUT)\n",
        "\n",
        "# Get outputs of processes\n",
        "outCkpt, errCkpt = pCheckpointHandling.communicate()\n",
        "outTraining, errTraining = pTraining.communicate()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48UbAlBYABdm"
      },
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The evaluation is performed for each checkpoint of the model from the previous training process. Therfore, the evaluation function from the Object Detection API has to run in parallel with a custom function, that sets the flag in the file \"checkpoint\" to the next checkpoint file respectively."
      ],
      "metadata": {
        "id": "v-FGG2RZN21y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVU-sCcKAEsl"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "# remove checkpoint pointer file if exists\n",
        "if os.path.exists(os.path.join(paths[\"custom_model_dir\"],\"checkpoint\")):\n",
        "  os.remove(os.path.join(paths[\"custom_model_dir\"],\"checkpoint\"))\n",
        "\n",
        "# create eval folder\n",
        "evalPath = os.path.join(paths[\"custom_model_dir\"],\"eval\")\n",
        "if not os.path.exists(evalPath):\n",
        "  os.mkdir(evalPath)\n",
        "\n",
        "# Build the command line call for the evaluation function\n",
        "TRAINING_SCRIPT = os.path.join(paths[\"obj_detection_api\"],\"model_main_tf2.py\")\n",
        "cmdArgsEval = \"{} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths[\"custom_model_dir\"], paths[\"custom_model_config\"],\n",
        "                                                                                       paths[\"ckpt_dir\"])\n",
        "cmdEval = [\"python\"] + cmdArgsEval.split(\" \")\n",
        "\n",
        "# File for evaluation log\n",
        "evalLogPath = os.path.join(paths[\"custom_model_dir\"],\"eval.log\")\n",
        "evalLogFile = open(evalLogPath, \"w\")\n",
        "\n",
        "# Run the evaluation script in subprocess\n",
        "pEval = subprocess.Popen(cmdEval, stdout=evalLogFile, stderr=subprocess.STDOUT)\n",
        "\n",
        "\n",
        "\n",
        "# Build the command line call for the checkpoint delivery script and run it in a subprocess\n",
        "scriptPathCkpt = os.path.join(paths[\"scripts_post\"],\"doCheckpointPointerSetting.py\")\n",
        "\n",
        "cmdArgsCkpt = \"{} --ckptPath={} --evalPath={} --maxRuntime={}\".format(scriptPathCkpt, paths[\"ckpt_dir\"], evalPath, 240)\n",
        "cmdCkpt = [\"python\"] + cmdArgsCkpt.split(\" \")\n",
        "\n",
        "# File for checkpoint pointer setting log\n",
        "ckptPtrSettingLogPath = os.path.join(paths[\"custom_model_dir\"], \"ckptPtrSetting.log\")\n",
        "ckptPtrSettingLogFile = open(ckptPtrSettingLogPath, \"w\")\n",
        "\n",
        "# Run checkpoint pointer setting script in subprocess\n",
        "pCheckpointDelivery = subprocess.Popen(cmdCkpt, stdout=ckptPtrSettingLogFile, stderr=subprocess.STDOUT)\n",
        "\n",
        "# get outputs of processes\n",
        "outCkpt, errCkpt = pCheckpointDelivery.communicate()\n",
        "outEval, errEval = pEval.communicate()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-7T7lCXFDkB"
      },
      "source": [
        "load tensorboard extension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtrLXvLkFGDa"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_C4MS6sJFI8L"
      },
      "source": [
        "Inspect evaluation results using tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Q9fomE9FmSk"
      },
      "outputs": [],
      "source": [
        "evalLogDir = paths[\"custom_model_dir\"]\n",
        "%tensorboard --logdir {evalLogDir} --samples_per_plugin=images=100"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "HR_BuildingDetector_Training.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.5 ('.venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "9b770e305961dc0abb9a6ba30fcb22311445fc021163a190ce871a4494dafc24"
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}