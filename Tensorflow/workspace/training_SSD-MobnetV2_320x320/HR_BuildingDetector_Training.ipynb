{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HR_BuildingDetector_Training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNRP8G7BHm2GHj3E/0v5NIP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lheinzel/UAVHRBuildingDetection/blob/SSD_MobNet_320x320/Tensorflow/workspace/training_SSD-MobnetV2_320x320/HR_BuildingDetector_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Project Parameters and Paths"
      ],
      "metadata": {
        "id": "pzx9J_TlztU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "iQUQ5KGU1dxB"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Project parameters"
      ],
      "metadata": {
        "id": "LsUgUFXIz23i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CUSTOM_MODEL_NAME = 'HRDetection_MobNetV2'\n",
        "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_320x320_coco17_tpu-8'\n",
        "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz'\n",
        "GITHUB_REPO_URL = 'https://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@github.com/lheinzel/UAVHRBuildingDetection.git'\n",
        "DATASET_REPO_URL = 'https://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@github.com/lheinzel/UAVHighRiseBuildingsKorea.git'\n",
        "DATASET_REPO_NAME = 'UAVHighRiseBuildingsKorea'\n",
        "DATASET_BRANCH_NAME = 'CroppingRework_320x320'\n",
        "DATA_PACKAGE_NAME = 'DataCropped_320x320'\n",
        "INPUT_DIMS = [320, 320]\n",
        "LABEL_MAP_NAME = 'labelmap.pbtxt'\n",
        "NOF_CLASSES = 1\n",
        "GIT_BRANCH = \"SSD_MobNet_320x320\"\n",
        "NOF_STEPS = 10000"
      ],
      "metadata": {
        "id": "7wQ7GzPHz5WH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paths"
      ],
      "metadata": {
        "id": "GaAB_EZw04EW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paths = {\"github_repo\" : os.path.join(\"//content\",\"UAVHRBuildingDetection\"),\n",
        "         \"workspace\" : os.path.join(\"//content\",\"UAVHRBuildingDetection\",\"Tensorflow\",\"workspace\"),\n",
        "         \"annotations\" : os.path.join(\"//content\",\"UAVHRBuildingDetection\",\"Tensorflow\",\"workspace\",\"annotations\"),\n",
        "         \"images\": os.path.join(\"//content\",\"UAVHRBuildingDetection\",\"Tensorflow\",\"workspace\",\"images\"),\n",
        "         \"training\" : os.path.join(\"//content\",\"UAVHRBuildingDetection\",\"Tensorflow\",\"workspace\",\"training_SSD-MobnetV2_320x320\"),\n",
        "         \"scripts_pre\" : os.path.join(\"//content\",\"UAVHRBuildingDetection\",\"Tensorflow\",\"scripts\",\"preprocessing\"),\n",
        "         \"pretrained_models\" : os.path.join(\"//content\",\"UAVHRBuildingDetection\",\"Tensorflow\",\"workspace\",\"pretrained_model\"),\n",
        "         \"custom_models\" : os.path.join(\"//content\",\"UAVHRBuildingDetection\",\"Tensorflow\",\"workspace\",\"training_SSD-MobnetV2_320x320\", \"models\"),\n",
        "         \"obj_detection_api\" : os.path.join(\"//content\",\"UAVHRBuildingDetection\",\"Tensorflow\", \"models\", \"research\", \"object_detection\"),\n",
        "         \"custom_model_dir\" : os.path.join(\"//content\",\"UAVHRBuildingDetection\",\"Tensorflow\",\"workspace\",\"training_SSD-MobnetV2_320x320\", \"models\",CUSTOM_MODEL_NAME),\n",
        "         \"custom_model_config\" : os.path.join(\"//content\",\"UAVHRBuildingDetection\",\"Tensorflow\",\"workspace\",\"training_SSD-MobnetV2_320x320\", \"models\",CUSTOM_MODEL_NAME, \"pipeline.config\"),\n",
        "         \"model_export_dir\" : os.path.join(\"//content\",\"UAVHRBuildingDetection\",\"Tensorflow\",\"workspace\",\"training_SSD-MobnetV2_320x320\",\"exported_models\"),\n",
        "         \"dataset_images\" : os.path.join(\"//content\", \"UAVHRBuildingDetection\", \"Datasets\", DATASET_REPO_NAME, DATA_PACKAGE_NAME, \"Images\"),\n",
        "         \"dataset_labels\" : os.path.join(\"//content\", \"UAVHRBuildingDetection\",\"Datasets\", DATASET_REPO_NAME, DATA_PACKAGE_NAME, \"Labels\")\n",
        "         }"
      ],
      "metadata": {
        "id": "6WQG9nQK05hv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment Setup"
      ],
      "metadata": {
        "id": "7CecPFTsQfH3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone the project repository from github"
      ],
      "metadata": {
        "id": "j1ZaBbmBTJvC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(paths[\"github_repo\"]):\n",
        "    !git clone -b {GIT_BRANCH} --single-branch {GITHUB_REPO_URL}\n",
        "\n",
        "%cd paths[\"github_repo\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "QIN-rdTzTO6e",
        "outputId": "43eef123-f12e-4cc6-9d5b-8137a588bb90"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'UAVHRBuildingDetection'...\n",
            "remote: Enumerating objects: 5921, done.\u001b[K\n",
            "remote: Counting objects: 100% (1609/1609), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1582/1582), done.\u001b[K\n",
            "remote: Total 5921 (delta 40), reused 1545 (delta 23), pack-reused 4312\u001b[K\n",
            "Receiving objects: 100% (5921/5921), 2.22 GiB | 41.90 MiB/s, done.\n",
            "Resolving deltas: 100% (367/367), done.\n",
            "/content/UAVHRBuildingDetection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull origin {GIT_BRANCH}"
      ],
      "metadata": {
        "id": "dIkeq6uxW1Qb",
        "outputId": "382078b0-1b3a-47ce-9347-eaca0ec1bc42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects:   9% (1/11)\u001b[K\rremote: Counting objects:  18% (2/11)\u001b[K\rremote: Counting objects:  27% (3/11)\u001b[K\rremote: Counting objects:  36% (4/11)\u001b[K\rremote: Counting objects:  45% (5/11)\u001b[K\rremote: Counting objects:  54% (6/11)\u001b[K\rremote: Counting objects:  63% (7/11)\u001b[K\rremote: Counting objects:  72% (8/11)\u001b[K\rremote: Counting objects:  81% (9/11)\u001b[K\rremote: Counting objects:  90% (10/11)\u001b[K\rremote: Counting objects: 100% (11/11)\u001b[K\rremote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects:  33% (1/3)\u001b[K\rremote: Compressing objects:  66% (2/3)\u001b[K\rremote: Compressing objects: 100% (3/3)\u001b[K\rremote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 6 (delta 2), reused 6 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects:  16% (1/6)   \rUnpacking objects:  33% (2/6)   \rUnpacking objects:  50% (3/6)   \rUnpacking objects:  66% (4/6)   \rUnpacking objects:  83% (5/6)   \rUnpacking objects: 100% (6/6)   \rUnpacking objects: 100% (6/6), done.\n",
            "From https://github.com/lheinzel/UAVHRBuildingDetection\n",
            " * branch            SSD_MobNet_320x320 -> FETCH_HEAD\n",
            "   04e0edc..2fd4c5b  SSD_MobNet_320x320 -> origin/SSD_MobNet_320x320\n",
            "Updating 04e0edc..2fd4c5b\n",
            "Fast-forward\n",
            " Tensorflow/scripts/preprocessing/dataAugmentation.py | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UfoOOLN9Wvc5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone the dataset repository from github"
      ],
      "metadata": {
        "id": "D_IWOJwP803d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datasetPath = os.path.join(paths[\"github_repo\"], \"Datasets\")\n",
        "\n",
        "if not os.path.exists(datasetPath):\n",
        "  os.makedirs(datasetPath)\n",
        "\n",
        "%cd {datasetPath}\n",
        "\n",
        "if not os.path.exists(os.path.join(datasetPath, DATASET_REPO_NAME)):\n",
        "  !git clone -b {DATASET_BRANCH_NAME} --single-branch {DATASET_REPO_URL}\n",
        "\n",
        "%cd {paths[\"github_repo\"]}"
      ],
      "metadata": {
        "id": "spMz-XGW83yX",
        "outputId": "31cd2cf7-b2a9-4ca5-ddbd-46eb73ec17eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UAVHRBuildingDetection/Datasets\n",
            "Cloning into 'UAVHighRiseBuildingsKorea'...\n",
            "remote: Enumerating objects: 14294, done.\u001b[K\n",
            "remote: Total 14294 (delta 0), reused 0 (delta 0), pack-reused 14294\u001b[K\n",
            "Receiving objects: 100% (14294/14294), 2.42 GiB | 46.10 MiB/s, done.\n",
            "Resolving deltas: 100% (7582/7582), done.\n",
            "/content/UAVHRBuildingDetection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {os.path.join(paths[\"github_repo\"], \"Datasets\",DATASET_REPO_NAME)}\n",
        "!git status\n",
        "!git pull origin {DATASET_BRANCH_NAME}\n",
        "%cd {paths[\"github_repo\"]}"
      ],
      "metadata": {
        "id": "GeARLJTzV4pn",
        "outputId": "68c09d68-1f41-4c14-856a-f120293b18bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UAVHRBuildingDetection/Datasets/UAVHighRiseBuildingsKorea\n",
            "On branch CroppingRework_320x320\n",
            "Your branch is up to date with 'origin/CroppingRework_320x320'.\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "From https://github.com/lheinzel/UAVHighRiseBuildingsKorea\n",
            " * branch            CroppingRework_320x320 -> FETCH_HEAD\n",
            "Already up to date.\n",
            "/content/UAVHRBuildingDetection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the object detection api and all other necessary things on the runtime"
      ],
      "metadata": {
        "id": "YE9tdhlZTRK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install/upgrade tensorflow\n",
        "#!pip install --ignore-installed --upgrade tensorflow==2.5.0\n",
        "!pip install tensorflow==2.8\n",
        "!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2\n",
        "\n",
        "# verify installation\n",
        "!python -c \"import tensorflow as tf; print(tf.reduce_sum(tf.random.normal([1000, 1000])))\"\n"
      ],
      "metadata": {
        "id": "JD8AsOp3QoNR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "f49650e9-325f-471d-ce7c-9e0e0829f1b5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.8\n",
            "  Downloading https://us-python.pkg.dev/colab-wheels/public/tensorflow/tensorflow-2.8.0%2Bzzzcolab20220506162203-cp37-cp37m-linux_x86_64.whl (668.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 668.3 MB 18 kB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (4.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (57.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.14.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.1.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (3.1.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (3.17.3)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.21.6)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (0.2.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (0.5.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (0.26.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (2.0)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (2.8.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.47.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (14.0.6)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (2.8.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow==2.8) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow==2.8) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (1.8.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly, tensorflow\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220719082949\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220719082949:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220719082949\n",
            "Successfully installed tensorflow-2.8.0+zzzcolab20220506162203 tf-estimator-nightly-2.8.0.dev2021122109\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following packages will be REMOVED:\n",
            "  libcudnn8-dev\n",
            "The following held packages will be changed:\n",
            "  libcudnn8\n",
            "The following packages will be upgraded:\n",
            "  libcudnn8\n",
            "1 upgraded, 0 newly installed, 1 to remove and 18 not upgraded.\n",
            "Need to get 430 MB of archives.\n",
            "After this operation, 3,139 MB disk space will be freed.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcudnn8 8.1.0.77-1+cuda11.2 [430 MB]\n",
            "Fetched 430 MB in 7s (61.9 MB/s)\n",
            "(Reading database ... 155676 files and directories currently installed.)\n",
            "Removing libcudnn8-dev (8.0.5.39-1+cuda11.1) ...\n",
            "(Reading database ... 155654 files and directories currently installed.)\n",
            "Preparing to unpack .../libcudnn8_8.1.0.77-1+cuda11.2_amd64.deb ...\n",
            "Unpacking libcudnn8 (8.1.0.77-1+cuda11.2) over (8.0.5.39-1+cuda11.1) ...\n",
            "Setting up libcudnn8 (8.1.0.77-1+cuda11.2) ...\n",
            "2022-08-29 10:07:10.439723: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "tf.Tensor(2692.048, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download model zoo if not present\n",
        "if not os.path.exists(r\"/content/UAVHRBuildingDetection/Tensorflow/models\"):\n",
        "  !mkdir /content/UAVHRBuildingDetection/Tensorflow\n",
        "  %cd /content/UAVHRBuildingDetection/Tensorflow\n",
        "  !git clone https://github.com/tensorflow/models.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3eUZ2lN6xJrr",
        "outputId": "529e2b79-b51e-422d-855f-83d23cf53d8d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/UAVHRBuildingDetection/Tensorflow’: File exists\n",
            "/content/UAVHRBuildingDetection/Tensorflow\n",
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 76561, done.\u001b[K\n",
            "remote: Counting objects: 100% (382/382), done.\u001b[K\n",
            "remote: Compressing objects: 100% (239/239), done.\u001b[K\n",
            "remote: Total 76561 (delta 178), reused 325 (delta 141), pack-reused 76179\u001b[K\n",
            "Receiving objects: 100% (76561/76561), 596.77 MiB | 34.76 MiB/s, done.\n",
            "Resolving deltas: 100% (54289/54289), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# protobuf compilation\n",
        "%cd /content/UAVHRBuildingDetection/Tensorflow/models/research/\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4BjKgzSLxMW9",
        "outputId": "945d25d3-ec7c-4012-8a21-bf489b145d20"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UAVHRBuildingDetection/Tensorflow/models/research\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/UAVHRBuildingDetection\n",
        "\n",
        "# install cocoapi\n",
        "if not os.path.exists(r\"/content/UAVHRBuildingDetection/Tensorflow/models/research/cocoapi\"):\n",
        "  !git clone https://github.com/cocodataset/cocoapi.git\n",
        "  %cd /content/UAVHRBuildingDetection/cocoapi/PythonAPI\n",
        "  !make\n",
        "  !cp -r pycocotools /content/UAVHRBuildingDetection/Tensorflow/models/research/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "HiyKej9ZxQO_",
        "outputId": "d68681d4-9382-45d3-b97e-589cac9cb3a2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UAVHRBuildingDetection\n",
            "Cloning into 'cocoapi'...\n",
            "remote: Enumerating objects: 975, done.\u001b[K\n",
            "remote: Total 975 (delta 0), reused 0 (delta 0), pack-reused 975\u001b[K\n",
            "Receiving objects: 100% (975/975), 11.72 MiB | 23.36 MiB/s, done.\n",
            "Resolving deltas: 100% (576/576), done.\n",
            "/content/UAVHRBuildingDetection/cocoapi/PythonAPI\n",
            "python setup.py build_ext --inplace\n",
            "running build_ext\n",
            "cythoning pycocotools/_mask.pyx to pycocotools/_mask.c\n",
            "/usr/local/lib/python3.7/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/UAVHRBuildingDetection/cocoapi/PythonAPI/pycocotools/_mask.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "building 'pycocotools._mask' extension\n",
            "creating build\n",
            "creating build/common\n",
            "creating build/temp.linux-x86_64-3.7\n",
            "creating build/temp.linux-x86_64-3.7/pycocotools\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c ../common/maskApi.c -o build/temp.linux-x86_64-3.7/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleDecode\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:46:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n",
            "       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:46:49:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; \u001b[01;36m\u001b[Kv\u001b[m\u001b[K=!v; }}\n",
            "                                                 \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrPoly\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:166:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n",
            "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:166:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); \u001b[01;36m\u001b[Kx\u001b[m\u001b[K[k]=x[0];\n",
            "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:167:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n",
            "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:167:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); \u001b[01;36m\u001b[Ky\u001b[m\u001b[K[k]=y[0];\n",
            "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:212:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "       \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(more) c |= 0x20; c+=48; s[p++]=c;\n",
            "       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:212:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "       if(more) c |= 0x20; \u001b[01;36m\u001b[Kc\u001b[m\u001b[K+=48; s[p++]=c;\n",
            "                           \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:220:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kwhile\u001b[m\u001b[K( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n",
            "   \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:220:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’\n",
            "   while( s[m] ) m++; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K=malloc(sizeof(uint)*m); m=0;\n",
            "                      \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:228:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "     \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n",
            "     \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:228:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "     if(m>2) x+=(long) cnts[m-2]; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K[m++]=(uint) x;\n",
            "                                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToBbox\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:141:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kxp\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
            "       if(j%2==0) xp=x; else if\u001b[01;35m\u001b[K(\u001b[m\u001b[Kxp<x) { ys=0; ye=h-1; }\n",
            "                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c pycocotools/_mask.c -o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "creating build/lib.linux-x86_64-3.7\n",
            "creating build/lib.linux-x86_64-3.7/pycocotools\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/../common/maskApi.o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -o build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so -> pycocotools\n",
            "rm -rf build\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install object detection api\n",
        "%cd /content/UAVHRBuildingDetection/Tensorflow/models/research/\n",
        "!cp object_detection/packages/tf2/setup.py .\n",
        "!pip install --ignore-installed --use-feature=2020-resolver ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6511
        },
        "id": "LTQ82a_KxUgQ",
        "outputId": "00b42e25-64d1-4487-e382-4ca62c448eca"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UAVHRBuildingDetection/Tensorflow/models/research\n",
            "\u001b[33mWARNING: --use-feature=2020-resolver no longer has any effect, since it is now the default dependency resolver in pip. This will become an error in pip 21.0.\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/UAVHRBuildingDetection/Tensorflow/models/research\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.41.0-cp37-cp37m-manylinux2010_x86_64.whl (10.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.9 MB 8.2 MB/s \n",
            "\u001b[?25hCollecting pillow\n",
            "  Downloading Pillow-9.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 45.5 MB/s \n",
            "\u001b[?25hCollecting lxml\n",
            "  Downloading lxml-4.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 46.5 MB/s \n",
            "\u001b[?25hCollecting matplotlib\n",
            "  Downloading matplotlib-3.5.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.2 MB 48.0 MB/s \n",
            "\u001b[?25hCollecting Cython\n",
            "  Downloading Cython-0.29.32-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 51.3 MB/s \n",
            "\u001b[?25hCollecting contextlib2\n",
            "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 77.7 MB/s \n",
            "\u001b[?25hCollecting six\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pycocotools\n",
            "  Downloading pycocotools-2.0.4.tar.gz (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 75.6 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Collecting scipy\n",
            "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.1 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting pandas\n",
            "  Downloading pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.3 MB 48.1 MB/s \n",
            "\u001b[?25hCollecting tf-models-official>=2.5.1\n",
            "  Downloading tf_models_official-2.9.2-py2.py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 50.7 MB/s \n",
            "\u001b[?25hCollecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.26.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (25.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9 MB 95.4 MB/s \n",
            "\u001b[?25hCollecting keras\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 57.6 MB/s \n",
            "\u001b[?25hCollecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 6.4 MB/s \n",
            "\u001b[?25hCollecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.4 MB/s \n",
            "\u001b[?25hCollecting tensorflow-text~=2.9.0\n",
            "  Downloading tensorflow_text-2.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 52.5 MB/s \n",
            "\u001b[?25hCollecting py-cpuinfo>=3.3.0\n",
            "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
            "\u001b[K     |████████████████████████████████| 99 kB 13.1 MB/s \n",
            "\u001b[?25hCollecting google-api-python-client>=1.6.7\n",
            "  Downloading google_api_python_client-2.58.0-py2.py3-none-any.whl (9.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.0 MB 54.5 MB/s \n",
            "\u001b[?25hCollecting oauth2client\n",
            "  Downloading oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[K     |████████████████████████████████| 98 kB 8.8 MB/s \n",
            "\u001b[?25hCollecting tensorflow-datasets\n",
            "  Downloading tensorflow_datasets-4.6.0-py3-none-any.whl (4.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 48.5 MB/s \n",
            "\u001b[?25hCollecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.17.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 70.6 MB/s \n",
            "\u001b[?25hCollecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (48.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 48.3 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting kaggle>=1.3.9\n",
            "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 8.0 MB/s \n",
            "\u001b[?25hCollecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.3-py2.py3-none-any.whl (238 kB)\n",
            "\u001b[K     |████████████████████████████████| 238 kB 70.2 MB/s \n",
            "\u001b[?25hCollecting gin-config\n",
            "  Downloading gin_config-0.5.0-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 10.1 MB/s \n",
            "\u001b[?25hCollecting pyyaml<6.0,>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 74.8 MB/s \n",
            "\u001b[?25hCollecting sacrebleu\n",
            "  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
            "\u001b[K     |████████████████████████████████| 116 kB 74.9 MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 66.5 MB/s \n",
            "\u001b[?25hCollecting psutil>=5.4.3\n",
            "  Downloading psutil-5.9.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
            "\u001b[K     |████████████████████████████████| 281 kB 76.2 MB/s \n",
            "\u001b[?25hCollecting tensorflow~=2.9.0\n",
            "  Downloading tensorflow-2.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 511.7 MB 6.0 kB/s \n",
            "\u001b[?25hCollecting tensorflow-hub>=0.6.0\n",
            "  Downloading tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
            "\u001b[K     |████████████████████████████████| 108 kB 71.1 MB/s \n",
            "\u001b[?25hCollecting numpy>=1.20\n",
            "  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 45.7 MB/s \n",
            "\u001b[?25hCollecting uritemplate<5,>=3.0.1\n",
            "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
            "Collecting google-auth<3.0.0dev,>=1.19.0\n",
            "  Downloading google_auth-2.11.0-py2.py3-none-any.whl (167 kB)\n",
            "\u001b[K     |████████████████████████████████| 167 kB 64.7 MB/s \n",
            "\u001b[?25hCollecting google-auth-httplib2>=0.1.0\n",
            "  Downloading google_auth_httplib2-0.1.0-py2.py3-none-any.whl (9.3 kB)\n",
            "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5\n",
            "  Downloading google_api_core-2.8.2-py3-none-any.whl (114 kB)\n",
            "\u001b[K     |████████████████████████████████| 114 kB 71.8 MB/s \n",
            "\u001b[?25hCollecting httplib2<1dev,>=0.15.0\n",
            "  Downloading httplib2-0.20.4-py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 6.7 MB/s \n",
            "\u001b[?25hCollecting googleapis-common-protos<2.0dev,>=1.56.2\n",
            "  Downloading googleapis_common_protos-1.56.4-py2.py3-none-any.whl (211 kB)\n",
            "\u001b[K     |████████████████████████████████| 211 kB 71.7 MB/s \n",
            "\u001b[?25hCollecting requests<3.0.0dev,>=2.18.0\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.3 MB/s \n",
            "\u001b[?25hCollecting protobuf<5.0.0dev,>=3.15.0\n",
            "  Downloading protobuf-4.21.5-cp37-abi3-manylinux2014_x86_64.whl (408 kB)\n",
            "\u001b[K     |████████████████████████████████| 408 kB 73.8 MB/s \n",
            "\u001b[?25hCollecting pyasn1-modules>=0.2.1\n",
            "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
            "\u001b[K     |████████████████████████████████| 155 kB 74.9 MB/s \n",
            "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
            "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0\n",
            "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
            "Collecting certifi\n",
            "  Downloading certifi-2022.6.15-py3-none-any.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 52.1 MB/s \n",
            "\u001b[?25hCollecting python-dateutil\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[K     |████████████████████████████████| 247 kB 81.5 MB/s \n",
            "\u001b[?25hCollecting tqdm\n",
            "  Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 9.0 MB/s \n",
            "\u001b[?25hCollecting python-slugify\n",
            "  Downloading python_slugify-6.1.2-py2.py3-none-any.whl (9.4 kB)\n",
            "Collecting urllib3\n",
            "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 75.3 MB/s \n",
            "\u001b[?25hCollecting pytz>=2017.3\n",
            "  Downloading pytz-2022.2.1-py2.py3-none-any.whl (500 kB)\n",
            "\u001b[K     |████████████████████████████████| 500 kB 67.8 MB/s \n",
            "\u001b[?25hCollecting pyasn1<0.5.0,>=0.4.6\n",
            "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 7.4 MB/s \n",
            "\u001b[?25hCollecting idna<4,>=2.5\n",
            "  Downloading idna-3.3-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 9.6 MB/s \n",
            "\u001b[?25hCollecting charset-normalizer<3,>=2\n",
            "  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
            "Collecting protobuf<5.0.0dev,>=3.15.0\n",
            "  Downloading protobuf-3.19.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 66.9 MB/s \n",
            "\u001b[?25hCollecting absl-py>=1.0.0\n",
            "  Downloading absl_py-1.2.0-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 55.1 MB/s \n",
            "\u001b[?25hCollecting setuptools\n",
            "  Using cached setuptools-65.3.0-py3-none-any.whl (1.2 MB)\n",
            "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[K     |████████████████████████████████| 438 kB 69.5 MB/s \n",
            "\u001b[?25hCollecting flatbuffers<2,>=1.12\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.26.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4 MB 51.5 MB/s \n",
            "\u001b[?25hCollecting keras-preprocessing>=1.1.1\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.6 MB/s \n",
            "\u001b[?25hCollecting gast<=0.4.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Collecting typing-extensions>=3.6.6\n",
            "  Downloading typing_extensions-4.3.0-py3-none-any.whl (25 kB)\n",
            "Collecting libclang>=13.0.0\n",
            "  Downloading libclang-14.0.6-py2.py3-none-manylinux2010_x86_64.whl (14.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.1 MB 54.7 MB/s \n",
            "\u001b[?25hCollecting packaging\n",
            "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 7.5 MB/s \n",
            "\u001b[?25hCollecting google-pasta>=0.1.1\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 6.6 MB/s \n",
            "\u001b[?25hCollecting tensorboard<2.10,>=2.9\n",
            "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 50.3 MB/s \n",
            "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
            "  Downloading grpcio-1.47.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.5 MB 54.2 MB/s \n",
            "\u001b[?25hCollecting h5py>=2.9.0\n",
            "  Downloading h5py-3.7.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 41.2 MB/s \n",
            "\u001b[?25hCollecting termcolor>=1.1.0\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "Collecting wrapt>=1.11.0\n",
            "  Downloading wrapt-1.14.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 5.4 MB/s \n",
            "\u001b[?25hCollecting astunparse>=1.6.0\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Collecting opt-einsum>=2.3.2\n",
            "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting wheel<1.0,>=0.23.0\n",
            "  Using cached wheel-0.37.1-py2.py3-none-any.whl (35 kB)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 52.5 MB/s \n",
            "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[K     |████████████████████████████████| 781 kB 70.4 MB/s \n",
            "\u001b[?25hCollecting werkzeug>=1.0.1\n",
            "  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
            "\u001b[K     |████████████████████████████████| 232 kB 77.7 MB/s \n",
            "\u001b[?25hCollecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.3 MB/s \n",
            "\u001b[?25hCollecting requests-oauthlib>=0.7.0\n",
            "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
            "Collecting importlib-metadata>=4.4\n",
            "  Downloading importlib_metadata-4.12.0-py3-none-any.whl (21 kB)\n",
            "Collecting zipp>=0.5\n",
            "  Downloading zipp-3.8.1-py3-none-any.whl (5.6 kB)\n",
            "Collecting oauthlib>=3.0.0\n",
            "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 69.5 MB/s \n",
            "\u001b[?25hCollecting dm-tree~=0.1.1\n",
            "  Downloading dm_tree-0.1.7-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (143 kB)\n",
            "\u001b[K     |████████████████████████████████| 143 kB 75.7 MB/s \n",
            "\u001b[?25hCollecting MarkupSafe>=2.1.1\n",
            "  Downloading MarkupSafe-2.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting crcmod<2.0,>=1.7\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[K     |████████████████████████████████| 89 kB 12.2 MB/s \n",
            "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 68.3 MB/s \n",
            "\u001b[?25hCollecting pyarrow<8.0.0,>=0.15.1\n",
            "  Downloading pyarrow-7.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.7 MB 103.2 MB/s \n",
            "\u001b[?25hCollecting pymongo<4.0.0,>=3.8.0\n",
            "  Downloading pymongo-3.12.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (508 kB)\n",
            "\u001b[K     |████████████████████████████████| 508 kB 66.5 MB/s \n",
            "\u001b[?25hCollecting pydot<2,>=1.2.0\n",
            "  Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
            "Collecting fastavro<2,>=0.23.6\n",
            "  Downloading fastavro-1.6.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4 MB 57.3 MB/s \n",
            "\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
            "Collecting cloudpickle<3,>=2.1.0\n",
            "  Downloading cloudpickle-2.1.0-py3-none-any.whl (25 kB)\n",
            "Collecting orjson<4.0\n",
            "  Downloading orjson-3.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (270 kB)\n",
            "\u001b[K     |████████████████████████████████| 270 kB 73.3 MB/s \n",
            "\u001b[?25hCollecting proto-plus<2,>=1.7.1\n",
            "  Downloading proto_plus-1.22.0-py3-none-any.whl (47 kB)\n",
            "\u001b[K     |████████████████████████████████| 47 kB 6.2 MB/s \n",
            "\u001b[?25hCollecting docopt\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "Collecting opencv-python>=4.1.0.25\n",
            "  Downloading opencv_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 60.9 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting kiwisolver>=1.1.0\n",
            "  Downloading kiwisolver-1.4.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 65.1 MB/s \n",
            "\u001b[?25hCollecting cycler>=0.10.0\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.37.1-py3-none-any.whl (957 kB)\n",
            "\u001b[K     |████████████████████████████████| 957 kB 75.0 MB/s \n",
            "\u001b[?25hCollecting text-unidecode>=1.3\n",
            "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 8.8 MB/s \n",
            "\u001b[?25hCollecting regex\n",
            "  Downloading regex-2022.8.17-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (752 kB)\n",
            "\u001b[K     |████████████████████████████████| 752 kB 70.3 MB/s \n",
            "\u001b[?25hCollecting portalocker\n",
            "  Downloading portalocker-2.5.1-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tabulate>=0.8.9\n",
            "  Downloading tabulate-0.8.10-py3-none-any.whl (29 kB)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
            "Collecting scikit-learn>=0.21.3\n",
            "  Downloading scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.8 MB 1.6 MB/s \n",
            "\u001b[?25hCollecting joblib>=0.11\n",
            "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
            "\u001b[K     |████████████████████████████████| 306 kB 65.4 MB/s \n",
            "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting typeguard>=2.7\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Collecting importlib-resources\n",
            "  Downloading importlib_resources-5.9.0-py3-none-any.whl (33 kB)\n",
            "Collecting toml\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting etils[epath]\n",
            "  Downloading etils-0.7.1-py3-none-any.whl (124 kB)\n",
            "\u001b[K     |████████████████████████████████| 124 kB 74.1 MB/s \n",
            "\u001b[?25hCollecting tensorflow-metadata\n",
            "  Downloading tensorflow_metadata-1.10.0-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.6 MB/s \n",
            "\u001b[?25hCollecting promise\n",
            "  Downloading promise-2.3.tar.gz (19 kB)\n",
            "Building wheels for collected packages: object-detection, kaggle, py-cpuinfo, termcolor, crcmod, dill, avro-python3, docopt, pycocotools, seqeval, promise\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1694955 sha256=098663068d0e0b609ff6476070bf5423c6e7945392cae9514852e665a650bc2c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-lpjsq6j4/wheels/d1/88/4c/6e266386b82f3ada7b4a0729eeff3721d08a9ba6a71efc7a13\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73051 sha256=27817b8adfa715d4ebc7dc7498d325d7698e840d8f3afff0d8c9065e7cbe576d\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/d6/58/5853130f941e75b2177d281eb7e44b4a98ed46dd155f556dc5\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=6aeef082332463865837266f130655e0ce5b9210e1ff190193a8f91178b67270\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4848 sha256=bc1ba30c2f6eae5a55daa56bba21a4c3499d79a2d79bb190dbe1b39c2a8568c7\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp37-cp37m-linux_x86_64.whl size=36351 sha256=5728d3bed070b599e5a54cb758acbf0ad8270a17e53070b64faa055e9c940347\n",
            "  Stored in directory: /root/.cache/pip/wheels/dc/9a/e9/49e627353476cec8484343c4ab656f1e0d783ee77b9dde2d1f\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=edd90492e0c8741a3de6d782a0c2ba303775d5dd42f4f4446cc00891b7998285\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44010 sha256=e565819dfb9b78b06cc57bfefb6723fd030123f332865b5b80a194b74484ab52\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/e5/b1/6b151d9b535ee50aaa6ab27d145a0104b6df02e5636f0376da\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=37fb973c73d2af62289985484c6c3b81b1b7b4a5bd59cfa615b9a3d64f67d597\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/b0/3f/1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\n",
            "  Building wheel for pycocotools (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0.4-cp37-cp37m-linux_x86_64.whl size=265251 sha256=b317ac3aceff49556688da864dd50a406680ba12f997957ae40b25984ba7e284\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/5f/fa/f011e578cc76e1fc5be8dce30b3eb9fd00f337e744b3bba59b\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=bb3658d1f69324b08757ee5a683246ead6b6c9bca600774cc04c38ac3d742029\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "  Building wheel for promise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21503 sha256=d040a9fe8164966e2e9fe736fbad9c70557a8485de5cc0d8fdf2b941d5576e91\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/93/c6/762e359f8cb6a5b69c72235d798804cae523bbe41c2aa8333d\n",
            "Successfully built object-detection kaggle py-cpuinfo termcolor crcmod dill avro-python3 docopt pycocotools seqeval promise\n",
            "Installing collected packages: urllib3, pyasn1, idna, charset-normalizer, certifi, zipp, typing-extensions, six, rsa, requests, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, MarkupSafe, importlib-metadata, google-auth, wheel, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, setuptools, pyparsing, protobuf, numpy, markdown, grpcio, google-auth-oauthlib, etils, absl-py, wrapt, threadpoolctl, text-unidecode, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, scipy, python-dateutil, pillow, packaging, opt-einsum, libclang, kiwisolver, keras-preprocessing, keras, joblib, importlib-resources, httplib2, h5py, googleapis-common-protos, google-pasta, gast, fonttools, flatbuffers, cycler, astunparse, uritemplate, typeguard, tqdm, toml, tensorflow-metadata, tensorflow-hub, tensorflow, tabulate, scikit-learn, regex, pytz, python-slugify, promise, portalocker, matplotlib, lxml, google-auth-httplib2, google-api-core, docopt, dm-tree, dill, colorama, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-datasets, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, pymongo, pydot, pycocotools, pyarrow, py-cpuinfo, psutil, proto-plus, pandas, orjson, opencv-python-headless, opencv-python, oauth2client, kaggle, hdfs, google-api-python-client, gin-config, fastavro, Cython, crcmod, cloudpickle, tf-models-official, tensorflow-io, lvis, contextlib2, avro-python3, apache-beam, object-detection\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\n",
            "thinc 8.1.0 requires typing-extensions<4.2.0,>=3.7.4.1; python_version < \"3.8\", but you have typing-extensions 4.3.0 which is incompatible.\n",
            "spacy 3.4.1 requires typing-extensions<4.2.0,>=3.7.4; python_version < \"3.8\", but you have typing-extensions 4.3.0 which is incompatible.\n",
            "google-cloud-translate 1.5.0 requires google-api-core[grpc]<2.0.0dev,>=1.6.0, but you have google-api-core 2.8.2 which is incompatible.\n",
            "google-cloud-language 1.2.0 requires google-api-core[grpc]<2.0.0dev,>=1.6.0, but you have google-api-core 2.8.2 which is incompatible.\n",
            "google-cloud-firestore 1.7.0 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.8.2 which is incompatible.\n",
            "google-cloud-datastore 1.8.0 requires google-api-core[grpc]<2.0.0dev,>=1.6.0, but you have google-api-core 2.8.2 which is incompatible.\n",
            "google-cloud-core 1.0.3 requires google-api-core<2.0.0dev,>=1.14.0, but you have google-api-core 2.8.2 which is incompatible.\n",
            "flask 1.1.4 requires Werkzeug<2.0,>=0.15, but you have werkzeug 2.2.2 which is incompatible.\n",
            "firebase-admin 4.4.0 requires google-api-core[grpc]<2.0.0dev,>=1.14.0; platform_python_implementation != \"PyPy\", but you have google-api-core 2.8.2 which is incompatible.\n",
            "earthengine-api 0.1.320 requires google-api-python-client<2,>=1.12.1, but you have google-api-python-client 2.58.0 which is incompatible.\u001b[0m\n",
            "Successfully installed Cython-0.29.32 MarkupSafe-2.1.1 absl-py-1.2.0 apache-beam-2.41.0 astunparse-1.6.3 avro-python3-1.10.2 cachetools-5.2.0 certifi-2022.6.15 charset-normalizer-2.1.1 cloudpickle-2.1.0 colorama-0.4.5 contextlib2-21.6.0 crcmod-1.7 cycler-0.11.0 dill-0.3.5.1 dm-tree-0.1.7 docopt-0.6.2 etils-0.7.1 fastavro-1.6.0 flatbuffers-2.0 fonttools-4.37.1 gast-0.5.3 gin-config-0.5.0 google-api-core-2.8.2 google-api-python-client-2.58.0 google-auth-2.11.0 google-auth-httplib2-0.1.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 googleapis-common-protos-1.56.4 grpcio-1.47.0 h5py-3.7.0 hdfs-2.7.0 httplib2-0.20.4 idna-3.3 importlib-metadata-4.12.0 importlib-resources-5.9.0 joblib-1.1.0 kaggle-1.5.12 keras-2.9.0 keras-preprocessing-1.1.2 kiwisolver-1.4.4 libclang-14.0.6 lvis-0.5.3 lxml-4.9.1 markdown-3.4.1 matplotlib-3.5.3 numpy-1.21.6 oauth2client-4.1.3 oauthlib-3.2.0 object-detection-0.1 opencv-python-4.6.0.66 opencv-python-headless-4.6.0.66 opt-einsum-3.3.0 orjson-3.8.0 packaging-21.3 pandas-1.3.5 pillow-9.2.0 portalocker-2.5.1 promise-2.3 proto-plus-1.22.0 protobuf-3.19.4 psutil-5.9.1 py-cpuinfo-8.0.0 pyarrow-7.0.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycocotools-2.0.4 pydot-1.4.2 pymongo-4.2.0 pyparsing-3.0.9 python-dateutil-2.8.2 python-slugify-6.1.2 pytz-2022.2.1 pyyaml-6.0 regex-2022.8.17 requests-2.28.1 requests-oauthlib-1.3.1 rsa-4.9 sacrebleu-2.2.0 scikit-learn-1.0.2 scipy-1.7.3 sentencepiece-0.1.97 seqeval-1.2.2 setuptools-65.3.0 six-1.16.0 tabulate-0.8.10 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.9.1 tensorflow-addons-0.17.1 tensorflow-datasets-4.6.0 tensorflow-estimator-2.9.0 tensorflow-hub-0.12.0 tensorflow-io-0.26.0 tensorflow-io-gcs-filesystem-0.26.0 tensorflow-metadata-1.10.0 tensorflow-model-optimization-0.7.3 tensorflow-text-2.9.0 termcolor-1.1.0 text-unidecode-1.3 tf-models-official-2.9.2 tf-slim-1.1.0 threadpoolctl-3.1.0 toml-0.10.2 tqdm-4.64.0 typeguard-2.13.3 typing-extensions-4.3.0 uritemplate-4.1.1 urllib3-1.26.12 werkzeug-2.2.2 wheel-0.37.1 wrapt-1.14.1 zipp-3.8.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "cycler",
                  "dateutil",
                  "google",
                  "kiwisolver",
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy",
                  "pkg_resources",
                  "psutil",
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify installation\n",
        "%cd /content/UAVHRBuildingDetection/Tensorflow/models/research/\n",
        "!python object_detection/builders/model_builder_tf2_test.py\n",
        "\n",
        "# return to content directory\n",
        "%cd /content/UAVHRBuildingDetection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "HVHMexLgxV_6",
        "outputId": "ca40af17-17f7-49e8-a1ad-efd3b1866220"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UAVHRBuildingDetection/Tensorflow/models/research\n",
            "Running tests under Python 3.7.13: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2022-08-29 10:10:37.019534: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "W0829 10:10:37.250630 140475103328128 model_builder.py:1102] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.42s\n",
            "I0829 10:10:37.500452 140475103328128 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.42s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.69s\n",
            "I0829 10:10:38.186293 140475103328128 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.69s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.27s\n",
            "I0829 10:10:38.453799 140475103328128 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.27s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.24s\n",
            "I0829 10:10:38.695714 140475103328128 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.24s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.67s\n",
            "I0829 10:10:40.365542 140475103328128 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.67s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0829 10:10:40.366434 140475103328128 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
            "I0829 10:10:40.388626 140475103328128 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
            "I0829 10:10:40.401901 140475103328128 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
            "I0829 10:10:40.415967 140475103328128 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.09s\n",
            "I0829 10:10:40.508565 140475103328128 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.08s\n",
            "I0829 10:10:40.593655 140475103328128 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.08s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.1s\n",
            "I0829 10:10:40.693560 140475103328128 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.1s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.09s\n",
            "I0829 10:10:40.786169 140475103328128 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.09s\n",
            "I0829 10:10:40.879557 140475103328128 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "I0829 10:10:40.906768 140475103328128 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0829 10:10:41.242452 140475103328128 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0829 10:10:41.242607 140475103328128 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n",
            "I0829 10:10:41.242682 140475103328128 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\n",
            "I0829 10:10:41.244885 140475103328128 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0829 10:10:41.261844 140475103328128 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0829 10:10:41.261992 140475103328128 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0829 10:10:41.324525 140475103328128 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0829 10:10:41.324689 140475103328128 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0829 10:10:41.474248 140475103328128 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0829 10:10:41.474393 140475103328128 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0829 10:10:41.637062 140475103328128 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0829 10:10:41.637204 140475103328128 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0829 10:10:41.876035 140475103328128 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0829 10:10:41.876203 140475103328128 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0829 10:10:42.118818 140475103328128 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0829 10:10:42.119009 140475103328128 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0829 10:10:42.426715 140475103328128 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0829 10:10:42.426889 140475103328128 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0829 10:10:42.498497 140475103328128 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0829 10:10:42.530269 140475103328128 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0829 10:10:42.579276 140475103328128 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0829 10:10:42.579402 140475103328128 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\n",
            "I0829 10:10:42.579473 140475103328128 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 4\n",
            "I0829 10:10:42.580922 140475103328128 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0829 10:10:42.596551 140475103328128 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0829 10:10:42.596650 140475103328128 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0829 10:10:42.725077 140475103328128 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0829 10:10:42.725213 140475103328128 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0829 10:10:42.962756 140475103328128 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0829 10:10:42.962937 140475103328128 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0829 10:10:43.193404 140475103328128 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0829 10:10:43.193573 140475103328128 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0829 10:10:43.512994 140475103328128 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0829 10:10:43.513177 140475103328128 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0829 10:10:43.830451 140475103328128 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0829 10:10:43.830617 140475103328128 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0829 10:10:44.215047 140475103328128 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0829 10:10:44.215308 140475103328128 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0829 10:10:44.372408 140475103328128 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0829 10:10:44.400810 140475103328128 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0829 10:10:44.460782 140475103328128 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0829 10:10:44.460959 140475103328128 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112\n",
            "I0829 10:10:44.461042 140475103328128 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 5\n",
            "I0829 10:10:44.462752 140475103328128 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0829 10:10:44.478351 140475103328128 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0829 10:10:44.478459 140475103328128 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0829 10:10:44.595939 140475103328128 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0829 10:10:44.596077 140475103328128 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0829 10:10:44.836039 140475103328128 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0829 10:10:44.836196 140475103328128 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0829 10:10:45.070441 140475103328128 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0829 10:10:45.070601 140475103328128 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0829 10:10:45.381078 140475103328128 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0829 10:10:45.381243 140475103328128 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0829 10:10:45.687926 140475103328128 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0829 10:10:45.688081 140475103328128 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0829 10:10:46.273717 140475103328128 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0829 10:10:46.273906 140475103328128 efficientnet_model.py:143] round_filter input=320 output=352\n",
            "I0829 10:10:46.424870 140475103328128 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
            "I0829 10:10:46.454010 140475103328128 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0829 10:10:46.510058 140475103328128 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0829 10:10:46.510178 140475103328128 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n",
            "I0829 10:10:46.510250 140475103328128 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 6\n",
            "I0829 10:10:46.511690 140475103328128 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0829 10:10:46.526658 140475103328128 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0829 10:10:46.526760 140475103328128 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0829 10:10:46.649881 140475103328128 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0829 10:10:46.650067 140475103328128 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0829 10:10:46.891120 140475103328128 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0829 10:10:46.891290 140475103328128 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0829 10:10:47.120787 140475103328128 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0829 10:10:47.120968 140475103328128 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0829 10:10:47.503819 140475103328128 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0829 10:10:47.504012 140475103328128 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0829 10:10:47.910688 140475103328128 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0829 10:10:47.910863 140475103328128 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0829 10:10:48.508748 140475103328128 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0829 10:10:48.508978 140475103328128 efficientnet_model.py:143] round_filter input=320 output=384\n",
            "I0829 10:10:48.718660 140475103328128 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
            "I0829 10:10:48.761024 140475103328128 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0829 10:10:48.872395 140475103328128 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0829 10:10:48.872591 140475103328128 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\n",
            "I0829 10:10:48.872675 140475103328128 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
            "I0829 10:10:48.875097 140475103328128 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0829 10:10:48.897422 140475103328128 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0829 10:10:48.897563 140475103328128 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0829 10:10:49.066990 140475103328128 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0829 10:10:49.067227 140475103328128 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0829 10:10:49.505522 140475103328128 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0829 10:10:49.505729 140475103328128 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0829 10:10:49.820594 140475103328128 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0829 10:10:49.820785 140475103328128 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0829 10:10:50.290496 140475103328128 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0829 10:10:50.290673 140475103328128 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0829 10:10:50.753646 140475103328128 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0829 10:10:50.753814 140475103328128 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0829 10:10:51.387933 140475103328128 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0829 10:10:51.388107 140475103328128 efficientnet_model.py:143] round_filter input=320 output=448\n",
            "I0829 10:10:51.535589 140475103328128 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
            "I0829 10:10:51.566377 140475103328128 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0829 10:10:51.641904 140475103328128 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0829 10:10:51.642077 140475103328128 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288\n",
            "I0829 10:10:51.642150 140475103328128 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
            "I0829 10:10:51.643673 140475103328128 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0829 10:10:51.659061 140475103328128 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0829 10:10:51.659166 140475103328128 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0829 10:10:51.847691 140475103328128 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0829 10:10:51.847842 140475103328128 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0829 10:10:52.479967 140475103328128 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0829 10:10:52.480145 140475103328128 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0829 10:10:52.860463 140475103328128 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0829 10:10:52.860625 140475103328128 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0829 10:10:53.427014 140475103328128 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0829 10:10:53.427194 140475103328128 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0829 10:10:53.983193 140475103328128 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0829 10:10:53.983361 140475103328128 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0829 10:10:54.683435 140475103328128 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0829 10:10:54.683614 140475103328128 efficientnet_model.py:143] round_filter input=320 output=512\n",
            "I0829 10:10:54.913744 140475103328128 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
            "I0829 10:10:54.949548 140475103328128 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0829 10:10:55.035265 140475103328128 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0829 10:10:55.035416 140475103328128 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
            "I0829 10:10:55.035485 140475103328128 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
            "I0829 10:10:55.036988 140475103328128 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0829 10:10:55.052140 140475103328128 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0829 10:10:55.052242 140475103328128 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0829 10:10:55.238858 140475103328128 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0829 10:10:55.239028 140475103328128 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0829 10:10:55.695267 140475103328128 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0829 10:10:55.695433 140475103328128 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0829 10:10:56.161098 140475103328128 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0829 10:10:56.161317 140475103328128 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0829 10:10:56.791898 140475103328128 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0829 10:10:56.792088 140475103328128 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0829 10:10:57.428981 140475103328128 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0829 10:10:57.429154 140475103328128 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0829 10:10:58.299089 140475103328128 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0829 10:10:58.299260 140475103328128 efficientnet_model.py:143] round_filter input=320 output=576\n",
            "I0829 10:10:58.525382 140475103328128 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
            "I0829 10:10:58.557623 140475103328128 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0829 10:10:58.887957 140475103328128 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0829 10:10:58.888133 140475103328128 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
            "I0829 10:10:58.888209 140475103328128 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
            "I0829 10:10:58.889806 140475103328128 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0829 10:10:58.906669 140475103328128 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0829 10:10:58.906798 140475103328128 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0829 10:10:59.167461 140475103328128 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0829 10:10:59.167625 140475103328128 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0829 10:10:59.706497 140475103328128 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0829 10:10:59.706672 140475103328128 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0829 10:11:00.256524 140475103328128 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0829 10:11:00.256694 140475103328128 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0829 10:11:01.023777 140475103328128 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0829 10:11:01.023956 140475103328128 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0829 10:11:01.813085 140475103328128 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0829 10:11:01.813249 140475103328128 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0829 10:11:02.832183 140475103328128 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0829 10:11:02.832398 140475103328128 efficientnet_model.py:143] round_filter input=320 output=640\n",
            "I0829 10:11:03.156817 140475103328128 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
            "I0829 10:11:03.187058 140475103328128 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 22.39s\n",
            "I0829 10:11:03.301860 140475103328128 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 22.39s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I0829 10:11:03.307330 140475103328128 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0829 10:11:03.308858 140475103328128 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0829 10:11:03.309341 140475103328128 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0829 10:11:03.310720 140475103328128 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0829 10:11:03.312006 140475103328128 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0829 10:11:03.312435 140475103328128 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0829 10:11:03.313398 140475103328128 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 27.229s\n",
            "\n",
            "OK (skipped=1)\n",
            "/content/UAVHRBuildingDetection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create directories for pretrained models and custom models in workspace"
      ],
      "metadata": {
        "id": "VDNCmFR1CnSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(paths[\"pretrained_models\"]):\n",
        "  os.makedirs(paths[\"pretrained_models\"])\n",
        "\n",
        "if not os.path.exists(paths[\"custom_models\"]):\n",
        "  os.makedirs(paths[\"custom_models\"])"
      ],
      "metadata": {
        "id": "WMLy0Wx3Csxj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install other python packages"
      ],
      "metadata": {
        "id": "P267uD75lE2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wget"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "gvHMyrW6lI4r",
        "outputId": "f4271022-5489-40e0-8126-7a0bd0247899"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9657 sha256=56b5e6491d88abdd36c05832e572b5bb04b779891644556709b33def0ce2aafb\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download pre-trained model"
      ],
      "metadata": {
        "id": "uIUttk2BkFi-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wget\n",
        "# download pretrained model\n",
        "%cd {paths[\"pretrained_models\"]}\n",
        "preModZipName = PRETRAINED_MODEL_NAME + \".tar.gz\"\n",
        "\n",
        "if not os.path.exists(preModZipName):\n",
        "  wget.download(PRETRAINED_MODEL_URL)\n",
        "\n",
        "if not os.path.exists(PRETRAINED_MODEL_NAME):\n",
        "  !tar -zxvf {PRETRAINED_MODEL_NAME + \".tar.gz\"}\n",
        "\n",
        "%cd {paths[\"github_repo\"]}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sLzYy5BkLg_",
        "outputId": "3e151074-7931-4c6a-9a0e-fa2e949c1feb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UAVHRBuildingDetection/Tensorflow/workspace/pretrained_model\n",
            "ssd_mobilenet_v2_320x320_coco17_tpu-8/\n",
            "ssd_mobilenet_v2_320x320_coco17_tpu-8/checkpoint/\n",
            "ssd_mobilenet_v2_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "ssd_mobilenet_v2_320x320_coco17_tpu-8/checkpoint/checkpoint\n",
            "ssd_mobilenet_v2_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "ssd_mobilenet_v2_320x320_coco17_tpu-8/pipeline.config\n",
            "ssd_mobilenet_v2_320x320_coco17_tpu-8/saved_model/\n",
            "ssd_mobilenet_v2_320x320_coco17_tpu-8/saved_model/saved_model.pb\n",
            "ssd_mobilenet_v2_320x320_coco17_tpu-8/saved_model/variables/\n",
            "ssd_mobilenet_v2_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "ssd_mobilenet_v2_320x320_coco17_tpu-8/saved_model/variables/variables.index\n",
            "/content/UAVHRBuildingDetection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Training Pipeline"
      ],
      "metadata": {
        "id": "kAlZZ0yXyoQ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy labelmap"
      ],
      "metadata": {
        "id": "4pr3yoKq-LKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from shutil import copyfile\n",
        "\n",
        "if not os.path.exists(os.path.join(paths[\"annotations\"], LABEL_MAP_NAME)):\n",
        "  copyfile(os.path.join(\"Dataset\",DATASET_REPO_NAME,LABEL_MAP_NAME), os.path.join(paths[\"annotations\"], LABEL_MAP_NAME))  "
      ],
      "metadata": {
        "id": "OHbakWIG-ZGr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Partition dataset"
      ],
      "metadata": {
        "id": "9AbHg5y065SJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from Tensorflow.scripts.preprocessing.datasetPartitioning import partition \n",
        "\n",
        "imgTestPath = os.path.join(paths[\"images\"],\"test\")\n",
        "imgTrainPath = os.path.join(paths[\"images\"], \"train\")\n",
        "ratio = 0.1\n",
        "\n",
        "!pwd\n",
        "\n",
        "# Create partitioning if train and test directories do not exist\n",
        "if not os.path.exists(imgTestPath) or not os.path.exists(imgTrainPath):\n",
        "  partition(paths[\"dataset_images\"], paths[\"dataset_labels\"], paths[\"images\"], ratio, \"png\")\n",
        "\n",
        "# Or if the directories are empty\n",
        "elif not os.listdir(imgTestPath) or not os.listdir(imgTrainPath):\n",
        "  partition(paths[\"dataset_images\"], paths[\"dataset_labels\"], paths[\"images\"], ratio, \"png\")"
      ],
      "metadata": {
        "id": "VoXHbrWK7Ahf",
        "outputId": "42626ee5-8665-4258-af59-ebf96aa9ef6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UAVHRBuildingDetection\n",
            "Partitioning the images...\n",
            "Copying matching labels...\n",
            "Verifying Test partition...\n",
            "Test partition o.k. !\n",
            "Verifying Train partition...\n",
            "Train partition o.k. !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "perform data augmentation"
      ],
      "metadata": {
        "id": "xbm5WYfKXiAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from Tensorflow.scripts.preprocessing.dataAugmentation import augmentData\n",
        "\n",
        "probabilities =  [0.5, 0.5, 0.25, 0.25]\n",
        "nAugmentations = 10\n",
        "testPath = os.path.join(paths[\"images\"],\"test\")\n",
        "trainPath = os.path.join(paths[\"images\"], \"train\")\n",
        "\n",
        "# Augment Test data\n",
        "augmentData(testPath, testPath, testPath, INPUT_DIMS, nAugmentations, probabilities, \"png\")\n",
        "\n",
        "# Augment Train data\n",
        "augmentData(trainPath, trainPath, trainPath, INPUT_DIMS, nAugmentations, probabilities, \"png\")"
      ],
      "metadata": {
        "id": "eX6s2w8pXkjr"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create tfrecord files for training and test data"
      ],
      "metadata": {
        "id": "Wv7HxrtMyyMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#if not os.path.exists(os.path.join(paths[\"annotations\"], \"train.record\")):\n",
        "!python {os.path.join(paths[\"scripts_pre\"],\"generate_tfrecord.py\")} -x {os.path.join(paths[\"images\"],\"train\")} -l {os.path.join(paths[\"annotations\"], LABEL_MAP_NAME)} -o {os.path.join(paths[\"annotations\"], \"train.record\" )} -i {os.path.join(paths[\"images\"],\"train\")}\n",
        "\n",
        "#if not os.path.exists(os.path.join(paths[\"annotations\"], \"test.record\")):\n",
        "!python {os.path.join(paths[\"scripts_pre\"],\"generate_tfrecord.py\")} -x {os.path.join(paths[\"images\"],\"test\")} -l {os.path.join(paths[\"annotations\"], LABEL_MAP_NAME)} -o {os.path.join(paths[\"annotations\"], \"test.record\" )} -i {os.path.join(paths[\"images\"],\"test\")}"
      ],
      "metadata": {
        "id": "ktavbHFHy3Z1",
        "outputId": "7a0b33f1-098d-48cd-ea09-3080d33b8d74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully created the TFRecord file: //content/UAVHRBuildingDetection/Tensorflow/workspace/annotations/train.record\n",
            "Successfully created the TFRecord file: //content/UAVHRBuildingDetection/Tensorflow/workspace/annotations/test.record\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "copy and adapt pipline config if necessary"
      ],
      "metadata": {
        "id": "OEWJr8-M9qBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from google.protobuf import text_format\n",
        "\n",
        "\n",
        "\n",
        "# Create custom model directory\n",
        "if not os.path.exists(paths[\"custom_model_dir\"] ):\n",
        "  os.makedirs(paths[\"custom_model_dir\"])\n",
        "\n",
        "if not os.path.exists(paths[\"custom_model_config\"]):\n",
        "  # Copy Config if necessary\n",
        "  if os.name == \"posix\":\n",
        "    !cp {os.path.join(paths[\"pretrained_models\"], PRETRAINED_MODEL_NAME,\"pipeline.config\")} {paths[\"custom_model_config\"]}\n",
        "  elif os.name == \"nt\":\n",
        "    !copy {os.path.join(paths[\"pretrained_models\"], PRETRAINED_MODEL_NAME,\"pipeline.config\")} {paths[\"custom_model_config\"]}\n",
        "  \n",
        "\n",
        "  # adapt config\n",
        "  config = config_util.get_configs_from_pipeline_file(paths[\"custom_model_config\"])\n",
        "\n",
        "  pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "  with tf.io.gfile.GFile(paths['custom_model_config'], \"r\") as f:                                                                                                                                                                                                                     \n",
        "      proto_str = f.read()                                                                                                                                                                                                                                          \n",
        "      text_format.Merge(proto_str, pipeline_config)  \n",
        "\n",
        "  pipeline_config.model.ssd.num_classes = NOF_CLASSES\n",
        "  pipeline_config.train_config.batch_size = 4\n",
        "  pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths[\"pretrained_models\"], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
        "  pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
        "  pipeline_config.train_input_reader.label_map_path= os.path.join(paths[\"annotations\"],LABEL_MAP_NAME)\n",
        "  pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths[\"annotations\"], 'train.record')]\n",
        "  pipeline_config.eval_input_reader[0].label_map_path = os.path.join(paths[\"annotations\"],LABEL_MAP_NAME)\n",
        "  pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths[\"annotations\"], 'test.record')]\n",
        "\n",
        "  config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
        "  with tf.io.gfile.GFile(paths[\"custom_model_config\"], \"wb\") as f:                                                                                                                                                                                                                     \n",
        "      f.write(config_text)   "
      ],
      "metadata": {
        "id": "zMHo2Mfp9umt"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "bpTdLaJ5O59u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAINING_SCRIPT = os.path.join(paths[\"obj_detection_api\"],\"model_main_tf2.py\")\n",
        "cmd = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps={}\".format(TRAINING_SCRIPT, os.path.join(paths[\"custom_models\"], CUSTOM_MODEL_NAME), paths[\"custom_model_config\"],NOF_STEPS)\n",
        "cmd\n",
        "!{cmd}"
      ],
      "metadata": {
        "id": "XCP97JHVO-56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cc89519-d4a0-46c1-d17f-1538624547bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-08-24 09:00:33.119140: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I0824 09:00:33.125650 139739119789952 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 10000\n",
            "I0824 09:00:33.134002 139739119789952 config_util.py:552] Maybe overwriting train_steps: 10000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0824 09:00:33.134173 139739119789952 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0824 09:00:33.162865 139739119789952 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['//content/UAVHRBuildingDetection/Tensorflow/workspace/annotations/train.record']\n",
            "I0824 09:00:33.167122 139739119789952 dataset_builder.py:162] Reading unweighted datasets: ['//content/UAVHRBuildingDetection/Tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['//content/UAVHRBuildingDetection/Tensorflow/workspace/annotations/train.record']\n",
            "I0824 09:00:33.167325 139739119789952 dataset_builder.py:79] Reading record datasets for input file: ['//content/UAVHRBuildingDetection/Tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0824 09:00:33.167418 139739119789952 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0824 09:00:33.167488 139739119789952 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0824 09:00:33.169853 139739119789952 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0824 09:00:33.193644 139739119789952 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0824 09:00:39.970070 139739119789952 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0824 09:00:42.823250 139739119789952 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0824 09:00:44.267630 139739119789952 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W0824 09:01:14.057896 139734158845696 deprecation.py:560] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "INFO:tensorflow:Step 1100 per-step time 0.673s\n",
            "I0824 09:02:21.044131 139739119789952 model_lib_v2.py:707] Step 1100 per-step time 0.673s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19826646,\n",
            " 'Loss/localization_loss': 0.21033911,\n",
            " 'Loss/regularization_loss': 0.1502916,\n",
            " 'Loss/total_loss': 0.5588972,\n",
            " 'learning_rate': 0.07999918}\n",
            "I0824 09:02:21.044486 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.19826646,\n",
            " 'Loss/localization_loss': 0.21033911,\n",
            " 'Loss/regularization_loss': 0.1502916,\n",
            " 'Loss/total_loss': 0.5588972,\n",
            " 'learning_rate': 0.07999918}\n",
            "INFO:tensorflow:Step 1200 per-step time 0.311s\n",
            "I0824 09:02:52.135875 139739119789952 model_lib_v2.py:707] Step 1200 per-step time 0.311s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.21423791,\n",
            " 'Loss/localization_loss': 0.2438797,\n",
            " 'Loss/regularization_loss': 0.15001732,\n",
            " 'Loss/total_loss': 0.6081349,\n",
            " 'learning_rate': 0.079996705}\n",
            "I0824 09:02:52.136217 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.21423791,\n",
            " 'Loss/localization_loss': 0.2438797,\n",
            " 'Loss/regularization_loss': 0.15001732,\n",
            " 'Loss/total_loss': 0.6081349,\n",
            " 'learning_rate': 0.079996705}\n",
            "INFO:tensorflow:Step 1300 per-step time 0.316s\n",
            "I0824 09:03:23.694174 139739119789952 model_lib_v2.py:707] Step 1300 per-step time 0.316s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.24536054,\n",
            " 'Loss/localization_loss': 0.19050823,\n",
            " 'Loss/regularization_loss': 0.14973682,\n",
            " 'Loss/total_loss': 0.5856056,\n",
            " 'learning_rate': 0.0799926}\n",
            "I0824 09:03:23.694501 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.24536054,\n",
            " 'Loss/localization_loss': 0.19050823,\n",
            " 'Loss/regularization_loss': 0.14973682,\n",
            " 'Loss/total_loss': 0.5856056,\n",
            " 'learning_rate': 0.0799926}\n",
            "INFO:tensorflow:Step 1400 per-step time 0.318s\n",
            "I0824 09:03:55.460270 139739119789952 model_lib_v2.py:707] Step 1400 per-step time 0.318s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1900246,\n",
            " 'Loss/localization_loss': 0.15985419,\n",
            " 'Loss/regularization_loss': 0.14957666,\n",
            " 'Loss/total_loss': 0.49945545,\n",
            " 'learning_rate': 0.07998685}\n",
            "I0824 09:03:55.460663 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.1900246,\n",
            " 'Loss/localization_loss': 0.15985419,\n",
            " 'Loss/regularization_loss': 0.14957666,\n",
            " 'Loss/total_loss': 0.49945545,\n",
            " 'learning_rate': 0.07998685}\n",
            "INFO:tensorflow:Step 1500 per-step time 0.318s\n",
            "I0824 09:04:27.270468 139739119789952 model_lib_v2.py:707] Step 1500 per-step time 0.318s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.17323825,\n",
            " 'Loss/localization_loss': 0.105808936,\n",
            " 'Loss/regularization_loss': 0.14941321,\n",
            " 'Loss/total_loss': 0.42846042,\n",
            " 'learning_rate': 0.07997945}\n",
            "I0824 09:04:27.270810 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.17323825,\n",
            " 'Loss/localization_loss': 0.105808936,\n",
            " 'Loss/regularization_loss': 0.14941321,\n",
            " 'Loss/total_loss': 0.42846042,\n",
            " 'learning_rate': 0.07997945}\n",
            "INFO:tensorflow:Step 1600 per-step time 0.320s\n",
            "I0824 09:04:59.237322 139739119789952 model_lib_v2.py:707] Step 1600 per-step time 0.320s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.14024831,\n",
            " 'Loss/localization_loss': 0.11851973,\n",
            " 'Loss/regularization_loss': 0.14911503,\n",
            " 'Loss/total_loss': 0.40788308,\n",
            " 'learning_rate': 0.079970405}\n",
            "I0824 09:04:59.237689 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.14024831,\n",
            " 'Loss/localization_loss': 0.11851973,\n",
            " 'Loss/regularization_loss': 0.14911503,\n",
            " 'Loss/total_loss': 0.40788308,\n",
            " 'learning_rate': 0.079970405}\n",
            "INFO:tensorflow:Step 1700 per-step time 0.321s\n",
            "I0824 09:05:31.345148 139739119789952 model_lib_v2.py:707] Step 1700 per-step time 0.321s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13939027,\n",
            " 'Loss/localization_loss': 0.12980194,\n",
            " 'Loss/regularization_loss': 0.14874049,\n",
            " 'Loss/total_loss': 0.4179327,\n",
            " 'learning_rate': 0.07995972}\n",
            "I0824 09:05:31.345459 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.13939027,\n",
            " 'Loss/localization_loss': 0.12980194,\n",
            " 'Loss/regularization_loss': 0.14874049,\n",
            " 'Loss/total_loss': 0.4179327,\n",
            " 'learning_rate': 0.07995972}\n",
            "INFO:tensorflow:Step 1800 per-step time 0.323s\n",
            "I0824 09:06:03.682471 139739119789952 model_lib_v2.py:707] Step 1800 per-step time 0.323s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.14999487,\n",
            " 'Loss/localization_loss': 0.1641069,\n",
            " 'Loss/regularization_loss': 0.14835064,\n",
            " 'Loss/total_loss': 0.4624524,\n",
            " 'learning_rate': 0.0799474}\n",
            "I0824 09:06:03.682795 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.14999487,\n",
            " 'Loss/localization_loss': 0.1641069,\n",
            " 'Loss/regularization_loss': 0.14835064,\n",
            " 'Loss/total_loss': 0.4624524,\n",
            " 'learning_rate': 0.0799474}\n",
            "INFO:tensorflow:Step 1900 per-step time 0.325s\n",
            "I0824 09:06:36.166288 139739119789952 model_lib_v2.py:707] Step 1900 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2864198,\n",
            " 'Loss/localization_loss': 0.1369579,\n",
            " 'Loss/regularization_loss': 0.14796975,\n",
            " 'Loss/total_loss': 0.5713475,\n",
            " 'learning_rate': 0.07993342}\n",
            "I0824 09:06:36.166652 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.2864198,\n",
            " 'Loss/localization_loss': 0.1369579,\n",
            " 'Loss/regularization_loss': 0.14796975,\n",
            " 'Loss/total_loss': 0.5713475,\n",
            " 'learning_rate': 0.07993342}\n",
            "INFO:tensorflow:Step 2000 per-step time 0.324s\n",
            "I0824 09:07:08.568526 139739119789952 model_lib_v2.py:707] Step 2000 per-step time 0.324s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.14484933,\n",
            " 'Loss/localization_loss': 0.13003309,\n",
            " 'Loss/regularization_loss': 0.14785393,\n",
            " 'Loss/total_loss': 0.42273635,\n",
            " 'learning_rate': 0.07991781}\n",
            "I0824 09:07:08.568840 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.14484933,\n",
            " 'Loss/localization_loss': 0.13003309,\n",
            " 'Loss/regularization_loss': 0.14785393,\n",
            " 'Loss/total_loss': 0.42273635,\n",
            " 'learning_rate': 0.07991781}\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0824 09:07:08.698834 139739119789952 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0824 09:07:08.700147 139739119789952 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0824 09:07:08.702325 139739119789952 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0824 09:07:08.703236 139739119789952 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0824 09:07:08.706618 139739119789952 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0824 09:07:08.707827 139739119789952 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0824 09:07:08.710695 139739119789952 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0824 09:07:08.711939 139739119789952 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0824 09:07:08.714772 139739119789952 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0824 09:07:08.715999 139739119789952 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Step 2100 per-step time 0.327s\n",
            "I0824 09:07:41.286617 139739119789952 model_lib_v2.py:707] Step 2100 per-step time 0.327s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13897797,\n",
            " 'Loss/localization_loss': 0.11204119,\n",
            " 'Loss/regularization_loss': 0.14752012,\n",
            " 'Loss/total_loss': 0.3985393,\n",
            " 'learning_rate': 0.07990056}\n",
            "I0824 09:07:41.286922 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.13897797,\n",
            " 'Loss/localization_loss': 0.11204119,\n",
            " 'Loss/regularization_loss': 0.14752012,\n",
            " 'Loss/total_loss': 0.3985393,\n",
            " 'learning_rate': 0.07990056}\n",
            "INFO:tensorflow:Step 2200 per-step time 0.326s\n",
            "I0824 09:08:13.863768 139739119789952 model_lib_v2.py:707] Step 2200 per-step time 0.326s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13912423,\n",
            " 'Loss/localization_loss': 0.10960203,\n",
            " 'Loss/regularization_loss': 0.14715524,\n",
            " 'Loss/total_loss': 0.39588147,\n",
            " 'learning_rate': 0.07988167}\n",
            "I0824 09:08:13.864062 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.13912423,\n",
            " 'Loss/localization_loss': 0.10960203,\n",
            " 'Loss/regularization_loss': 0.14715524,\n",
            " 'Loss/total_loss': 0.39588147,\n",
            " 'learning_rate': 0.07988167}\n",
            "INFO:tensorflow:Step 2300 per-step time 0.326s\n",
            "I0824 09:08:46.480841 139739119789952 model_lib_v2.py:707] Step 2300 per-step time 0.326s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12614158,\n",
            " 'Loss/localization_loss': 0.1225165,\n",
            " 'Loss/regularization_loss': 0.14671613,\n",
            " 'Loss/total_loss': 0.3953742,\n",
            " 'learning_rate': 0.07986114}\n",
            "I0824 09:08:46.481191 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.12614158,\n",
            " 'Loss/localization_loss': 0.1225165,\n",
            " 'Loss/regularization_loss': 0.14671613,\n",
            " 'Loss/total_loss': 0.3953742,\n",
            " 'learning_rate': 0.07986114}\n",
            "INFO:tensorflow:Step 2400 per-step time 0.324s\n",
            "I0824 09:09:18.902668 139739119789952 model_lib_v2.py:707] Step 2400 per-step time 0.324s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1554822,\n",
            " 'Loss/localization_loss': 0.1361388,\n",
            " 'Loss/regularization_loss': 0.14628597,\n",
            " 'Loss/total_loss': 0.43790698,\n",
            " 'learning_rate': 0.07983897}\n",
            "I0824 09:09:18.902970 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.1554822,\n",
            " 'Loss/localization_loss': 0.1361388,\n",
            " 'Loss/regularization_loss': 0.14628597,\n",
            " 'Loss/total_loss': 0.43790698,\n",
            " 'learning_rate': 0.07983897}\n",
            "INFO:tensorflow:Step 2500 per-step time 0.325s\n",
            "I0824 09:09:51.420044 139739119789952 model_lib_v2.py:707] Step 2500 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13825165,\n",
            " 'Loss/localization_loss': 0.099359564,\n",
            " 'Loss/regularization_loss': 0.14593229,\n",
            " 'Loss/total_loss': 0.3835435,\n",
            " 'learning_rate': 0.079815164}\n",
            "I0824 09:09:51.420337 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.13825165,\n",
            " 'Loss/localization_loss': 0.099359564,\n",
            " 'Loss/regularization_loss': 0.14593229,\n",
            " 'Loss/total_loss': 0.3835435,\n",
            " 'learning_rate': 0.079815164}\n",
            "INFO:tensorflow:Step 2600 per-step time 0.325s\n",
            "I0824 09:10:23.964224 139739119789952 model_lib_v2.py:707] Step 2600 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10535742,\n",
            " 'Loss/localization_loss': 0.07501911,\n",
            " 'Loss/regularization_loss': 0.14572082,\n",
            " 'Loss/total_loss': 0.32609737,\n",
            " 'learning_rate': 0.07978972}\n",
            "I0824 09:10:23.964574 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.10535742,\n",
            " 'Loss/localization_loss': 0.07501911,\n",
            " 'Loss/regularization_loss': 0.14572082,\n",
            " 'Loss/total_loss': 0.32609737,\n",
            " 'learning_rate': 0.07978972}\n",
            "INFO:tensorflow:Step 2700 per-step time 0.325s\n",
            "I0824 09:10:56.489363 139739119789952 model_lib_v2.py:707] Step 2700 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1070084,\n",
            " 'Loss/localization_loss': 0.07906541,\n",
            " 'Loss/regularization_loss': 0.14524376,\n",
            " 'Loss/total_loss': 0.33131757,\n",
            " 'learning_rate': 0.07976264}\n",
            "I0824 09:10:56.489740 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.1070084,\n",
            " 'Loss/localization_loss': 0.07906541,\n",
            " 'Loss/regularization_loss': 0.14524376,\n",
            " 'Loss/total_loss': 0.33131757,\n",
            " 'learning_rate': 0.07976264}\n",
            "INFO:tensorflow:Step 2800 per-step time 0.325s\n",
            "I0824 09:11:28.970629 139739119789952 model_lib_v2.py:707] Step 2800 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12823321,\n",
            " 'Loss/localization_loss': 0.0942941,\n",
            " 'Loss/regularization_loss': 0.144831,\n",
            " 'Loss/total_loss': 0.36735833,\n",
            " 'learning_rate': 0.07973392}\n",
            "I0824 09:11:28.970998 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.12823321,\n",
            " 'Loss/localization_loss': 0.0942941,\n",
            " 'Loss/regularization_loss': 0.144831,\n",
            " 'Loss/total_loss': 0.36735833,\n",
            " 'learning_rate': 0.07973392}\n",
            "INFO:tensorflow:Step 2900 per-step time 0.324s\n",
            "I0824 09:12:01.411183 139739119789952 model_lib_v2.py:707] Step 2900 per-step time 0.324s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11953657,\n",
            " 'Loss/localization_loss': 0.09719687,\n",
            " 'Loss/regularization_loss': 0.14446749,\n",
            " 'Loss/total_loss': 0.36120093,\n",
            " 'learning_rate': 0.07970358}\n",
            "I0824 09:12:01.411493 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.11953657,\n",
            " 'Loss/localization_loss': 0.09719687,\n",
            " 'Loss/regularization_loss': 0.14446749,\n",
            " 'Loss/total_loss': 0.36120093,\n",
            " 'learning_rate': 0.07970358}\n",
            "INFO:tensorflow:Step 3000 per-step time 0.325s\n",
            "I0824 09:12:33.953470 139739119789952 model_lib_v2.py:707] Step 3000 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.14865421,\n",
            " 'Loss/localization_loss': 0.09006681,\n",
            " 'Loss/regularization_loss': 0.14400533,\n",
            " 'Loss/total_loss': 0.38272634,\n",
            " 'learning_rate': 0.0796716}\n",
            "I0824 09:12:33.953900 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.14865421,\n",
            " 'Loss/localization_loss': 0.09006681,\n",
            " 'Loss/regularization_loss': 0.14400533,\n",
            " 'Loss/total_loss': 0.38272634,\n",
            " 'learning_rate': 0.0796716}\n",
            "INFO:tensorflow:Step 3100 per-step time 0.335s\n",
            "I0824 09:13:07.405196 139739119789952 model_lib_v2.py:707] Step 3100 per-step time 0.335s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12866789,\n",
            " 'Loss/localization_loss': 0.10664007,\n",
            " 'Loss/regularization_loss': 0.14358371,\n",
            " 'Loss/total_loss': 0.37889168,\n",
            " 'learning_rate': 0.07963799}\n",
            "I0824 09:13:07.405524 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.12866789,\n",
            " 'Loss/localization_loss': 0.10664007,\n",
            " 'Loss/regularization_loss': 0.14358371,\n",
            " 'Loss/total_loss': 0.37889168,\n",
            " 'learning_rate': 0.07963799}\n",
            "INFO:tensorflow:Step 3200 per-step time 0.328s\n",
            "I0824 09:13:40.194210 139739119789952 model_lib_v2.py:707] Step 3200 per-step time 0.328s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1104269,\n",
            " 'Loss/localization_loss': 0.0807001,\n",
            " 'Loss/regularization_loss': 0.14313488,\n",
            " 'Loss/total_loss': 0.3342619,\n",
            " 'learning_rate': 0.07960275}\n",
            "I0824 09:13:40.194539 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.1104269,\n",
            " 'Loss/localization_loss': 0.0807001,\n",
            " 'Loss/regularization_loss': 0.14313488,\n",
            " 'Loss/total_loss': 0.3342619,\n",
            " 'learning_rate': 0.07960275}\n",
            "INFO:tensorflow:Step 3300 per-step time 0.326s\n",
            "I0824 09:14:12.798935 139739119789952 model_lib_v2.py:707] Step 3300 per-step time 0.326s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15684895,\n",
            " 'Loss/localization_loss': 0.06345752,\n",
            " 'Loss/regularization_loss': 0.14265148,\n",
            " 'Loss/total_loss': 0.36295795,\n",
            " 'learning_rate': 0.07956588}\n",
            "I0824 09:14:12.799264 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.15684895,\n",
            " 'Loss/localization_loss': 0.06345752,\n",
            " 'Loss/regularization_loss': 0.14265148,\n",
            " 'Loss/total_loss': 0.36295795,\n",
            " 'learning_rate': 0.07956588}\n",
            "INFO:tensorflow:Step 3400 per-step time 0.327s\n",
            "I0824 09:14:45.527257 139739119789952 model_lib_v2.py:707] Step 3400 per-step time 0.327s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10969464,\n",
            " 'Loss/localization_loss': 0.078299575,\n",
            " 'Loss/regularization_loss': 0.14221771,\n",
            " 'Loss/total_loss': 0.33021194,\n",
            " 'learning_rate': 0.079527386}\n",
            "I0824 09:14:45.527597 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.10969464,\n",
            " 'Loss/localization_loss': 0.078299575,\n",
            " 'Loss/regularization_loss': 0.14221771,\n",
            " 'Loss/total_loss': 0.33021194,\n",
            " 'learning_rate': 0.079527386}\n",
            "INFO:tensorflow:Step 3500 per-step time 0.328s\n",
            "I0824 09:15:18.297823 139739119789952 model_lib_v2.py:707] Step 3500 per-step time 0.328s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12569842,\n",
            " 'Loss/localization_loss': 0.0940886,\n",
            " 'Loss/regularization_loss': 0.1417298,\n",
            " 'Loss/total_loss': 0.36151683,\n",
            " 'learning_rate': 0.07948727}\n",
            "I0824 09:15:18.298156 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.12569842,\n",
            " 'Loss/localization_loss': 0.0940886,\n",
            " 'Loss/regularization_loss': 0.1417298,\n",
            " 'Loss/total_loss': 0.36151683,\n",
            " 'learning_rate': 0.07948727}\n",
            "INFO:tensorflow:Step 3600 per-step time 0.327s\n",
            "I0824 09:15:51.024579 139739119789952 model_lib_v2.py:707] Step 3600 per-step time 0.327s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.14076741,\n",
            " 'Loss/localization_loss': 0.08188354,\n",
            " 'Loss/regularization_loss': 0.14121698,\n",
            " 'Loss/total_loss': 0.36386794,\n",
            " 'learning_rate': 0.079445526}\n",
            "I0824 09:15:51.024871 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.14076741,\n",
            " 'Loss/localization_loss': 0.08188354,\n",
            " 'Loss/regularization_loss': 0.14121698,\n",
            " 'Loss/total_loss': 0.36386794,\n",
            " 'learning_rate': 0.079445526}\n",
            "INFO:tensorflow:Step 3700 per-step time 0.326s\n",
            "I0824 09:16:23.576505 139739119789952 model_lib_v2.py:707] Step 3700 per-step time 0.326s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.099365205,\n",
            " 'Loss/localization_loss': 0.05963446,\n",
            " 'Loss/regularization_loss': 0.14068626,\n",
            " 'Loss/total_loss': 0.29968593,\n",
            " 'learning_rate': 0.07940216}\n",
            "I0824 09:16:23.576839 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.099365205,\n",
            " 'Loss/localization_loss': 0.05963446,\n",
            " 'Loss/regularization_loss': 0.14068626,\n",
            " 'Loss/total_loss': 0.29968593,\n",
            " 'learning_rate': 0.07940216}\n",
            "INFO:tensorflow:Step 3800 per-step time 0.326s\n",
            "I0824 09:16:56.193708 139739119789952 model_lib_v2.py:707] Step 3800 per-step time 0.326s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11779005,\n",
            " 'Loss/localization_loss': 0.10396213,\n",
            " 'Loss/regularization_loss': 0.14019701,\n",
            " 'Loss/total_loss': 0.3619492,\n",
            " 'learning_rate': 0.079357184}\n",
            "I0824 09:16:56.194027 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.11779005,\n",
            " 'Loss/localization_loss': 0.10396213,\n",
            " 'Loss/regularization_loss': 0.14019701,\n",
            " 'Loss/total_loss': 0.3619492,\n",
            " 'learning_rate': 0.079357184}\n",
            "INFO:tensorflow:Step 3900 per-step time 0.326s\n",
            "I0824 09:17:28.790388 139739119789952 model_lib_v2.py:707] Step 3900 per-step time 0.326s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12414209,\n",
            " 'Loss/localization_loss': 0.0895789,\n",
            " 'Loss/regularization_loss': 0.14001916,\n",
            " 'Loss/total_loss': 0.35374016,\n",
            " 'learning_rate': 0.07931058}\n",
            "I0824 09:17:28.790697 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.12414209,\n",
            " 'Loss/localization_loss': 0.0895789,\n",
            " 'Loss/regularization_loss': 0.14001916,\n",
            " 'Loss/total_loss': 0.35374016,\n",
            " 'learning_rate': 0.07931058}\n",
            "INFO:tensorflow:Step 4000 per-step time 0.326s\n",
            "I0824 09:18:01.374108 139739119789952 model_lib_v2.py:707] Step 4000 per-step time 0.326s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11136049,\n",
            " 'Loss/localization_loss': 0.08343558,\n",
            " 'Loss/regularization_loss': 0.13965447,\n",
            " 'Loss/total_loss': 0.33445054,\n",
            " 'learning_rate': 0.07926236}\n",
            "I0824 09:18:01.374406 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.11136049,\n",
            " 'Loss/localization_loss': 0.08343558,\n",
            " 'Loss/regularization_loss': 0.13965447,\n",
            " 'Loss/total_loss': 0.33445054,\n",
            " 'learning_rate': 0.07926236}\n",
            "INFO:tensorflow:Step 4100 per-step time 0.330s\n",
            "I0824 09:18:34.392857 139739119789952 model_lib_v2.py:707] Step 4100 per-step time 0.330s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11811116,\n",
            " 'Loss/localization_loss': 0.10167038,\n",
            " 'Loss/regularization_loss': 0.13911268,\n",
            " 'Loss/total_loss': 0.35889423,\n",
            " 'learning_rate': 0.07921253}\n",
            "I0824 09:18:34.393206 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.11811116,\n",
            " 'Loss/localization_loss': 0.10167038,\n",
            " 'Loss/regularization_loss': 0.13911268,\n",
            " 'Loss/total_loss': 0.35889423,\n",
            " 'learning_rate': 0.07921253}\n",
            "INFO:tensorflow:Step 4200 per-step time 0.326s\n",
            "I0824 09:19:07.007808 139739119789952 model_lib_v2.py:707] Step 4200 per-step time 0.326s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.122788325,\n",
            " 'Loss/localization_loss': 0.099940784,\n",
            " 'Loss/regularization_loss': 0.13867909,\n",
            " 'Loss/total_loss': 0.3614082,\n",
            " 'learning_rate': 0.07916109}\n",
            "I0824 09:19:07.008128 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.122788325,\n",
            " 'Loss/localization_loss': 0.099940784,\n",
            " 'Loss/regularization_loss': 0.13867909,\n",
            " 'Loss/total_loss': 0.3614082,\n",
            " 'learning_rate': 0.07916109}\n",
            "INFO:tensorflow:Step 4300 per-step time 0.323s\n",
            "I0824 09:19:39.345858 139739119789952 model_lib_v2.py:707] Step 4300 per-step time 0.323s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.115246445,\n",
            " 'Loss/localization_loss': 0.0896876,\n",
            " 'Loss/regularization_loss': 0.13820648,\n",
            " 'Loss/total_loss': 0.34314054,\n",
            " 'learning_rate': 0.07910804}\n",
            "I0824 09:19:39.346166 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.115246445,\n",
            " 'Loss/localization_loss': 0.0896876,\n",
            " 'Loss/regularization_loss': 0.13820648,\n",
            " 'Loss/total_loss': 0.34314054,\n",
            " 'learning_rate': 0.07910804}\n",
            "INFO:tensorflow:Step 4400 per-step time 0.327s\n",
            "I0824 09:20:11.997309 139739119789952 model_lib_v2.py:707] Step 4400 per-step time 0.327s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08499676,\n",
            " 'Loss/localization_loss': 0.0428721,\n",
            " 'Loss/regularization_loss': 0.13770536,\n",
            " 'Loss/total_loss': 0.26557422,\n",
            " 'learning_rate': 0.07905338}\n",
            "I0824 09:20:11.997637 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.08499676,\n",
            " 'Loss/localization_loss': 0.0428721,\n",
            " 'Loss/regularization_loss': 0.13770536,\n",
            " 'Loss/total_loss': 0.26557422,\n",
            " 'learning_rate': 0.07905338}\n",
            "INFO:tensorflow:Step 4500 per-step time 0.326s\n",
            "I0824 09:20:44.552757 139739119789952 model_lib_v2.py:707] Step 4500 per-step time 0.326s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.096877806,\n",
            " 'Loss/localization_loss': 0.06849083,\n",
            " 'Loss/regularization_loss': 0.13718218,\n",
            " 'Loss/total_loss': 0.30255082,\n",
            " 'learning_rate': 0.07899711}\n",
            "I0824 09:20:44.553084 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.096877806,\n",
            " 'Loss/localization_loss': 0.06849083,\n",
            " 'Loss/regularization_loss': 0.13718218,\n",
            " 'Loss/total_loss': 0.30255082,\n",
            " 'learning_rate': 0.07899711}\n",
            "INFO:tensorflow:Step 4600 per-step time 0.325s\n",
            "I0824 09:21:17.079941 139739119789952 model_lib_v2.py:707] Step 4600 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11147477,\n",
            " 'Loss/localization_loss': 0.09350389,\n",
            " 'Loss/regularization_loss': 0.13667662,\n",
            " 'Loss/total_loss': 0.34165528,\n",
            " 'learning_rate': 0.078939244}\n",
            "I0824 09:21:17.080245 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.11147477,\n",
            " 'Loss/localization_loss': 0.09350389,\n",
            " 'Loss/regularization_loss': 0.13667662,\n",
            " 'Loss/total_loss': 0.34165528,\n",
            " 'learning_rate': 0.078939244}\n",
            "INFO:tensorflow:Step 4700 per-step time 0.326s\n",
            "I0824 09:21:49.716778 139739119789952 model_lib_v2.py:707] Step 4700 per-step time 0.326s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10063124,\n",
            " 'Loss/localization_loss': 0.06290165,\n",
            " 'Loss/regularization_loss': 0.13623187,\n",
            " 'Loss/total_loss': 0.29976475,\n",
            " 'learning_rate': 0.07887978}\n",
            "I0824 09:21:49.717074 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.10063124,\n",
            " 'Loss/localization_loss': 0.06290165,\n",
            " 'Loss/regularization_loss': 0.13623187,\n",
            " 'Loss/total_loss': 0.29976475,\n",
            " 'learning_rate': 0.07887978}\n",
            "INFO:tensorflow:Step 4800 per-step time 0.326s\n",
            "I0824 09:22:22.307467 139739119789952 model_lib_v2.py:707] Step 4800 per-step time 0.326s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10359054,\n",
            " 'Loss/localization_loss': 0.06403619,\n",
            " 'Loss/regularization_loss': 0.13566345,\n",
            " 'Loss/total_loss': 0.3032902,\n",
            " 'learning_rate': 0.07881871}\n",
            "I0824 09:22:22.307793 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.10359054,\n",
            " 'Loss/localization_loss': 0.06403619,\n",
            " 'Loss/regularization_loss': 0.13566345,\n",
            " 'Loss/total_loss': 0.3032902,\n",
            " 'learning_rate': 0.07881871}\n",
            "INFO:tensorflow:Step 4900 per-step time 0.325s\n",
            "I0824 09:22:54.826359 139739119789952 model_lib_v2.py:707] Step 4900 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11501092,\n",
            " 'Loss/localization_loss': 0.089745395,\n",
            " 'Loss/regularization_loss': 0.13513653,\n",
            " 'Loss/total_loss': 0.33989286,\n",
            " 'learning_rate': 0.07875605}\n",
            "I0824 09:22:54.826685 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.11501092,\n",
            " 'Loss/localization_loss': 0.089745395,\n",
            " 'Loss/regularization_loss': 0.13513653,\n",
            " 'Loss/total_loss': 0.33989286,\n",
            " 'learning_rate': 0.07875605}\n",
            "INFO:tensorflow:Step 5000 per-step time 0.325s\n",
            "I0824 09:23:27.359081 139739119789952 model_lib_v2.py:707] Step 5000 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.086824335,\n",
            " 'Loss/localization_loss': 0.05008966,\n",
            " 'Loss/regularization_loss': 0.13473526,\n",
            " 'Loss/total_loss': 0.27164924,\n",
            " 'learning_rate': 0.078691795}\n",
            "I0824 09:23:27.359407 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.086824335,\n",
            " 'Loss/localization_loss': 0.05008966,\n",
            " 'Loss/regularization_loss': 0.13473526,\n",
            " 'Loss/total_loss': 0.27164924,\n",
            " 'learning_rate': 0.078691795}\n",
            "INFO:tensorflow:Step 5100 per-step time 0.331s\n",
            "I0824 09:24:00.451388 139739119789952 model_lib_v2.py:707] Step 5100 per-step time 0.331s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.121283814,\n",
            " 'Loss/localization_loss': 0.07257376,\n",
            " 'Loss/regularization_loss': 0.13436207,\n",
            " 'Loss/total_loss': 0.32821965,\n",
            " 'learning_rate': 0.07862595}\n",
            "I0824 09:24:00.451728 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.121283814,\n",
            " 'Loss/localization_loss': 0.07257376,\n",
            " 'Loss/regularization_loss': 0.13436207,\n",
            " 'Loss/total_loss': 0.32821965,\n",
            " 'learning_rate': 0.07862595}\n",
            "INFO:tensorflow:Step 5200 per-step time 0.327s\n",
            "I0824 09:24:33.150262 139739119789952 model_lib_v2.py:707] Step 5200 per-step time 0.327s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09269685,\n",
            " 'Loss/localization_loss': 0.0661499,\n",
            " 'Loss/regularization_loss': 0.13392255,\n",
            " 'Loss/total_loss': 0.2927693,\n",
            " 'learning_rate': 0.07855851}\n",
            "I0824 09:24:33.150635 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.09269685,\n",
            " 'Loss/localization_loss': 0.0661499,\n",
            " 'Loss/regularization_loss': 0.13392255,\n",
            " 'Loss/total_loss': 0.2927693,\n",
            " 'learning_rate': 0.07855851}\n",
            "INFO:tensorflow:Step 5300 per-step time 0.325s\n",
            "I0824 09:25:05.662473 139739119789952 model_lib_v2.py:707] Step 5300 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.122085884,\n",
            " 'Loss/localization_loss': 0.079488225,\n",
            " 'Loss/regularization_loss': 0.13362794,\n",
            " 'Loss/total_loss': 0.33520204,\n",
            " 'learning_rate': 0.07848949}\n",
            "I0824 09:25:05.662821 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.122085884,\n",
            " 'Loss/localization_loss': 0.079488225,\n",
            " 'Loss/regularization_loss': 0.13362794,\n",
            " 'Loss/total_loss': 0.33520204,\n",
            " 'learning_rate': 0.07848949}\n",
            "INFO:tensorflow:Step 5400 per-step time 0.326s\n",
            "I0824 09:25:38.290307 139739119789952 model_lib_v2.py:707] Step 5400 per-step time 0.326s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11095081,\n",
            " 'Loss/localization_loss': 0.07534547,\n",
            " 'Loss/regularization_loss': 0.13326867,\n",
            " 'Loss/total_loss': 0.31956494,\n",
            " 'learning_rate': 0.078418896}\n",
            "I0824 09:25:38.290606 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.11095081,\n",
            " 'Loss/localization_loss': 0.07534547,\n",
            " 'Loss/regularization_loss': 0.13326867,\n",
            " 'Loss/total_loss': 0.31956494,\n",
            " 'learning_rate': 0.078418896}\n",
            "INFO:tensorflow:Step 5500 per-step time 0.325s\n",
            "I0824 09:26:10.773330 139739119789952 model_lib_v2.py:707] Step 5500 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.094014235,\n",
            " 'Loss/localization_loss': 0.0557162,\n",
            " 'Loss/regularization_loss': 0.13280497,\n",
            " 'Loss/total_loss': 0.28253543,\n",
            " 'learning_rate': 0.078346714}\n",
            "I0824 09:26:10.773646 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.094014235,\n",
            " 'Loss/localization_loss': 0.0557162,\n",
            " 'Loss/regularization_loss': 0.13280497,\n",
            " 'Loss/total_loss': 0.28253543,\n",
            " 'learning_rate': 0.078346714}\n",
            "INFO:tensorflow:Step 5600 per-step time 0.325s\n",
            "I0824 09:26:43.225586 139739119789952 model_lib_v2.py:707] Step 5600 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09736352,\n",
            " 'Loss/localization_loss': 0.07532364,\n",
            " 'Loss/regularization_loss': 0.13242081,\n",
            " 'Loss/total_loss': 0.30510795,\n",
            " 'learning_rate': 0.07827295}\n",
            "I0824 09:26:43.225915 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.09736352,\n",
            " 'Loss/localization_loss': 0.07532364,\n",
            " 'Loss/regularization_loss': 0.13242081,\n",
            " 'Loss/total_loss': 0.30510795,\n",
            " 'learning_rate': 0.07827295}\n",
            "INFO:tensorflow:Step 5700 per-step time 0.323s\n",
            "I0824 09:27:15.553826 139739119789952 model_lib_v2.py:707] Step 5700 per-step time 0.323s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15224718,\n",
            " 'Loss/localization_loss': 0.09225303,\n",
            " 'Loss/regularization_loss': 0.13198407,\n",
            " 'Loss/total_loss': 0.37648427,\n",
            " 'learning_rate': 0.07819763}\n",
            "I0824 09:27:15.554152 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.15224718,\n",
            " 'Loss/localization_loss': 0.09225303,\n",
            " 'Loss/regularization_loss': 0.13198407,\n",
            " 'Loss/total_loss': 0.37648427,\n",
            " 'learning_rate': 0.07819763}\n",
            "INFO:tensorflow:Step 5800 per-step time 0.324s\n",
            "I0824 09:27:47.988030 139739119789952 model_lib_v2.py:707] Step 5800 per-step time 0.324s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.089936465,\n",
            " 'Loss/localization_loss': 0.063180946,\n",
            " 'Loss/regularization_loss': 0.13144524,\n",
            " 'Loss/total_loss': 0.28456265,\n",
            " 'learning_rate': 0.07812072}\n",
            "I0824 09:27:47.988324 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.089936465,\n",
            " 'Loss/localization_loss': 0.063180946,\n",
            " 'Loss/regularization_loss': 0.13144524,\n",
            " 'Loss/total_loss': 0.28456265,\n",
            " 'learning_rate': 0.07812072}\n",
            "INFO:tensorflow:Step 5900 per-step time 0.326s\n",
            "I0824 09:28:20.606385 139739119789952 model_lib_v2.py:707] Step 5900 per-step time 0.326s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09460589,\n",
            " 'Loss/localization_loss': 0.053041484,\n",
            " 'Loss/regularization_loss': 0.13099936,\n",
            " 'Loss/total_loss': 0.27864674,\n",
            " 'learning_rate': 0.078042254}\n",
            "I0824 09:28:20.606711 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.09460589,\n",
            " 'Loss/localization_loss': 0.053041484,\n",
            " 'Loss/regularization_loss': 0.13099936,\n",
            " 'Loss/total_loss': 0.27864674,\n",
            " 'learning_rate': 0.078042254}\n",
            "INFO:tensorflow:Step 6000 per-step time 0.327s\n",
            "I0824 09:28:53.280178 139739119789952 model_lib_v2.py:707] Step 6000 per-step time 0.327s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09645673,\n",
            " 'Loss/localization_loss': 0.055885863,\n",
            " 'Loss/regularization_loss': 0.13053721,\n",
            " 'Loss/total_loss': 0.2828798,\n",
            " 'learning_rate': 0.07796223}\n",
            "I0824 09:28:53.280503 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.09645673,\n",
            " 'Loss/localization_loss': 0.055885863,\n",
            " 'Loss/regularization_loss': 0.13053721,\n",
            " 'Loss/total_loss': 0.2828798,\n",
            " 'learning_rate': 0.07796223}\n",
            "INFO:tensorflow:Step 6100 per-step time 0.326s\n",
            "I0824 09:29:25.928249 139739119789952 model_lib_v2.py:707] Step 6100 per-step time 0.326s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0898222,\n",
            " 'Loss/localization_loss': 0.06263161,\n",
            " 'Loss/regularization_loss': 0.1300422,\n",
            " 'Loss/total_loss': 0.282496,\n",
            " 'learning_rate': 0.077880636}\n",
            "I0824 09:29:25.928568 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.0898222,\n",
            " 'Loss/localization_loss': 0.06263161,\n",
            " 'Loss/regularization_loss': 0.1300422,\n",
            " 'Loss/total_loss': 0.282496,\n",
            " 'learning_rate': 0.077880636}\n",
            "INFO:tensorflow:Step 6200 per-step time 0.325s\n",
            "I0824 09:29:58.420909 139739119789952 model_lib_v2.py:707] Step 6200 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.14751208,\n",
            " 'Loss/localization_loss': 0.061734237,\n",
            " 'Loss/regularization_loss': 0.12962905,\n",
            " 'Loss/total_loss': 0.33887535,\n",
            " 'learning_rate': 0.07779749}\n",
            "I0824 09:29:58.421218 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.14751208,\n",
            " 'Loss/localization_loss': 0.061734237,\n",
            " 'Loss/regularization_loss': 0.12962905,\n",
            " 'Loss/total_loss': 0.33887535,\n",
            " 'learning_rate': 0.07779749}\n",
            "INFO:tensorflow:Step 6300 per-step time 0.326s\n",
            "I0824 09:30:31.036850 139739119789952 model_lib_v2.py:707] Step 6300 per-step time 0.326s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.078123845,\n",
            " 'Loss/localization_loss': 0.054854084,\n",
            " 'Loss/regularization_loss': 0.12908734,\n",
            " 'Loss/total_loss': 0.2620653,\n",
            " 'learning_rate': 0.07771279}\n",
            "I0824 09:30:31.037179 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.078123845,\n",
            " 'Loss/localization_loss': 0.054854084,\n",
            " 'Loss/regularization_loss': 0.12908734,\n",
            " 'Loss/total_loss': 0.2620653,\n",
            " 'learning_rate': 0.07771279}\n",
            "INFO:tensorflow:Step 6400 per-step time 0.325s\n",
            "I0824 09:31:03.571551 139739119789952 model_lib_v2.py:707] Step 6400 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08319616,\n",
            " 'Loss/localization_loss': 0.05034426,\n",
            " 'Loss/regularization_loss': 0.1286829,\n",
            " 'Loss/total_loss': 0.2622233,\n",
            " 'learning_rate': 0.077626534}\n",
            "I0824 09:31:03.571862 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.08319616,\n",
            " 'Loss/localization_loss': 0.05034426,\n",
            " 'Loss/regularization_loss': 0.1286829,\n",
            " 'Loss/total_loss': 0.2622233,\n",
            " 'learning_rate': 0.077626534}\n",
            "INFO:tensorflow:Step 6500 per-step time 0.325s\n",
            "I0824 09:31:36.064073 139739119789952 model_lib_v2.py:707] Step 6500 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.113086954,\n",
            " 'Loss/localization_loss': 0.073106065,\n",
            " 'Loss/regularization_loss': 0.12818922,\n",
            " 'Loss/total_loss': 0.31438226,\n",
            " 'learning_rate': 0.077538736}\n",
            "I0824 09:31:36.064364 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.113086954,\n",
            " 'Loss/localization_loss': 0.073106065,\n",
            " 'Loss/regularization_loss': 0.12818922,\n",
            " 'Loss/total_loss': 0.31438226,\n",
            " 'learning_rate': 0.077538736}\n",
            "INFO:tensorflow:Step 6600 per-step time 0.325s\n",
            "I0824 09:32:08.608182 139739119789952 model_lib_v2.py:707] Step 6600 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09738231,\n",
            " 'Loss/localization_loss': 0.07139468,\n",
            " 'Loss/regularization_loss': 0.12784427,\n",
            " 'Loss/total_loss': 0.29662126,\n",
            " 'learning_rate': 0.077449396}\n",
            "I0824 09:32:08.608478 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.09738231,\n",
            " 'Loss/localization_loss': 0.07139468,\n",
            " 'Loss/regularization_loss': 0.12784427,\n",
            " 'Loss/total_loss': 0.29662126,\n",
            " 'learning_rate': 0.077449396}\n",
            "INFO:tensorflow:Step 6700 per-step time 0.325s\n",
            "I0824 09:32:41.090781 139739119789952 model_lib_v2.py:707] Step 6700 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10024189,\n",
            " 'Loss/localization_loss': 0.081405714,\n",
            " 'Loss/regularization_loss': 0.12740564,\n",
            " 'Loss/total_loss': 0.30905324,\n",
            " 'learning_rate': 0.077358514}\n",
            "I0824 09:32:41.091104 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.10024189,\n",
            " 'Loss/localization_loss': 0.081405714,\n",
            " 'Loss/regularization_loss': 0.12740564,\n",
            " 'Loss/total_loss': 0.30905324,\n",
            " 'learning_rate': 0.077358514}\n",
            "INFO:tensorflow:Step 6800 per-step time 0.325s\n",
            "I0824 09:33:13.621846 139739119789952 model_lib_v2.py:707] Step 6800 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.107961535,\n",
            " 'Loss/localization_loss': 0.082382016,\n",
            " 'Loss/regularization_loss': 0.12703556,\n",
            " 'Loss/total_loss': 0.31737912,\n",
            " 'learning_rate': 0.0772661}\n",
            "I0824 09:33:13.622191 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.107961535,\n",
            " 'Loss/localization_loss': 0.082382016,\n",
            " 'Loss/regularization_loss': 0.12703556,\n",
            " 'Loss/total_loss': 0.31737912,\n",
            " 'learning_rate': 0.0772661}\n",
            "INFO:tensorflow:Step 6900 per-step time 0.325s\n",
            "I0824 09:33:46.116410 139739119789952 model_lib_v2.py:707] Step 6900 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.087582126,\n",
            " 'Loss/localization_loss': 0.06891596,\n",
            " 'Loss/regularization_loss': 0.12663507,\n",
            " 'Loss/total_loss': 0.28313315,\n",
            " 'learning_rate': 0.077172145}\n",
            "I0824 09:33:46.116715 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.087582126,\n",
            " 'Loss/localization_loss': 0.06891596,\n",
            " 'Loss/regularization_loss': 0.12663507,\n",
            " 'Loss/total_loss': 0.28313315,\n",
            " 'learning_rate': 0.077172145}\n",
            "INFO:tensorflow:Step 7000 per-step time 0.326s\n",
            "I0824 09:34:18.741271 139739119789952 model_lib_v2.py:707] Step 7000 per-step time 0.326s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1419237,\n",
            " 'Loss/localization_loss': 0.09041498,\n",
            " 'Loss/regularization_loss': 0.12618153,\n",
            " 'Loss/total_loss': 0.3585202,\n",
            " 'learning_rate': 0.07707667}\n",
            "I0824 09:34:18.741585 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.1419237,\n",
            " 'Loss/localization_loss': 0.09041498,\n",
            " 'Loss/regularization_loss': 0.12618153,\n",
            " 'Loss/total_loss': 0.3585202,\n",
            " 'learning_rate': 0.07707667}\n",
            "INFO:tensorflow:Step 7100 per-step time 0.328s\n",
            "I0824 09:34:51.496666 139739119789952 model_lib_v2.py:707] Step 7100 per-step time 0.328s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12125324,\n",
            " 'Loss/localization_loss': 0.068368904,\n",
            " 'Loss/regularization_loss': 0.1256749,\n",
            " 'Loss/total_loss': 0.31529704,\n",
            " 'learning_rate': 0.07697967}\n",
            "I0824 09:34:51.496995 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.12125324,\n",
            " 'Loss/localization_loss': 0.068368904,\n",
            " 'Loss/regularization_loss': 0.1256749,\n",
            " 'Loss/total_loss': 0.31529704,\n",
            " 'learning_rate': 0.07697967}\n",
            "INFO:tensorflow:Step 7200 per-step time 0.324s\n",
            "I0824 09:35:23.919674 139739119789952 model_lib_v2.py:707] Step 7200 per-step time 0.324s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07854379,\n",
            " 'Loss/localization_loss': 0.05450062,\n",
            " 'Loss/regularization_loss': 0.12516475,\n",
            " 'Loss/total_loss': 0.25820917,\n",
            " 'learning_rate': 0.07688115}\n",
            "I0824 09:35:23.919963 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.07854379,\n",
            " 'Loss/localization_loss': 0.05450062,\n",
            " 'Loss/regularization_loss': 0.12516475,\n",
            " 'Loss/total_loss': 0.25820917,\n",
            " 'learning_rate': 0.07688115}\n",
            "INFO:tensorflow:Step 7300 per-step time 0.325s\n",
            "I0824 09:35:56.464722 139739119789952 model_lib_v2.py:707] Step 7300 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07863636,\n",
            " 'Loss/localization_loss': 0.04619785,\n",
            " 'Loss/regularization_loss': 0.12471655,\n",
            " 'Loss/total_loss': 0.24955076,\n",
            " 'learning_rate': 0.07678111}\n",
            "I0824 09:35:56.465083 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.07863636,\n",
            " 'Loss/localization_loss': 0.04619785,\n",
            " 'Loss/regularization_loss': 0.12471655,\n",
            " 'Loss/total_loss': 0.24955076,\n",
            " 'learning_rate': 0.07678111}\n",
            "INFO:tensorflow:Step 7400 per-step time 0.328s\n",
            "I0824 09:36:29.221988 139739119789952 model_lib_v2.py:707] Step 7400 per-step time 0.328s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1082321,\n",
            " 'Loss/localization_loss': 0.061630484,\n",
            " 'Loss/regularization_loss': 0.12428878,\n",
            " 'Loss/total_loss': 0.29415137,\n",
            " 'learning_rate': 0.076679565}\n",
            "I0824 09:36:29.222308 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.1082321,\n",
            " 'Loss/localization_loss': 0.061630484,\n",
            " 'Loss/regularization_loss': 0.12428878,\n",
            " 'Loss/total_loss': 0.29415137,\n",
            " 'learning_rate': 0.076679565}\n",
            "INFO:tensorflow:Step 7500 per-step time 0.325s\n",
            "I0824 09:37:01.676236 139739119789952 model_lib_v2.py:707] Step 7500 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12010402,\n",
            " 'Loss/localization_loss': 0.06831313,\n",
            " 'Loss/regularization_loss': 0.12388995,\n",
            " 'Loss/total_loss': 0.31230712,\n",
            " 'learning_rate': 0.0765765}\n",
            "I0824 09:37:01.676557 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.12010402,\n",
            " 'Loss/localization_loss': 0.06831313,\n",
            " 'Loss/regularization_loss': 0.12388995,\n",
            " 'Loss/total_loss': 0.31230712,\n",
            " 'learning_rate': 0.0765765}\n",
            "INFO:tensorflow:Step 7600 per-step time 0.326s\n",
            "I0824 09:37:34.281147 139739119789952 model_lib_v2.py:707] Step 7600 per-step time 0.326s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.070855595,\n",
            " 'Loss/localization_loss': 0.03945093,\n",
            " 'Loss/regularization_loss': 0.12347766,\n",
            " 'Loss/total_loss': 0.23378418,\n",
            " 'learning_rate': 0.07647194}\n",
            "I0824 09:37:34.281505 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.070855595,\n",
            " 'Loss/localization_loss': 0.03945093,\n",
            " 'Loss/regularization_loss': 0.12347766,\n",
            " 'Loss/total_loss': 0.23378418,\n",
            " 'learning_rate': 0.07647194}\n",
            "INFO:tensorflow:Step 7700 per-step time 0.328s\n",
            "I0824 09:38:07.085535 139739119789952 model_lib_v2.py:707] Step 7700 per-step time 0.328s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.084580235,\n",
            " 'Loss/localization_loss': 0.05449622,\n",
            " 'Loss/regularization_loss': 0.123041116,\n",
            " 'Loss/total_loss': 0.26211756,\n",
            " 'learning_rate': 0.07636588}\n",
            "I0824 09:38:07.085839 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.084580235,\n",
            " 'Loss/localization_loss': 0.05449622,\n",
            " 'Loss/regularization_loss': 0.123041116,\n",
            " 'Loss/total_loss': 0.26211756,\n",
            " 'learning_rate': 0.07636588}\n",
            "INFO:tensorflow:Step 7800 per-step time 0.324s\n",
            "I0824 09:38:39.532711 139739119789952 model_lib_v2.py:707] Step 7800 per-step time 0.324s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07868569,\n",
            " 'Loss/localization_loss': 0.04523649,\n",
            " 'Loss/regularization_loss': 0.12254044,\n",
            " 'Loss/total_loss': 0.24646261,\n",
            " 'learning_rate': 0.07625833}\n",
            "I0824 09:38:39.533046 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.07868569,\n",
            " 'Loss/localization_loss': 0.04523649,\n",
            " 'Loss/regularization_loss': 0.12254044,\n",
            " 'Loss/total_loss': 0.24646261,\n",
            " 'learning_rate': 0.07625833}\n",
            "INFO:tensorflow:Step 7900 per-step time 0.326s\n",
            "I0824 09:39:12.126660 139739119789952 model_lib_v2.py:707] Step 7900 per-step time 0.326s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07876001,\n",
            " 'Loss/localization_loss': 0.04967347,\n",
            " 'Loss/regularization_loss': 0.12206472,\n",
            " 'Loss/total_loss': 0.2504982,\n",
            " 'learning_rate': 0.07614928}\n",
            "I0824 09:39:12.127010 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.07876001,\n",
            " 'Loss/localization_loss': 0.04967347,\n",
            " 'Loss/regularization_loss': 0.12206472,\n",
            " 'Loss/total_loss': 0.2504982,\n",
            " 'learning_rate': 0.07614928}\n",
            "INFO:tensorflow:Step 8000 per-step time 0.323s\n",
            "I0824 09:39:44.456451 139739119789952 model_lib_v2.py:707] Step 8000 per-step time 0.323s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08716969,\n",
            " 'Loss/localization_loss': 0.045108356,\n",
            " 'Loss/regularization_loss': 0.1215779,\n",
            " 'Loss/total_loss': 0.25385594,\n",
            " 'learning_rate': 0.07603875}\n",
            "I0824 09:39:44.456748 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.08716969,\n",
            " 'Loss/localization_loss': 0.045108356,\n",
            " 'Loss/regularization_loss': 0.1215779,\n",
            " 'Loss/total_loss': 0.25385594,\n",
            " 'learning_rate': 0.07603875}\n",
            "INFO:tensorflow:Step 8100 per-step time 0.330s\n",
            "I0824 09:40:17.485870 139739119789952 model_lib_v2.py:707] Step 8100 per-step time 0.330s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15319282,\n",
            " 'Loss/localization_loss': 0.069265276,\n",
            " 'Loss/regularization_loss': 0.12109904,\n",
            " 'Loss/total_loss': 0.34355712,\n",
            " 'learning_rate': 0.07592674}\n",
            "I0824 09:40:17.486176 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.15319282,\n",
            " 'Loss/localization_loss': 0.069265276,\n",
            " 'Loss/regularization_loss': 0.12109904,\n",
            " 'Loss/total_loss': 0.34355712,\n",
            " 'learning_rate': 0.07592674}\n",
            "INFO:tensorflow:Step 8200 per-step time 0.324s\n",
            "I0824 09:40:49.923378 139739119789952 model_lib_v2.py:707] Step 8200 per-step time 0.324s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08986075,\n",
            " 'Loss/localization_loss': 0.062226724,\n",
            " 'Loss/regularization_loss': 0.120759256,\n",
            " 'Loss/total_loss': 0.27284673,\n",
            " 'learning_rate': 0.075813256}\n",
            "I0824 09:40:49.923709 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.08986075,\n",
            " 'Loss/localization_loss': 0.062226724,\n",
            " 'Loss/regularization_loss': 0.120759256,\n",
            " 'Loss/total_loss': 0.27284673,\n",
            " 'learning_rate': 0.075813256}\n",
            "INFO:tensorflow:Step 8300 per-step time 0.326s\n",
            "I0824 09:41:22.501905 139739119789952 model_lib_v2.py:707] Step 8300 per-step time 0.326s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.090488985,\n",
            " 'Loss/localization_loss': 0.06822429,\n",
            " 'Loss/regularization_loss': 0.12033502,\n",
            " 'Loss/total_loss': 0.2790483,\n",
            " 'learning_rate': 0.07569829}\n",
            "I0824 09:41:22.502214 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.090488985,\n",
            " 'Loss/localization_loss': 0.06822429,\n",
            " 'Loss/regularization_loss': 0.12033502,\n",
            " 'Loss/total_loss': 0.2790483,\n",
            " 'learning_rate': 0.07569829}\n",
            "INFO:tensorflow:Step 8400 per-step time 0.327s\n",
            "I0824 09:41:55.169808 139739119789952 model_lib_v2.py:707] Step 8400 per-step time 0.327s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07690415,\n",
            " 'Loss/localization_loss': 0.050544612,\n",
            " 'Loss/regularization_loss': 0.11985723,\n",
            " 'Loss/total_loss': 0.24730599,\n",
            " 'learning_rate': 0.07558186}\n",
            "I0824 09:41:55.170120 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.07690415,\n",
            " 'Loss/localization_loss': 0.050544612,\n",
            " 'Loss/regularization_loss': 0.11985723,\n",
            " 'Loss/total_loss': 0.24730599,\n",
            " 'learning_rate': 0.07558186}\n",
            "INFO:tensorflow:Step 8500 per-step time 0.324s\n",
            "I0824 09:42:27.586024 139739119789952 model_lib_v2.py:707] Step 8500 per-step time 0.324s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.089263625,\n",
            " 'Loss/localization_loss': 0.06858476,\n",
            " 'Loss/regularization_loss': 0.11937379,\n",
            " 'Loss/total_loss': 0.2772222,\n",
            " 'learning_rate': 0.07546397}\n",
            "I0824 09:42:27.586338 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.089263625,\n",
            " 'Loss/localization_loss': 0.06858476,\n",
            " 'Loss/regularization_loss': 0.11937379,\n",
            " 'Loss/total_loss': 0.2772222,\n",
            " 'learning_rate': 0.07546397}\n",
            "INFO:tensorflow:Step 8600 per-step time 0.325s\n",
            "I0824 09:43:00.112062 139739119789952 model_lib_v2.py:707] Step 8600 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.14675619,\n",
            " 'Loss/localization_loss': 0.07233294,\n",
            " 'Loss/regularization_loss': 0.118947096,\n",
            " 'Loss/total_loss': 0.3380362,\n",
            " 'learning_rate': 0.075344615}\n",
            "I0824 09:43:00.112402 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.14675619,\n",
            " 'Loss/localization_loss': 0.07233294,\n",
            " 'Loss/regularization_loss': 0.118947096,\n",
            " 'Loss/total_loss': 0.3380362,\n",
            " 'learning_rate': 0.075344615}\n",
            "INFO:tensorflow:Step 8700 per-step time 0.324s\n",
            "I0824 09:43:32.562359 139739119789952 model_lib_v2.py:707] Step 8700 per-step time 0.324s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09447295,\n",
            " 'Loss/localization_loss': 0.058611017,\n",
            " 'Loss/regularization_loss': 0.1185671,\n",
            " 'Loss/total_loss': 0.27165106,\n",
            " 'learning_rate': 0.07522382}\n",
            "I0824 09:43:32.562665 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.09447295,\n",
            " 'Loss/localization_loss': 0.058611017,\n",
            " 'Loss/regularization_loss': 0.1185671,\n",
            " 'Loss/total_loss': 0.27165106,\n",
            " 'learning_rate': 0.07522382}\n",
            "INFO:tensorflow:Step 8800 per-step time 0.325s\n",
            "I0824 09:44:05.105379 139739119789952 model_lib_v2.py:707] Step 8800 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07332906,\n",
            " 'Loss/localization_loss': 0.0494868,\n",
            " 'Loss/regularization_loss': 0.11815008,\n",
            " 'Loss/total_loss': 0.24096593,\n",
            " 'learning_rate': 0.07510157}\n",
            "I0824 09:44:05.105687 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.07332906,\n",
            " 'Loss/localization_loss': 0.0494868,\n",
            " 'Loss/regularization_loss': 0.11815008,\n",
            " 'Loss/total_loss': 0.24096593,\n",
            " 'learning_rate': 0.07510157}\n",
            "INFO:tensorflow:Step 8900 per-step time 0.327s\n",
            "I0824 09:44:37.839447 139739119789952 model_lib_v2.py:707] Step 8900 per-step time 0.327s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07532967,\n",
            " 'Loss/localization_loss': 0.041414995,\n",
            " 'Loss/regularization_loss': 0.1177679,\n",
            " 'Loss/total_loss': 0.23451257,\n",
            " 'learning_rate': 0.074977875}\n",
            "I0824 09:44:37.839778 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.07532967,\n",
            " 'Loss/localization_loss': 0.041414995,\n",
            " 'Loss/regularization_loss': 0.1177679,\n",
            " 'Loss/total_loss': 0.23451257,\n",
            " 'learning_rate': 0.074977875}\n",
            "INFO:tensorflow:Step 9000 per-step time 0.326s\n",
            "I0824 09:45:10.433533 139739119789952 model_lib_v2.py:707] Step 9000 per-step time 0.326s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09549819,\n",
            " 'Loss/localization_loss': 0.053617798,\n",
            " 'Loss/regularization_loss': 0.11729582,\n",
            " 'Loss/total_loss': 0.26641178,\n",
            " 'learning_rate': 0.07485275}\n",
            "I0824 09:45:10.433840 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.09549819,\n",
            " 'Loss/localization_loss': 0.053617798,\n",
            " 'Loss/regularization_loss': 0.11729582,\n",
            " 'Loss/total_loss': 0.26641178,\n",
            " 'learning_rate': 0.07485275}\n",
            "INFO:tensorflow:Step 9100 per-step time 0.334s\n",
            "I0824 09:45:43.852436 139739119789952 model_lib_v2.py:707] Step 9100 per-step time 0.334s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.20030983,\n",
            " 'Loss/localization_loss': 0.13205037,\n",
            " 'Loss/regularization_loss': 0.11690673,\n",
            " 'Loss/total_loss': 0.44926694,\n",
            " 'learning_rate': 0.07472619}\n",
            "I0824 09:45:43.852743 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.20030983,\n",
            " 'Loss/localization_loss': 0.13205037,\n",
            " 'Loss/regularization_loss': 0.11690673,\n",
            " 'Loss/total_loss': 0.44926694,\n",
            " 'learning_rate': 0.07472619}\n",
            "INFO:tensorflow:Step 9200 per-step time 0.327s\n",
            "I0824 09:46:16.535683 139739119789952 model_lib_v2.py:707] Step 9200 per-step time 0.327s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.101349,\n",
            " 'Loss/localization_loss': 0.0587944,\n",
            " 'Loss/regularization_loss': 0.11655374,\n",
            " 'Loss/total_loss': 0.27669716,\n",
            " 'learning_rate': 0.07459819}\n",
            "I0824 09:46:16.536030 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.101349,\n",
            " 'Loss/localization_loss': 0.0587944,\n",
            " 'Loss/regularization_loss': 0.11655374,\n",
            " 'Loss/total_loss': 0.27669716,\n",
            " 'learning_rate': 0.07459819}\n",
            "INFO:tensorflow:Step 9300 per-step time 0.328s\n",
            "I0824 09:46:49.326457 139739119789952 model_lib_v2.py:707] Step 9300 per-step time 0.328s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.089035556,\n",
            " 'Loss/localization_loss': 0.03967384,\n",
            " 'Loss/regularization_loss': 0.116193675,\n",
            " 'Loss/total_loss': 0.24490306,\n",
            " 'learning_rate': 0.074468784}\n",
            "I0824 09:46:49.326802 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.089035556,\n",
            " 'Loss/localization_loss': 0.03967384,\n",
            " 'Loss/regularization_loss': 0.116193675,\n",
            " 'Loss/total_loss': 0.24490306,\n",
            " 'learning_rate': 0.074468784}\n",
            "INFO:tensorflow:Step 9400 per-step time 0.327s\n",
            "I0824 09:47:22.050228 139739119789952 model_lib_v2.py:707] Step 9400 per-step time 0.327s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06791843,\n",
            " 'Loss/localization_loss': 0.033154394,\n",
            " 'Loss/regularization_loss': 0.115772516,\n",
            " 'Loss/total_loss': 0.21684533,\n",
            " 'learning_rate': 0.074337944}\n",
            "I0824 09:47:22.050578 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.06791843,\n",
            " 'Loss/localization_loss': 0.033154394,\n",
            " 'Loss/regularization_loss': 0.115772516,\n",
            " 'Loss/total_loss': 0.21684533,\n",
            " 'learning_rate': 0.074337944}\n",
            "INFO:tensorflow:Step 9500 per-step time 0.327s\n",
            "I0824 09:47:54.710349 139739119789952 model_lib_v2.py:707] Step 9500 per-step time 0.327s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06914304,\n",
            " 'Loss/localization_loss': 0.034513664,\n",
            " 'Loss/regularization_loss': 0.115381956,\n",
            " 'Loss/total_loss': 0.21903867,\n",
            " 'learning_rate': 0.074205704}\n",
            "I0824 09:47:54.710821 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.06914304,\n",
            " 'Loss/localization_loss': 0.034513664,\n",
            " 'Loss/regularization_loss': 0.115381956,\n",
            " 'Loss/total_loss': 0.21903867,\n",
            " 'learning_rate': 0.074205704}\n",
            "INFO:tensorflow:Step 9600 per-step time 0.323s\n",
            "I0824 09:48:27.054067 139739119789952 model_lib_v2.py:707] Step 9600 per-step time 0.323s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07082718,\n",
            " 'Loss/localization_loss': 0.038600292,\n",
            " 'Loss/regularization_loss': 0.11499222,\n",
            " 'Loss/total_loss': 0.22441968,\n",
            " 'learning_rate': 0.07407206}\n",
            "I0824 09:48:27.054396 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.07082718,\n",
            " 'Loss/localization_loss': 0.038600292,\n",
            " 'Loss/regularization_loss': 0.11499222,\n",
            " 'Loss/total_loss': 0.22441968,\n",
            " 'learning_rate': 0.07407206}\n",
            "INFO:tensorflow:Step 9700 per-step time 0.324s\n",
            "I0824 09:48:59.441193 139739119789952 model_lib_v2.py:707] Step 9700 per-step time 0.324s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07596112,\n",
            " 'Loss/localization_loss': 0.04762329,\n",
            " 'Loss/regularization_loss': 0.11454575,\n",
            " 'Loss/total_loss': 0.23813015,\n",
            " 'learning_rate': 0.073937014}\n",
            "I0824 09:48:59.441509 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.07596112,\n",
            " 'Loss/localization_loss': 0.04762329,\n",
            " 'Loss/regularization_loss': 0.11454575,\n",
            " 'Loss/total_loss': 0.23813015,\n",
            " 'learning_rate': 0.073937014}\n",
            "INFO:tensorflow:Step 9800 per-step time 0.327s\n",
            "I0824 09:49:32.097887 139739119789952 model_lib_v2.py:707] Step 9800 per-step time 0.327s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10586661,\n",
            " 'Loss/localization_loss': 0.049602557,\n",
            " 'Loss/regularization_loss': 0.11412498,\n",
            " 'Loss/total_loss': 0.26959413,\n",
            " 'learning_rate': 0.07380057}\n",
            "I0824 09:49:32.098227 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.10586661,\n",
            " 'Loss/localization_loss': 0.049602557,\n",
            " 'Loss/regularization_loss': 0.11412498,\n",
            " 'Loss/total_loss': 0.26959413,\n",
            " 'learning_rate': 0.07380057}\n",
            "INFO:tensorflow:Step 9900 per-step time 0.328s\n",
            "I0824 09:50:04.871130 139739119789952 model_lib_v2.py:707] Step 9900 per-step time 0.328s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12591742,\n",
            " 'Loss/localization_loss': 0.06423758,\n",
            " 'Loss/regularization_loss': 0.113702245,\n",
            " 'Loss/total_loss': 0.30385724,\n",
            " 'learning_rate': 0.073662736}\n",
            "I0824 09:50:04.871424 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.12591742,\n",
            " 'Loss/localization_loss': 0.06423758,\n",
            " 'Loss/regularization_loss': 0.113702245,\n",
            " 'Loss/total_loss': 0.30385724,\n",
            " 'learning_rate': 0.073662736}\n",
            "INFO:tensorflow:Step 10000 per-step time 0.326s\n",
            "I0824 09:50:37.493156 139739119789952 model_lib_v2.py:707] Step 10000 per-step time 0.326s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.099985674,\n",
            " 'Loss/localization_loss': 0.05767369,\n",
            " 'Loss/regularization_loss': 0.11329388,\n",
            " 'Loss/total_loss': 0.27095324,\n",
            " 'learning_rate': 0.07352352}\n",
            "I0824 09:50:37.493492 139739119789952 model_lib_v2.py:708] {'Loss/classification_loss': 0.099985674,\n",
            " 'Loss/localization_loss': 0.05767369,\n",
            " 'Loss/regularization_loss': 0.11329388,\n",
            " 'Loss/total_loss': 0.27095324,\n",
            " 'learning_rate': 0.07352352}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "48UbAlBYABdm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create evaluation files"
      ],
      "metadata": {
        "id": "znEgFtf8FBFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths[\"custom_model_dir\"], paths[\"custom_model_config\"], paths[\"custom_model_dir\"])\n",
        "print(command)\n",
        "!{command}"
      ],
      "metadata": {
        "id": "sVU-sCcKAEsl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b803fd4e-0467-45f1-88ad-7394d006233b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python //content/UAVHRBuildingDetection/Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=//content/UAVHRBuildingDetection/Tensorflow/workspace/training_demo/models/HRDetection_MobNetV2 --pipeline_config_path=//content/UAVHRBuildingDetection/Tensorflow/workspace/training_demo/models/HRDetection_MobNetV2/pipeline.config --checkpoint_dir=//content/UAVHRBuildingDetection/Tensorflow/workspace/training_demo/models/HRDetection_MobNetV2\n",
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0824 09:50:58.398072 140419858831232 model_lib_v2.py:1090] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n",
            "I0824 09:50:58.398293 140419858831232 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0824 09:50:58.398389 140419858831232 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0824 09:50:58.398482 140419858831232 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0824 09:50:58.398630 140419858831232 model_lib_v2.py:1110] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "2022-08-24 09:50:59.285719: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['//content/UAVHRBuildingDetection/Tensorflow/workspace/annotations/test.record']\n",
            "I0824 09:50:59.327485 140419858831232 dataset_builder.py:162] Reading unweighted datasets: ['//content/UAVHRBuildingDetection/Tensorflow/workspace/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['//content/UAVHRBuildingDetection/Tensorflow/workspace/annotations/test.record']\n",
            "I0824 09:50:59.327773 140419858831232 dataset_builder.py:79] Reading record datasets for input file: ['//content/UAVHRBuildingDetection/Tensorflow/workspace/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0824 09:50:59.327872 140419858831232 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0824 09:50:59.327941 140419858831232 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0824 09:50:59.329719 140419858831232 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0824 09:50:59.350586 140419858831232 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0824 09:51:03.286515 140419858831232 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0824 09:51:04.410215 140419858831232 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Waiting for new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_demo/models/HRDetection_MobNetV2\n",
            "I0824 09:51:06.841325 140419858831232 checkpoint_utils.py:136] Waiting for new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_demo/models/HRDetection_MobNetV2\n",
            "INFO:tensorflow:Found new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_demo/models/HRDetection_MobNetV2/ckpt-11\n",
            "I0824 09:51:06.842534 140419858831232 checkpoint_utils.py:145] Found new checkpoint at //content/UAVHRBuildingDetection/Tensorflow/workspace/training_demo/models/HRDetection_MobNetV2/ckpt-11\n",
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0824 09:51:30.774390 140419858831232 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Finished eval step 0\n",
            "I0824 09:51:30.784482 140419858831232 model_lib_v2.py:966] Finished eval step 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W0824 09:51:30.909972 140419858831232 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "INFO:tensorflow:Finished eval step 100\n",
            "I0824 09:51:40.212129 140419858831232 model_lib_v2.py:966] Finished eval step 100\n",
            "INFO:tensorflow:Finished eval step 200\n",
            "I0824 09:51:45.696102 140419858831232 model_lib_v2.py:966] Finished eval step 200\n",
            "INFO:tensorflow:Performing evaluation on 270 images.\n",
            "I0824 09:51:49.285961 140419858831232 coco_evaluation.py:293] Performing evaluation on 270 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0824 09:51:49.291739 140419858831232 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I0824 09:51:49.304904 140419858831232 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=21.37s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.22s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.595\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.824\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.717\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.344\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.750\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.823\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.021\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.184\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.648\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.446\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.796\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.850\n",
            "INFO:tensorflow:Eval metrics at step 10000\n",
            "I0824 09:52:10.928225 140419858831232 model_lib_v2.py:1015] Eval metrics at step 10000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.594824\n",
            "I0824 09:52:10.938200 140419858831232 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.594824\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.824233\n",
            "I0824 09:52:10.939724 140419858831232 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.824233\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.717368\n",
            "I0824 09:52:10.941063 140419858831232 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.717368\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.343624\n",
            "I0824 09:52:10.942318 140419858831232 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): 0.343624\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.749524\n",
            "I0824 09:52:10.943575 140419858831232 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): 0.749524\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.823227\n",
            "I0824 09:52:10.944811 140419858831232 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): 0.823227\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.020771\n",
            "I0824 09:52:10.946045 140419858831232 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.020771\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.184023\n",
            "I0824 09:52:10.947284 140419858831232 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.184023\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.647585\n",
            "I0824 09:52:10.948533 140419858831232 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.647585\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.446212\n",
            "I0824 09:52:10.949765 140419858831232 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): 0.446212\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.795975\n",
            "I0824 09:52:10.951103 140419858831232 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.795975\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.850000\n",
            "I0824 09:52:10.952455 140419858831232 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): 0.850000\n",
            "INFO:tensorflow:\t+ Loss/localization_loss: 0.178971\n",
            "I0824 09:52:10.953453 140419858831232 model_lib_v2.py:1018] \t+ Loss/localization_loss: 0.178971\n",
            "INFO:tensorflow:\t+ Loss/classification_loss: 0.145336\n",
            "I0824 09:52:10.954586 140419858831232 model_lib_v2.py:1018] \t+ Loss/classification_loss: 0.145336\n",
            "INFO:tensorflow:\t+ Loss/regularization_loss: 0.113290\n",
            "I0824 09:52:10.955699 140419858831232 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.113290\n",
            "INFO:tensorflow:\t+ Loss/total_loss: 0.437596\n",
            "I0824 09:52:10.956765 140419858831232 model_lib_v2.py:1018] \t+ Loss/total_loss: 0.437596\n",
            "Traceback (most recent call last):\n",
            "  File \"//content/UAVHRBuildingDetection/Tensorflow/models/research/object_detection/model_main_tf2.py\", line 114, in <module>\n",
            "    tf.compat.v1.app.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/platform/app.py\", line 36, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 308, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 254, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"//content/UAVHRBuildingDetection/Tensorflow/models/research/object_detection/model_main_tf2.py\", line 89, in main\n",
            "    wait_interval=300, timeout=FLAGS.eval_timeout)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py\", line 1136, in eval_continuously\n",
            "    checkpoint_dir, timeout=timeout, min_interval_secs=wait_interval):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 212, in checkpoints_iterator\n",
            "    time.sleep(time_to_next_eval)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "load tensorboard extension"
      ],
      "metadata": {
        "id": "_-7T7lCXFDkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "dtrLXvLkFGDa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61a82f34-c902-40c3-835c-d97f7ca76c47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate training loss with Tensorbord"
      ],
      "metadata": {
        "id": "0wSwNl4KC5ad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainingLogDir = os.path.join(paths[\"custom_model_dir\"],\"train\")\n",
        "%tensorboard --logdir {trainingLogDir}\n"
      ],
      "metadata": {
        "id": "VTVjx1iNCoI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate Test results"
      ],
      "metadata": {
        "id": "_C4MS6sJFI8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evalLogDir = os.path.join(paths[\"custom_model_dir\"],\"eval\")\n",
        "%tensorboard --logdir {evalLogDir} --samples_per_plugin=images=100"
      ],
      "metadata": {
        "id": "7Q9fomE9FmSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save the results"
      ],
      "metadata": {
        "id": "q8vcvgfDGqRY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Export the model"
      ],
      "metadata": {
        "id": "GfhZPheA7J8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil as sh\n",
        "\n",
        "# Copy exporter script\n",
        "expScriptLocalPath = os.path.join(paths[\"training\"],\"exporter_main_v2.py\")\n",
        "if not os.path.exists(expScriptLocalPath):\n",
        "  sh.copyfile(os.path.join(paths['obj_detection_api'], \"exporter_main_v2.py\"), expScriptLocalPath)\n",
        "\n",
        "# run the script\n",
        "!python {expScriptLocalPath} --input_type image_tensor --pipeline_config_path {paths['custom_model_config']} --trained_checkpoint_dir {paths['custom_model_dir']} --output_directory {os.path.join(paths[\"model_export_dir\"], CUSTOM_MODEL_NAME)}"
      ],
      "metadata": {
        "id": "CcCmhsRwX8t9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Push exported model to git branch"
      ],
      "metadata": {
        "id": "e04RputVaKyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {paths[\"github_repo\"]}\n",
        "!git fetch\n",
        "!git status"
      ],
      "metadata": {
        "id": "FKElQdVvaNEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull\n",
        "!git status"
      ],
      "metadata": {
        "id": "AupXj-N3aSYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git add {paths[\"model_export_dir\"]}\n",
        "!git status"
      ],
      "metadata": {
        "id": "ZsxN-SIMabF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email \"linus.heinzelmann@uni-ulm.de\"\n",
        "!git config --global user.name \"lheinzel\"\n",
        "!git commit -m \"model trained on colab\"\n",
        "!git status"
      ],
      "metadata": {
        "id": "JzIjIfBea7KQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git remote"
      ],
      "metadata": {
        "id": "eS6NmonQlI_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git push origin {GIT_BRANCH}"
      ],
      "metadata": {
        "id": "exRRBU4VlMn_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}